{"meta":{"title":"wzktravel","subtitle":null,"description":null,"author":"wzktravel","url":"http://wzktravel.github.io"},"pages":[],"posts":[{"title":"elasticsearch2.3.5升级到5.1.2","slug":"elasticsearch-upgrade-to-5-1-2-from-2-3-5","date":"2017-01-18T02:33:39.000Z","updated":"2017-02-17T07:44:11.000Z","comments":true,"path":"2017/01/18/elasticsearch-upgrade-to-5-1-2-from-2-3-5/","link":"","permalink":"http://wzktravel.github.io/2017/01/18/elasticsearch-upgrade-to-5-1-2-from-2-3-5/","excerpt":"elasticsearch在2.3.5版本中，在写入数据量比较大的时候经常遇到load超高的情况。决定升级到5.1.2看看效果。目前来看升级后机器load有显著降低。以下记录升级过程中需要注意的一些事情，以及java api和spark api的变化。","text":"elasticsearch&#x5728;2.3.5&#x7248;&#x672C;&#x4E2D;&#xFF0C;&#x5728;&#x5199;&#x5165;&#x6570;&#x636E;&#x91CF;&#x6BD4;&#x8F83;&#x5927;&#x7684;&#x65F6;&#x5019;&#x7ECF;&#x5E38;&#x9047;&#x5230;load&#x8D85;&#x9AD8;&#x7684;&#x60C5;&#x51B5;&#x3002;&#x51B3;&#x5B9A;&#x5347;&#x7EA7;&#x5230;5.1.2&#x770B;&#x770B;&#x6548;&#x679C;&#x3002;&#x76EE;&#x524D;&#x6765;&#x770B;&#x5347;&#x7EA7;&#x540E;&#x673A;&#x5668;load&#x6709;&#x663E;&#x8457;&#x964D;&#x4F4E;&#x3002;&#x4EE5;&#x4E0B;&#x8BB0;&#x5F55;&#x5347;&#x7EA7;&#x8FC7;&#x7A0B;&#x4E2D;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x4E00;&#x4E9B;&#x4E8B;&#x60C5;&#xFF0C;&#x4EE5;&#x53CA;java api&#x548C;spark api&#x7684;&#x53D8;&#x5316;&#x3002; &#x5347;&#x7EA7;&#x8FC7;&#x7A0B;&#x4E0B;&#x8F7D;&#x89E3;&#x538B;&#x7701;&#x7565; &#x4FEE;&#x6539;jvm&#x53C2;&#x6570;&#x4FEE;&#x6539;config/jvm.options &#x4FEE;&#x6539;&#x673A;&#x5668;&#x914D;&#x7F6E; &#x4FEE;&#x6539;vm.max_map_count&#x5230;262144&#x4EE5;&#x4E0A; 1sudo sysctl -w vm.max_map_count=270000 &#x53C2;&#x8003;elastic: Maximum map count check &#x4FEE;&#x6539;&#x6587;&#x4EF6;&#x63CF;&#x8FF0;&#x7B26;&#x5927;&#x5C0F;&#xFF0C;&#x5C06;&#x542F;&#x52A8;es&#x7528;&#x6237;&#x7684;&#x6587;&#x4EF6;&#x63CF;&#x8FF0;&#x7B26;&#x5927;&#x5C0F;&#x8BBE;&#x7F6E;&#x4E3A;65536&#x4EE5;&#x4E0A; &#x4FEE;&#x6539;/etc/security/limits.conf&#x3002; &#x5347;&#x7EA7;&#x4ECE;2.3.x&#x5347;&#x7EA7;&#x5230;5.x.x&#xFF0C;&#x4E0D;&#x80FD;&#x91C7;&#x7528;&#x4EE5;&#x524D;&#x7684;&#x6EDA;&#x52A8;&#x91CD;&#x542F;&#x65B9;&#x5F0F;&#xFF0C;&#x5FC5;&#x987B;&#x5C06;&#x6574;&#x4E2A;&#x96C6;&#x7FA4;&#x5168;&#x90E8;&#x505C;&#x6389;&#xFF0C;&#x7136;&#x540E;&#x5347;&#x7EA7;&#x540E;&#x91CD;&#x542F;&#x3002;&#x5347;&#x7EA7;&#x8FC7;&#x7A0B;&#x4E3B;&#x8981;&#x53C2;&#x8003;Elastic: Full cluster restart upgrade &#x63D2;&#x4EF6;&#x5B89;&#x88C5;5.0.0&#x4EE5;&#x524D;&#x7248;&#x672C;&#x5B89;&#x88C5;&#x63D2;&#x4EF6;&#x4F7F;&#x7528;bin/plugin install&#xFF0C;&#x65B0;&#x7248;&#x672C;&#x7684;&#x4F7F;&#x7528;bin/elasticsearch-plugin install&#x3002; kopfkopf&#x4E0D;&#x518D;&#x652F;&#x6301;es 5.0.0&#x53CA;&#x4EE5;&#x4E0A;&#x7248;&#x672C;&#x3002;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;cerebro&#x4EE3;&#x66FF;&#x3002; elasticsearch sqlgithub&#x5730;&#x5740;: https://github.com/NLPchina/elasticsearch-sql/ 1./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/5.1.2.0/elasticsearch-sql-5.1.2.0.zip &#x5B89;&#x88C5;elasticsearch-sql UI&#x754C;&#x9762;5.0.0&#x4EE5;&#x540E;&#xFF0C;&#x9700;&#x8981;&#x5355;&#x72EC;&#x5B89;&#x88C5;UI&#x754C;&#x9762;&#x3002; &#x5B89;&#x88C5;node js&#xFF0C;&#x53C2;&#x8003;http://www.cnblogs.com/kevin19900306/p/5701281.html &#x4E0B;&#x8F7D;https://github.com/NLPchina/elasticsearch-sql/releases/download/5.1.2/es-sql-site-standalone.zip&#xFF0C;&#x89E3;&#x538B; &#x542F;&#x52A8; 123$ cd site-server$ npm install express --save$ node node-server.js kibana&#x65B0;&#x7248;&#x672C;&#x7684;kibana&#x4E2D;&#x81EA;&#x5E26;dev tools&#xFF0C;&#x6709;&#x5174;&#x8DA3;&#x53EF;&#x4EE5;&#x7814;&#x7A76;&#x4E00;&#x4E0B;xpack&#x3002; &#x4EE3;&#x7801;&#x65B9;&#x9762;javamaven&#x4F9D;&#x8D56;&#xFF1A; 12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;${elasticsearch.version}&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;rest&lt;/artifactId&gt; &lt;version&gt;${elasticsearch.version}&lt;/version&gt;&lt;/dependency&gt; &#x5347;&#x7EA7;maven&#x4F9D;&#x8D56;&#x540E;&#xFF0C;&#x4F1A;&#x53D1;&#x73B0;&#x4E4B;&#x524D;&#x4EE3;&#x7801;&#x4E2D;&#x6709;&#x4E00;&#x4E9B;api&#x5DF2;&#x7ECF;&#x6539;&#x53D8;&#xFF0C;&#x6839;&#x636E;&#x63D0;&#x793A;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x5373;&#x53EF;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x65B0;&#x7248;&#x672C;&#x4E2D;&#x6DFB;&#x52A0;&#x4E86;rest&#x65B9;&#x5F0F;&#x4E0E;elasticsearch&#x8FDB;&#x884C;&#x4EA4;&#x4E92;&#x3002; sparkmaven&#x4F9D;&#x8D56;&#xFF1A; 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-spark-13_2.10&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;spark-sql_2.10&lt;/artifactId&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; api&#x6CA1;&#x6709;&#x53D8;&#x5316;&#x3002; &#x53C2;&#x8003; &#x5927;&#x6570;&#x636E;&#x6742;&#x8C08;&#x5FAE;&#x8BFE;&#x5802;|Elasticsearch 5.0&#x65B0;&#x7248;&#x672C;&#x7684;&#x7279;&#x6027;&#x4E0E;&#x6539;&#x8FDB;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://wzktravel.github.io/tags/elasticsearch/"}]},{"title":"kafka安装和配置","slug":"kafka-install-and-config","date":"2017-01-17T03:40:42.000Z","updated":"2017-01-18T02:23:18.000Z","comments":true,"path":"2017/01/17/kafka-install-and-config/","link":"","permalink":"http://wzktravel.github.io/2017/01/17/kafka-install-and-config/","excerpt":"以0.9.0.1版本kafka为例，介绍kafka的安装、配置步骤，以及如何开启jmx等。","text":"&#x4EE5;0.9.0.1&#x7248;&#x672C;kafka&#x4E3A;&#x4F8B;&#xFF0C;&#x4ECB;&#x7ECD;kafka&#x7684;&#x5B89;&#x88C5;&#x3001;&#x914D;&#x7F6E;&#x6B65;&#x9AA4;&#xFF0C;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x5F00;&#x542F;jmx&#x7B49;&#x3002; &#x4E0B;&#x8F7D;&#x4ECE;&#x5B98;&#x7F51;http://kafka.apache.org/downloads&#x9009;&#x62E9;&#x5408;&#x9002;&#x7248;&#x672C;&#x4E0B;&#x8F7D;&#xFF0C;&#x89E3;&#x538B;&#x5373;&#x53EF;&#x3002;&#x4E3A;&#x4E86;&#x4EE5;&#x540E;&#x5347;&#x7EA7;&#x65B9;&#x4FBF;&#xFF0C;&#x53EF;&#x4EE5;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x8F6F;&#x94FE;&#xFF0C;ln -s kafka-0.9.0.1 kafka&#xFF0C;&#x5982;&#x4EE5;&#x540E;&#x5347;&#x7EA7;&#x5230;0.10.1.1&#xFF0C;&#x53EA;&#x9700;&#x6539;&#x53D8;&#x8F6F;&#x94FE;&#x6307;&#x5411;&#x5373;&#x53EF;&#x3002;&#x4F7F;&#x7528;&#x8F6F;&#x94FE;&#x53E6;&#x4E00;&#x4E2A;&#x597D;&#x5904;&#x662F; kafka&#x914D;&#x7F6E;&#x4FEE;&#x6539;conf/server.properties&#x6587;&#x4EF6;&#xFF0C;&#x6839;&#x636E;&#x9700;&#x8981;&#x4FEE;&#x6539;&#x3002; 1234567891011121314151617181920212223242526272829303132listeners=PLAINTEXT://:9092auto.create.topics.enable=trueauto.leader.rebalance.enable=truecontrolled.shutdown.enable=truedelete.topic.enable=truekafka.http.metrics.host=0.0.0.0kafka.http.metrics.port=24042log.segment.bytes=106954752max.connections.per.ip=10message.max.bytes=5000000min.insync.replicas=1replica.fetch.max.bytes=10000000replica.lag.max.messages=4000unclean.leader.election.enable=falsezookeeper.session.timeout.ms=6000log.retention.bytes=-1port=9092# &#x4E0D;&#x4E3B;&#x52A8;&#x521B;&#x5EFA;topic&#x65F6;&#xFF0C;&#x9ED8;&#x8BA4;&#x4F7F;&#x7528;&#x7684;&#x5907;&#x4EFD;&#x56E0;&#x5B50;&#xFF0C;partition&#x6570;&#x91CF;&#xFF0C;&#x8FC7;&#x671F;&#x65F6;&#x95F4;default.replication.factor=2num.partitions=6log.retention.hours=168log.roll.hours=168# kafka&#x6570;&#x636E;&#x76EE;&#x5F55;&#xFF0C;&#x4E0D;&#x662F;kafka&#x81EA;&#x8EAB;&#x65E5;&#x5FD7;&#x76EE;&#x5F55;log.dirs=/data/kafka/data# kafka&#x8FDE;&#x63A5;&#x7684;zk&#x5730;&#x5740;&#xFF0C;&#x5404;&#x4E2A;broker&#x914D;&#x7F6E;&#x4E00;&#x81F4;zookeeper.connect=192.168.10.1:2181,192.168.10.2:2181,192.168.10.3:2181# &#x5404;&#x4E2A;broker&#x914D;&#x7F6E;&#x4E0D;&#x4E00;&#x81F4;&#x7684;&#x5730;&#x65B9;advertised.host.name=192.168.11.1broker.id=0 kafka&#x81EA;&#x8EAB;&#x65E5;&#x5FD7;&#x76EE;&#x5F55;&#x9ED8;&#x8BA4;&#x662F;${kafka.dir}/logs&#xFF0C;&#x53EF;&#x4EE5;&#x5728;bin/kafa-server-start.sh&#x4E2D;export LOG_DIR&#x4FEE;&#x6539;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4FEE;&#x6539;bin/kafka-run-class.sh&#x7684;&#x4EE5;&#x4E0B;&#x90E8;&#x5206;&#x3002;1234# Log directory to useif [ &quot;x$LOG_DIR&quot; = &quot;x&quot; ]; then LOG_DIR=&quot;$base_dir/logs&quot;fi jvm&#x914D;&#x7F6E;&#x914D;&#x7F6E;xmx,xms&#xFF0C;&#x76F4;&#x63A5;&#x4FEE;&#x6539;bin/kafa-server-start.sh&#x3002; 123if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then export KAFKA_HEAP_OPTS=&quot;-Xmx4G -Xms4G&quot;fi &#x9700;&#x8981;&#x4FEE;&#x6539;&#x66F4;&#x591A;jvm&#x53C2;&#x6570;&#xFF0C;&#x5982;gc&#x7B49;&#xFF0C;&#x4FEE;&#x6539;bin/kafka-run-class.sh&#x3002; jmx&#x914D;&#x7F6E;&#x53EF;&#x4EE5;&#x5728;bin/kafa-server-start.sh&#x4E2D;export KAFKA_JMX_OPTS&#x548C;KAFKA_JMX_OPTS&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4FEE;&#x6539;bin/kafka-run-class.sh&#x3002; 1234567891011# JMX settingsif [ -z &quot;$KAFKA_JMX_OPTS&quot; ]; then KAFKA_JMX_OPTS=&quot;-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false &quot;fi# JMX port to useJMX_PORT=9393JMX_RMI_PORT=8033if [ $JMX_PORT ]; then KAFKA_JMX_OPTS=&quot;$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT -Dcom.sun.management.jmxremote.rmi.port=$JMX_RMI_PORT &quot;fi &#x7531;&#x4E8E;jmx&#x4F1A;&#x5728;jmxremote.port&#x4E4B;&#x5916;&#xFF0C;&#x53E6;&#x5916;&#x968F;&#x673A;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x7AEF;&#x53E3;&#x4F5C;&#x4E3A;jmxremote.rmi.port&#xFF0C;\b&#x5F53;&#x673A;&#x5668;&#x6253;&#x5F00;iptables&#x800C;&#x6B64;&#x7AEF;&#x53E3;&#x4E0D;&#x5728;iptables&#x653E;&#x884C;&#x7AEF;&#x53E3;&#x4E2D;&#x65F6;&#xFF0C;&#x5C31;&#x4F1A;&#x8FDE;&#x63A5;&#x4E0D;&#x4E86;jmx&#x3002;&#x6240;&#x4EE5;&#x6CE8;&#x610F;jmxremote.port&#x548C;jmxremote.rmi.port&#x90FD;&#x9700;&#x8981;&#x914D;&#x7F6E;&#xFF0C;&#x5E76;&#x4E14;&#x5728;iptables&#x4E2D;&#x653E;&#x884C;&#x3002; &#x53C2;&#x8003;Stack Overflow: How to activate JMX on my JVM for access with jconsole?","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://wzktravel.github.io/tags/kafka/"}]},{"title":"zookeeper python客户端","slug":"zookeeper-python-client","date":"2016-12-19T02:18:24.000Z","updated":"2017-01-18T02:23:30.000Z","comments":true,"path":"2016/12/19/zookeeper-python-client/","link":"","permalink":"http://wzktravel.github.io/2016/12/19/zookeeper-python-client/","excerpt":"","text":"123$ git clone https://github.com/rgs1/zk_shell$ sudo pip install -r zk_shell/requirements.txt$ export ZKSHELL_SRC=1; bin/zk-shell &#x6216;&#x8005;&#x76F4;&#x63A5;pip&#x5B89;&#x88C5; 1$ pip install zk-shell &#x4FEE;&#x6539;pip&#x6E90;&#x4F7F;&#x7528;&#x963F;&#x91CC;pip&#x6E90; 1234$ cat ~/.pip/pip.conf[global]trusted-host = mirrors.aliyun.comindex-url = http://mirrors.aliyun.com/pypi/simple","categories":[],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://wzktravel.github.io/tags/zookeeper/"},{"name":"python","slug":"python","permalink":"http://wzktravel.github.io/tags/python/"}]},{"title":"greenplum分区","slug":"greenplum-partition","date":"2016-12-17T11:10:49.000Z","updated":"2016-12-17T11:49:52.000Z","comments":true,"path":"2016/12/17/greenplum-partition/","link":"","permalink":"http://wzktravel.github.io/2016/12/17/greenplum-partition/","excerpt":"","text":"&#x521B;&#x5EFA;&#x5206;&#x533A;&#x8868;1234567891011121314CREATE SCHEMA employee;CREATE TABLE &quot;employee&quot;.&quot;employee&quot; ( &quot;name&quot; VARCHAR, &quot;ei&quot; int4 NOT NULL, &quot;employeeid&quot; int4 NOT NULL, &quot;department&quot; TEXT, &quot;updatetime&quot; TIMESTAMP (0), &quot;isstop&quot; int2, CONSTRAINT &quot;employee_pk&quot; PRIMARY KEY (&quot;ei&quot;, &quot;employeeid&quot;)) WITH (OIDS = FALSE) DISTRIBUTED BY (ei) PARTITION BY RANGE (ei)( START (0) END (500000) EVERY (10000), DEFAULT PARTITION extra); &#x5206;&#x533A;&#x524D;&#x540E;&#x6027;&#x80FD;&#x5BF9;&#x6BD4;&#x5206;&#x533A;&#x524D;&#x540E;&#x590D;&#x6742;sql&#x7684;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x5BF9;&#x6BD4;&#xFF0C;&#x5355;&#x4F4D;&#x662F;&#x79D2; &#x5206;&#x533A;&#x524D; &#x5206;&#x533A;&#x540E; 3.666 2.836 7.105 2.873 4.763 2.624 6.018 3.070 5.024 2.310 3.101 1.967 5.357 3.095 &#x67E5;&#x770B;&#x8868;&#x7A7A;&#x95F4;&#x5927;&#x5C0F; &#x67E5;&#x770B;&#x6307;&#x5B9A;&#x8868;&#x5927;&#x5C0F; 1select pg_size_pretty(pg_relation_size(&apos;test&apos;)); &#x67E5;&#x770B;&#x6307;&#x5B9A;schema&#x4E0B;&#x6240;&#x6709;&#x8868;&#x5927;&#x5C0F; 1select relname, pg_size_pretty(pg_relation_size(relid)) from pg_stat_user_tables where schemaname=&apos;public&apos; order by pg_relation_size(relid) desc; &#x9644;&#x5F55;copy1copy (select ei, contactid, isdeleted, name, tel, mobile from contact) to &apos;/data/contact.txt&apos;; &#x68C0;&#x67E5;schema&#x662F;&#x5426;&#x5B58;&#x5728;1select exists (select * from pg_catalog.pg_namespace where nspname = &apos;$schema&apos;) as schema_exists &#x68C0;&#x67E5;table&#x662F;&#x5426;&#x5B58;&#x5728;1select exists (select 1 from information_schema.tables where table_schema = &apos;$schema&apos; and table_name = &apos;$table&apos;) as table_exists &#x53C2;&#x8003; Pivotal Greenplum Docs: CREATE TABLE Pivotal Greenplum Docs: DELETE Pivotal Greenplum Docs: Partitioning Large Tables PostgreSQL &#x67E5;&#x770B;&#x6570;&#x636E;&#x5E93;&#xFF0C;&#x7D22;&#x5F15;&#xFF0C;&#x8868;&#xFF0C;&#x8868;&#x7A7A;&#x95F4;&#x5927;&#x5C0F; How to check if PostgreSQL public schema exists? - Stack Overflow","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"http://wzktravel.github.io/tags/sql/"}]},{"title":"spark自定义分区策略(partitioner)","slug":"spark-custom-partitioner","date":"2016-12-17T09:23:00.000Z","updated":"2016-12-17T11:02:33.000Z","comments":true,"path":"2016/12/17/spark-custom-partitioner/","link":"","permalink":"http://wzktravel.github.io/2016/12/17/spark-custom-partitioner/","excerpt":"Spark内部提供了HashPartitioner和RangePartitioner两种分区策略，但有些场景下，我们希望能够根据业务需求自定义分区策略。只需要继承Partitioner，然后实现其方法即可。 12345678/** * An object that defines how the elements in a key-value pair RDD are partitioned by key. * Maps each key to a partition ID, from 0 to `numPartitions - 1`. */abstract class Partitioner extends Serializable &#123; def numPartitions: Int def getPartition(key: Any): Int&#125;","text":"Spark&#x5185;&#x90E8;&#x63D0;&#x4F9B;&#x4E86;HashPartitioner&#x548C;RangePartitioner&#x4E24;&#x79CD;&#x5206;&#x533A;&#x7B56;&#x7565;&#xFF0C;&#x4F46;&#x6709;&#x4E9B;&#x573A;&#x666F;&#x4E0B;&#xFF0C;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x80FD;&#x591F;&#x6839;&#x636E;&#x4E1A;&#x52A1;&#x9700;&#x6C42;&#x81EA;&#x5B9A;&#x4E49;&#x5206;&#x533A;&#x7B56;&#x7565;&#x3002;&#x53EA;&#x9700;&#x8981;&#x7EE7;&#x627F;Partitioner&#xFF0C;&#x7136;&#x540E;&#x5B9E;&#x73B0;&#x5176;&#x65B9;&#x6CD5;&#x5373;&#x53EF;&#x3002; 12345678/** * An object that defines how the elements in a key-value pair RDD are partitioned by key. * Maps each key to a partition ID, from 0 to `numPartitions - 1`. */abstract class Partitioner extends Serializable { def numPartitions: Int def getPartition(key: Any): Int} &#x73B0;&#x5728;&#x9047;&#x5230;&#x4E00;&#x4E2A;&#x573A;&#x666F;&#xFF0C;&#x4ECE;&#x6570;&#x636E;&#x5E93;&#x540C;&#x6B65;&#x6570;&#x636E;&#x5230;kafka&#x4E2D;&#xFF0C;&#x7136;&#x540E;&#x4F7F;&#x7528;spark&#x4ECE;kafka&#x83B7;&#x53D6;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x3002;&#x7531;&#x4E8E;&#x6839;&#x636E;&#x6570;&#x636E;&#x5E93;&#x64CD;&#x4F5C;&#x8BB0;&#x5F55;&#x8FDB;&#x884C;&#x540C;&#x6B65;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x6570;&#x636E;&#x5E93;&#x4E2D;&#x540C;&#x4E00;&#x6761;&#x6570;&#x636E;&#x53EF;&#x80FD;&#x88AB;&#x66F4;&#x65B0;&#x6216;&#x5220;&#x9664;&#x591A;&#x6B21;&#xFF0C;&#x8FD9;&#x8981;&#x6C42;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5C06;&#x76F8;&#x540C;&#x4E3B;&#x952E;&#x7684;&#x6570;&#x636E;&#x5206;&#x533A;&#x5230;&#x540C;&#x4E00;&#x4E2A;&#x533A;&#x4E2D;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x3002; &#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x7684;&#x5206;&#x533A;&#x7B56;&#x7565;&#x662F;&#xFF0C;&#x4ECE;&#x6570;&#x636E;&#x4E2D;&#x627E;&#x51FA;&#x4E3B;&#x952E;&#xFF0C;&#x5C06;&#x5176;&#x5206;&#x914D;&#x5230;&#x67D0;&#x4E00;&#x4E2A;&#x5206;&#x533A;&#x4E2D;&#x3002; 123456789101112131415161718192021class PrimaryKeyPartitioner(partitions: Int) extends Partitioner { override def numPartitions: Int = partitions override def getPartition(key: Any): Int = key match { case null =&gt; 0 case _ =&gt; try { val json = JSON.parseObject(key.toString) val primaryKeyString = json.getString(&quot;primary_keys&quot;) .split(&quot;,&quot;) .map(k =&gt; json.getString(k)) .mkString(&quot;_&quot;) Utils.nonNegativeMod(primaryKeyString.hashCode, numPartitions) } catch { case e: Exception =&gt; e.printStackTrace() 0 } }} &#x4F7F;&#x7528;&#x975E;&#x5E38;&#x7B80;&#x5355; 12345rdd.partitionBy(new PrimaryKeyPartitioner(numPartitions)).foreachPartition( par =&gt; { // &#x5904;&#x7406;&#x903B;&#x8F91; }) &#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x4F7F;&#x7528;partitionBy&#x65B9;&#x6CD5;&#x7684;rdd&#x7C7B;&#x578B;&#x9700;&#x8981;&#x662F;kv&#x5143;&#x7EC4;&#xFF0C;&#x4ECE;&#x6E90;&#x7801;&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#x3002; 12345678910111213/** * Return a copy of the RDD partitioned using the specified partitioner. */def partitionBy(partitioner: Partitioner): RDD[(K, V)] = self.withScope { if (keyClass.isArray &amp;&amp; partitioner.isInstanceOf[HashPartitioner]) { throw new SparkException(&quot;Default partitioner cannot partition array keys.&quot;) } if (self.partitioner == Some(partitioner)) { self } else { new ShuffledRDD[K, V, V](self, partitioner) }} &#x6240;&#x4EE5;&#x5982;&#x679C;&#x662F;&#x4ECE;&#x6587;&#x4EF6;&#x4E2D;&#x8BFB;&#x53D6;&#x6570;&#x636E;&#xFF0C;&#x9700;&#x8981;&#x5C06;&#x5176;&#x8F6C;&#x6362;&#x4E3A;&#x5143;&#x7EC4;&#x624D;&#x80FD;&#x4F7F;&#x7528;partitionBy&#x65B9;&#x6CD5;&#x3002; 1val rdd: RDD[(String, String)] = sc.textFile(&quot;sss.log&quot;).map((_, &quot;&quot;))","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"}]},{"title":"spark使用jdbc connector连接数据库","slug":"jdbc-spark-connector","date":"2016-12-12T14:53:06.000Z","updated":"2016-12-14T01:39:48.000Z","comments":true,"path":"2016/12/12/jdbc-spark-connector/","link":"","permalink":"http://wzktravel.github.io/2016/12/12/jdbc-spark-connector/","excerpt":"","text":"&#x4F7F;&#x7528;spark-shell&#x6D4B;&#x8BD5;1SPARK_CLASSPATH=/usr/share/java/mysql-connector-java.jar spark-shell &#x4F7F;&#x7528; --driver-class-path &#x53C2;&#x6570;&#x5728;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;&#x65F6;&#x4F1A;&#x62A5;&#x9519;&#xFF0C; Did not find registered driver with class com.mysql.jdbc.Driver &#x3002;&#x731C;&#x6D4B;&#x662F;&#x7531;&#x4E8E;yarn&#x6CA1;&#x6709;&#x9ED8;&#x8BA4;&#x52A0;&#x8F7D;mysql-connector-java.jar&#x9020;&#x6210;&#x7684;&#x3002; &#x521B;&#x5EFA;DataFrame12345678910111213141516171819scala&gt; val df = sqlContext.read.format(&quot;jdbc&quot;).options(Map(&quot;url&quot; -&gt; &quot;jdbc:mysql://db_host/?user=secret&amp;password=secret&quot;,&quot;dbtable&quot; -&gt; &quot;db.table&quot;)).load()df: org.apache.spark.sql.DataFrame = [id: string, name: string, age: int]scala&gt; df.printSchemaroot |-- id: string (nullable = false) |-- name: string (nullable = true) |-- age: integer (nullable = true)scala&gt; df.countres0: Long = 7scala&gt; df.registerTempTable(&quot;people&quot;)scala&gt; sqlContext.sql(&quot;select count(*) from people&quot;).collectres2: Array[org.apache.spark.sql.Row] = Array([7])scala&gt; sqlContext.sql(&quot;select name, age from people&quot;).collectres3: Array[org.apache.spark.sql.Row] = Array([name,32], [name,32], [name,32], [name,32], [name,32], [name,32], [name,32]) &#x53C2;&#x8003; spark1.6&#x5B98;&#x65B9;&#x6587;&#x6863; stackoverflow: &#x5982;&#x4F55;&#x4F7F;&#x7528;spark&#x8FDE;&#x63A5;postgresql Spark SQL&#x5B98;&#x65B9;&#x6587;&#x6863;-&#x4E2D;&#x6587;&#x7FFB;&#x8BD1;","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"}]},{"title":"kafka manager","slug":"kafka-manager","date":"2016-12-01T02:38:10.000Z","updated":"2017-06-20T07:40:02.000Z","comments":true,"path":"2016/12/01/kafka-manager/","link":"","permalink":"http://wzktravel.github.io/2016/12/01/kafka-manager/","excerpt":"","text":"yahoo&#x51FA;&#x54C1;&#x7684;kafka&#x7BA1;&#x7406;&#x5DE5;&#x5177;&#xFF0C;git&#x5730;&#x5740;https://github.com/yahoo/kafka-manager&#x3002; &#x624B;&#x52A8;&#x6253;&#x5305;kafka-manager&#x7528;scala&#x7F16;&#x5199;&#xFF0C;&#x9700;&#x8981;&#x4F7F;&#x7528;sbt&#x8FDB;&#x884C;&#x6253;&#x5305;&#x3002;sbt&#x73AF;&#x5883;&#x914D;&#x7F6E;&#x8FD9;&#x91CC;&#x4E0D;&#x8BE6;&#x7EC6;&#x4ECB;&#x7ECD;&#xFF0C;&#x4F46;&#x4E3A;&#x52A0;&#x5FEB;&#x4F9D;&#x8D56;&#x5305;&#x4E0B;&#x8F7D;&#x901F;&#x5EA6;&#xFF0C;&#x53EF;&#x4EE5;&#x4FEE;&#x6539;project/plugins.sbt&#xFF0C;&#x589E;&#x52A0;&#x6216;&#x4FEE;&#x6539;resolvers&#x3002; 123// The Typesafe repository// resolvers += &quot;Typesafe repository&quot; at &quot;http://repo.typesafe.com/typesafe/releases/&quot;resolvers += &quot;sonatype&quot; at &quot;https://oss.sonatype.org/content/repositories/public/&quot; &#x7136;&#x540E;&#x4F7F;&#x7528;./sbt clean dist&#x8FDB;&#x884C;&#x6253;&#x5305;&#xFF0C;&#x6253;&#x5305;&#x540E;&#x7684;zip&#x5305;&#x5728;target/universal/&#x4E0B;&#x3002; &#x4E5F;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4E0B;&#x8F7D;&#x6211;&#x6253;&#x5305;&#x597D;&#x7684;zip&#x5305;: kafka-manager-1.3.0.7 kafka-manager-1.3.3.7 &#x914D;&#x7F6E;&#x4FEE;&#x6539;&#x89E3;&#x538B;&#x540E;&#x542F;&#x52A8;&#x524D;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x4E00;&#x4E9B;&#x8BBE;&#x7F6E;&#xFF1A; &#x4FEE;&#x6539;conf/application.conf&#x4E2D;kafka-manager.zkhosts&#x4E3A;&#x4F60;&#x81EA;&#x5DF1;&#x7684;zookeeper&#x5730;&#x5740;&#xFF0C;&#x6B64;zk&#x5730;&#x5740;&#x662F;kafka-manager&#x4F7F;&#x7528;&#x7684;&#xFF0C;&#x7528;&#x6765;&#x4FDD;&#x5B58;&#x4E00;&#x4E9B;kafka-manager&#x7684;&#x72B6;&#x6001;&#x7B49;&#x3002; &#x591A;&#x4E2A;zk&#x65F6;&#x7528;&#x9017;&#x53F7;&#x5206;&#x9694;&#xFF0C; 1kafka-manager.zkhosts=&quot;my.zookeeper.host.com:2181,other.zookeeper.host.com:2181&quot; &#x66F4;&#x6539;&#x65E5;&#x5FD7;&#x76EE;&#x5F55;&#xFF0C;&#x4FEE;&#x6539;conf/logback.xml&#x4E2D;name&#x4E3A;FILE&#x7684;appender&#x3002; 123456789101112&lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- &lt;file&gt;${application.home}/logs/application.log&lt;/file&gt; --&gt; &lt;encoder&gt; &lt;pattern&gt;%date - [%level] - from %logger in %thread %n%message%n%xException%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;logs/application.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;5&lt;/maxHistory&gt; &lt;totalSizeCap&gt;5GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt;&lt;/appender&gt; &#x542F;&#x52A8; &#x6307;&#x5B9A;java home&#x548C;&#x7AEF;&#x53E3;&#x542F;&#x52A8;&#x3002; 1/bin/kafka-manager -java-home /usr/java/jdk1.8.0_66 -Dhttp.port=8909","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://wzktravel.github.io/tags/kafka/"}]},{"title":"kafka系统工具","slug":"kafka-system-tools","date":"2016-11-23T03:58:02.000Z","updated":"2016-12-13T15:08:45.000Z","comments":true,"path":"2016/11/23/kafka-system-tools/","link":"","permalink":"http://wzktravel.github.io/2016/11/23/kafka-system-tools/","excerpt":"Kafka内部提供了许多管理脚本，这些脚本都放在$KAFKA_HOME/bin目录下，而这些类的实现都是放在源码的kafka/core/src/main/Scala/kafka/tools/路径下。","text":"Kafka&#x5185;&#x90E8;&#x63D0;&#x4F9B;&#x4E86;&#x8BB8;&#x591A;&#x7BA1;&#x7406;&#x811A;&#x672C;&#xFF0C;&#x8FD9;&#x4E9B;&#x811A;&#x672C;&#x90FD;&#x653E;&#x5728;$KAFKA_HOME/bin&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x800C;&#x8FD9;&#x4E9B;&#x7C7B;&#x7684;&#x5B9E;&#x73B0;&#x90FD;&#x662F;&#x653E;&#x5728;&#x6E90;&#x7801;&#x7684;kafka/core/src/main/Scala/kafka/tools/&#x8DEF;&#x5F84;&#x4E0B;&#x3002; consumer offset checkerConsumer Offset Checker&#x4E3B;&#x8981;&#x662F;&#x8FD0;&#x884C;kafka.tools.ConsumerOffsetChecker&#x7C7B;&#xFF0C;&#x5BF9;&#x5E94;&#x7684;&#x811A;&#x672C;&#x662F;kafka-consumer-offset-checker.sh&#xFF0C;&#x4F1A;&#x663E;&#x793A;&#x51FA;Consumer&#x7684;Group&#x3001;Topic&#x3001;&#x5206;&#x533A;ID&#x3001;&#x5206;&#x533A;&#x5BF9;&#x5E94;&#x5DF2;&#x7ECF;&#x6D88;&#x8D39;&#x7684;Offset&#x3001;logSize&#x5927;&#x5C0F;&#xFF0C;Lag&#x4EE5;&#x53CA;Owner&#x7B49;&#x4FE1;&#x606F;&#x3002; &#x5982;&#x679C;&#x8FD0;&#x884C;kafka-consumer-offset-checker.sh&#x811A;&#x672C;&#x7684;&#x65F6;&#x5019;&#x4EC0;&#x4E48;&#x4FE1;&#x606F;&#x90FD;&#x4E0D;&#x8F93;&#x5165;&#xFF0C;&#x90A3;&#x4E48;&#x4F1A;&#x663E;&#x793A;&#x4EE5;&#x4E0B;&#x4FE1;&#x606F;&#xFF1A;123456789101112131415[iteblog@www.iteblog.com /]$ bin/kafka-consumer-offset-checker.shCheck the offset of your consumers.Option Description ------ ----------- --broker-info Print broker info --group Consumer group. --help Print this message. --retry.backoff.ms &lt;Integer&gt; Retry back-off to use for failed offset queries. (default: 3000) --socket.timeout.ms &lt;Integer&gt; Socket timeout to use when querying for offsets. (default: 6000) --topic Comma-separated list of consumer topics (all topics if absent). --zookeeper ZooKeeper connect string. (default: localhost:2181) &#x6211;&#x4EEC;&#x6839;&#x636E;&#x63D0;&#x793A;&#xFF0C;&#x8F93;&#x5165;&#x7684;&#x547D;&#x4EE4;&#x5982;&#x4E0B;&#xFF1A;1234567891011121314151617[iteblog@www.iteblog.com /]$ bin/kafka-consumer-offset-checker.sh --zookeeper www.iteblog.com:2181 --topic test --group spark --broker-infoGroup Topic Pid Offset logSize Lag Ownerspark test 0 34666914 34674392 7478 nonespark test 1 34670481 34678029 7548 nonespark test 2 34670547 34678002 7455 nonespark test 3 34664512 34671961 7449 nonespark test 4 34680143 34687562 7419 nonespark test 5 34672309 34679823 7514 nonespark test 6 34674660 34682220 7560 noneBROKER INFO2 -&gt; www.iteblog.com:90925 -&gt; www.iteblog.com:90934 -&gt; www.iteblog.com:90947 -&gt; www.iteblog.com:90951 -&gt; www.iteblog.com:90963 -&gt; www.iteblog.com:90976 -&gt; www.iteblog.com:9098 Dump Log Segment&#x6709;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x9A8C;&#x8BC1;&#x65E5;&#x5FD7;&#x7D22;&#x5F15;&#x662F;&#x5426;&#x6B63;&#x786E;&#xFF0C;&#x6216;&#x8005;&#x4EC5;&#x4EC5;&#x60F3;&#x4ECE;log&#x6587;&#x4EF6;&#x4E2D;&#x76F4;&#x63A5;&#x6253;&#x5370;&#x6D88;&#x606F;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;kafka.tools.DumpLogSegments&#x7C7B;&#x6765;&#x5B9E;&#x73B0;&#xFF0C;&#x5148;&#x6765;&#x770B;&#x770B;&#x5B83;&#x9700;&#x8981;&#x7684;&#x53C2;&#x6570;&#xFF1A;123456789101112131415161718192021222324252627[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.DumpLogSegmentsParse a log file and dump its contents to the console, useful for debugging a seemingly corrupt log segment.Option Description ------ ----------- --deep-iteration if set, uses deep instead of shallow iteration --files &lt;file1, file2, ...&gt; REQUIRED: The comma separated list of data and index log files to be dumped--key-decoder-class if set, used to deserialize the keys. This class should implement kafka. serializer.Decoder trait. Custom jar should be available in kafka/libs directory. (default: kafka. serializer.StringDecoder) --max-message-size &lt;Integer: size&gt; Size of largest message. (default: 5242880) --print-data-log if set, printing the messages content when dumping data logs --value-decoder-class if set, used to deserialize the messages. This class should implement kafka.serializer.Decoder trait. Custom jar should be available in kafka/libs directory. (default: kafka.serializer. StringDecoder) --verify-index-only if set, just verify the index log without printing its content &#x5F88;&#x660E;&#x663E;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x4F7F;&#x7528;kafka.tools.DumpLogSegments&#x7684;&#x65F6;&#x5019;&#x5FC5;&#x987B;&#x8F93;&#x5165;&#x2013;files&#xFF0C;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x6307;&#x7684;&#x5C31;&#x662F;Kafka&#x4E2D;Topic&#x5206;&#x533A;&#x6240;&#x5728;&#x7684;&#x7EDD;&#x5BF9;&#x8DEF;&#x5F84;&#x3002;&#x5206;&#x533A;&#x6240;&#x5728;&#x7684;&#x76EE;&#x5F55;&#x7531;config/server.properties&#x6587;&#x4EF6;&#x4E2D;log.dirs&#x53C2;&#x6570;&#x51B3;&#x5B9A;&#x3002;&#x6BD4;&#x5982;&#x6211;&#x4EEC;&#x60F3;&#x770B;/home/q/kafka/kafka_2.10-0.8.2.1/data/test-4/00000000000034245135.log&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x7684;&#x76F8;&#x5173;&#x60C5;&#x51B5;&#x53EF;&#x4EE5; &#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x7684;&#x547D;&#x4EE4;&#xFF1A; 1234567891011121314151617181920[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.DumpLogSegments --files /iteblog/data/test-4/00000000000034245135.logDumping /home/q/kafka/kafka_2.10-0.8.2.1/data/test-4/00000000000034245135.logStarting offset: 34245135offset: 34245135 position: 0 isvalid: true payloadsize: 4213 magic: 0 compresscodec: NoCompressionCodec crc: 865449274 keysize: 4213offset: 34245136 position: 8452 isvalid: true payloadsize: 4657 magic: 0 compresscodec: NoCompressionCodec crc: 4123037760 keysize: 4657offset: 34245137 position: 17792 isvalid: true payloadsize: 3921 magic: 0 compresscodec: NoCompressionCodec crc: 541297511 keysize: 3921offset: 34245138 position: 25660 isvalid: true payloadsize: 2290 magic: 0 compresscodec: NoCompressionCodec crc: 1346104996 keysize: 2290offset: 34245139 position: 30266 isvalid: true payloadsize: 2284 magic: 0 compresscodec: NoCompressionCodec crc: 1930558677 keysize: 2284offset: 34245140 position: 34860 isvalid: true payloadsize: 268 magic: 0 compresscodec: NoCompressionCodec crc: 57847488 keysize: 268offset: 34245141 position: 35422 isvalid: true payloadsize: 263 magic: 0 compresscodec: NoCompressionCodec crc: 2964399224 keysize: 263offset: 34245142 position: 35974 isvalid: true payloadsize: 1875 magic: 0 compresscodec: NoCompressionCodec crc: 647039113 keysize: 1875offset: 34245143 position: 39750 isvalid: true payloadsize: 648 magic: 0 compresscodec: NoCompressionCodec crc: 865445580 keysize: 648offset: 34245144 position: 41072 isvalid: true payloadsize: 556 magic: 0 compresscodec: NoCompressionCodec crc: 1174686061 keysize: 556offset: 34245145 position: 42210 isvalid: true payloadsize: 4211 magic: 0 compresscodec: NoCompressionCodec crc: 3691302513 keysize: 4211offset: 34245146 position: 50658 isvalid: true payloadsize: 2299 magic: 0 compresscodec: NoCompressionCodec crc: 2367114411 keysize: 2299offset: 34245147 position: 55282 isvalid: true payloadsize: 642 magic: 0 compresscodec: NoCompressionCodec crc: 4122061921 keysize: 642offset: 34245148 position: 56592 isvalid: true payloadsize: 4211 magic: 0 compresscodec: NoCompressionCodec crc: 3257991653 keysize: 4211offset: 34245149 position: 65040 isvalid: true payloadsize: 2278 magic: 0 compresscodec: NoCompressionCodec crc: 2103489307 keysize: 2278offset: 34245150 position: 69622 isvalid: true payloadsize: 269 magic: 0 compresscodec: NoCompressionCodec crc: 792857391 keysize: 269offset: 34245151 position: 70186 isvalid: true payloadsize: 640 magic: 0 compresscodec: NoCompressionCodec crc: 791599616 keysize: 640 &#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x8FD9;&#x4E2A;&#x547D;&#x4EE4;&#x5C06;Kafka&#x4E2D;Message&#x4E2D;Header&#x7684;&#x76F8;&#x5173;&#x4FE1;&#x606F;&#x548C;&#x504F;&#x79FB;&#x91CF;&#x90FD;&#x663E;&#x793A;&#x51FA;&#x6765;&#x4E86;&#xFF0C;&#x4F46;&#x662F;&#x6CA1;&#x6709;&#x770B;&#x5230;&#x65E5;&#x5FD7;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x2013;print-data-log&#x6765;&#x8BBE;&#x7F6E;&#x3002;&#x5982;&#x679C;&#x9700;&#x8981;&#x67E5;&#x770B;&#x591A;&#x4E2A;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#xFF0C;&#x53EF;&#x4EE5;&#x4EE5;&#x9017;&#x53F7;&#x5206;&#x5272;&#x3002; &#x5BFC;&#x51FA;Zookeeper&#x4E2D;Group&#x76F8;&#x5173;&#x7684;&#x504F;&#x79FB;&#x91CF;&#x6709;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x5BFC;&#x51FA;&#x67D0;&#x4E2A;Consumer group&#x5404;&#x4E2A;&#x5206;&#x533A;&#x7684;&#x504F;&#x79FB;&#x91CF;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4F7F;&#x7528;Kafka&#x7684;kafka.tools.ExportZkOffsets&#x7C7B;&#x6765;&#x6EE1;&#x8DB3;&#x3002;&#x6765;&#x770B;&#x770B;&#x8FD9;&#x4E2A;&#x7C7B;&#x9700;&#x8981;&#x7684;&#x53C2;&#x6570;&#xFF1A; 123456789[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.ExportZkOffsetsExport consumer offsets to an output file.Option Description ------ ----------- --group Consumer group. --help Print this message. --output-file Output file --zkconnect ZooKeeper connect string. (default: localhost:2181) &#x6211;&#x4EEC;&#x9700;&#x8981;&#x8F93;&#x5165;Consumer group&#xFF0C;Zookeeper&#x7684;&#x5730;&#x5740;&#x4EE5;&#x53CA;&#x4FDD;&#x5B58;&#x6587;&#x4EF6;&#x8DEF;&#x5F84;&#xFF1A; 12345678910[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.ExportZkOffsets --group spark --zkconnect www.iteblog.com:2181 --output-file ~/offset[iteblog@www.iteblog.com /]$ vim ~/offset/consumers/spark/offsets/test/3:34846274/consumers/spark/offsets/test/2:34852378/consumers/spark/offsets/test/1:34852360/consumers/spark/offsets/test/0:34848170/consumers/spark/offsets/test/6:34857010/consumers/spark/offsets/test/5:34854268/consumers/spark/offsets/test/4:34861572 &#x6CE8;&#x610F;&#xFF0C;--output-file&#x53C2;&#x6570;&#x5FC5;&#x987B;&#x5728;&#x6307;&#x5B9A;&#xFF0C;&#x5426;&#x5219;&#x4F1A;&#x51FA;&#x9519;&#x3002; &#x901A;&#x8FC7;JMX&#x83B7;&#x53D6;metrics&#x4FE1;&#x606F;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;kafka.tools.JmxTool&#x7C7B;&#x6253;&#x5370;&#x51FA;Kafka&#x76F8;&#x5173;&#x7684;metrics&#x4FE1;&#x606F;&#x3002; 12345678910111213141516171819202122232425[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.JmxToolDump JMX values to standard output.Option Description ------ ----------- --attributes &lt;name&gt; The whitelist of attributes to query. This is a comma-separated list. If no attributes are specified all objects will be queried. --date-format &lt;format&gt; The date format to use for formatting the time field. See java.text. SimpleDateFormat for options. --help Print usage information. --jmx-url &lt;service-url&gt; The url to connect to to poll JMX data. See Oracle javadoc for JMXServiceURL for details. (default: service:jmx:rmi:///jndi/rmi://: 9999/jmxrmi) --object-name &lt;name&gt; A JMX object name to use as a query. This can contain wild cards, and this option can be given multiple times to specify more than one query. If no objects are specified all objects will be queried. --reporting-interval &lt;Integer: ms&gt; Interval in MS with which to poll jmx stats. (default: 2000) &#x53EF;&#x4EE5;&#x8FD9;&#x4E48;&#x4F7F;&#x7528; 1[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.JmxTool --jmx-url service:jmx:rmi:///jndi/rmi://www.iteblog.com:1099/jmxrmi &#x8FD0;&#x884C;&#x4E0A;&#x9762;&#x547D;&#x4EE4;&#x524D;&#x63D0;&#x662F;&#x5728;&#x542F;&#x52A8;kafka&#x96C6;&#x7FA4;&#x7684;&#x65F6;&#x5019;&#x6307;&#x5B9A;export JMX_PORT=&#xFF0C;&#x8FD9;&#x6837;&#x624D;&#x4F1A;&#x5F00;&#x542F;JMX&#x3002;&#x7136;&#x540E;&#x5C31;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4E0A;&#x9762;&#x547D;&#x4EE4;&#x6253;&#x5370;&#x51FA;Kafka&#x6240;&#x6709;&#x7684;metrics&#x4FE1;&#x606F;&#x3002; Kafka&#x6570;&#x636E;&#x8FC1;&#x79FB;&#x5DE5;&#x5177;&#x8FD9;&#x4E2A;&#x5DE5;&#x5177;&#x4E3B;&#x8981;&#x6709;&#x4E24;&#x4E2A;&#xFF1A;kafka.tools.KafkaMigrationTool&#x548C;kafka.tools.MirrorMaker&#x3002;&#x7B2C;&#x4E00;&#x4E2A;&#x4E3B;&#x8981;&#x662F;&#x7528;&#x4E8E;&#x5C06;Kafka 0.7&#x4E0A;&#x9762;&#x7684;&#x6570;&#x636E;&#x8FC1;&#x79FB;&#x5230;Kafka 0.8&#xFF08;https://cwiki.apache.org/confluence/display/KAFKA/Migrating+from+0.7+to+0.8&#xFF09;&#xFF1B;&#x800C;&#x540E;&#x8005;&#x53EF;&#x4EE5;&#x540C;&#x6B65;&#x4E24;&#x4E2A;Kafka&#x96C6;&#x7FA4;&#x7684;&#x6570;&#x636E;&#xFF08;https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330&#xFF09;&#x3002;&#x90FD;&#x662F;&#x4ECE;&#x539F;&#x7AEF;&#x6D88;&#x8D39;Messages&#xFF0C;&#x7136;&#x540E;&#x53D1;&#x5E03;&#x5230;&#x76EE;&#x6807;&#x7AEF;&#x3002; 123[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.KafkaMigrationTool --kafka.07.jar kafka-0.7.19.jar --zkclient.01.jar zkclient-0.2.0.jar --num.producers 16 --consumer.config=sourceCluster2Consumer.config --producer.config=targetClusterProducer.config --whitelist=.*[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.MirrorMaker --consumer.config sourceCluster1Consumer.config --consumer.config sourceCluster2Consumer.config --num.streams 2 --producer.config targetClusterProducer.config --whitelist=&quot;.*&quot; &#x65E5;&#x5FD7;&#x91CD;&#x653E;&#x5DE5;&#x5177;&#x8FD9;&#x4E2A;&#x5DE5;&#x5177;&#x4E3B;&#x8981;&#x4F5C;&#x7528;&#x662F;&#x4ECE;&#x4E00;&#x4E2A;Kafka&#x96C6;&#x7FA4;&#x91CC;&#x9762;&#x8BFB;&#x53D6;&#x6307;&#x5B9A;Topic&#x7684;&#x6D88;&#x606F;&#xFF0C;&#x5E76;&#x5C06;&#x8FD9;&#x4E9B;&#x6D88;&#x606F;&#x53D1;&#x9001;&#x5230;&#x5176;&#x4ED6;&#x96C6;&#x7FA4;&#x7684;&#x6307;&#x5B9A;topic&#x4E2D;&#xFF1A; 123456789101112131415161718192021[iteblog@www.iteblog.com /]$ bin/kafka-replay-log-producer.shMissing required argument &quot;[broker-list]&quot;Option Description ------ ----------- --broker-list &lt;hostname:port&gt; REQUIRED: the broker list must be specified.--inputtopic &lt;input-topic&gt; REQUIRED: The topic to consume from. --messages &lt;Integer: count&gt; The number of messages to send. (default: -1)--outputtopic &lt;output-topic&gt; REQUIRED: The topic to produce to --property &lt;producer properties&gt; A mechanism to pass properties in the form key=value to the producer. This allows the user to override producer properties that are not exposed by the existing command line arguments --reporting-interval &lt;Integer: size&gt; Interval at which to print progress info. (default: 5000) --sync If set message send requests to the brokers are synchronously, one at a time as they arrive. --threads &lt;Integer: threads&gt; Number of sending threads. (default: 1)--zookeeper &lt;zookeeper url&gt; REQUIRED: The connection string for the zookeeper connection in the form host:port. Multiple URLS can be given to allow fail-over. (default: 127.0.0.1:2181) Simple Consume&#x811A;&#x672C;kafka-simple-consumer-shell.sh&#x5DE5;&#x5177;&#x4E3B;&#x8981;&#x662F;&#x4F7F;&#x7528;Simple Consumer API&#x4ECE;&#x6307;&#x5B9A;Topic&#x7684;&#x5206;&#x533A;&#x8BFB;&#x53D6;&#x6570;&#x636E;&#x5E76;&#x6253;&#x5370;&#x5728;&#x7EC8;&#x7AEF;&#xFF1A; 1bin/kafka-simple-consumer-shell.sh --broker-list www.iteblog.com:9092 --topic test --partition 0 &#x66F4;&#x65B0;Zookeeper&#x4E2D;&#x7684;&#x504F;&#x79FB;&#x91CF;kafka.tools.UpdateOffsetsInZK&#x5DE5;&#x5177;&#x53EF;&#x4EE5;&#x66F4;&#x65B0;Zookeeper&#x4E2D;&#x6307;&#x5B9A;Topic&#x6240;&#x6709;&#x5206;&#x533A;&#x7684;&#x504F;&#x79FB;&#x91CF;&#xFF0C;&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x6210; earliest&#x6216;&#x8005;latest&#xFF1A; 12[iteblog@www.iteblog.com /]$ bin/kafka-run-class.sh kafka.tools.UpdateOffsetsInZKUSAGE: kafka.tools.UpdateOffsetsInZK$ [earliest | latest] consumer.properties topic &#x9700;&#x8981;&#x6307;&#x5B9A;&#x662F;&#x66F4;&#x65B0;&#x6210;earliest&#x6216;&#x8005;latest&#xFF0C;consumer.properties&#x6587;&#x4EF6;&#x7684;&#x8DEF;&#x5F84;&#x4EE5;&#x53CA;topic&#x7684;&#x540D;&#x79F0; &#x53C2;&#x8003; kafka: System Tools kafka: Replication tools kafka&#x7BA1;&#x7406;&#x5DE5;&#x5177;&#x4ECB;&#x7ECD;","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://wzktravel.github.io/tags/kafka/"}]},{"title":"Oozie中添加sqoop用到的jdbc包","slug":"oozie-sqoop","date":"2016-11-17T07:26:34.000Z","updated":"2016-11-21T04:07:47.000Z","comments":true,"path":"2016/11/17/oozie-sqoop/","link":"","permalink":"http://wzktravel.github.io/2016/11/17/oozie-sqoop/","excerpt":"","text":"CDH5&#x4E2D;&#xFF0C;&#x5728;oozie&#x4E2D;&#x6267;&#x884C;sqoop&#x547D;&#x4EE4;&#x65F6;&#xFF0C;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x624B;&#x52A8;&#x6DFB;&#x52A0;&#x4E00;&#x4E9B;jdbc&#x5305;&#x3002; &#x5C06;jar&#x5305;&#x653E;&#x7F6E;&#x5230;hdfs&#x4E2D;lib&#x76EE;&#x5F55; 1/user/oozie/share/lib/lib_${timestamp}/sqoop &#x7136;&#x540E;&#x4F7F;&#x7528;oozie&#x7684;sharelibupdate&#x547D;&#x4EE4;&#x66F4;&#x65B0; 123456$ oozie admin -oozie http://192.168.0.100:11000/oozie -sharelibupdate[ShareLib update status] sharelibDirOld = hdfs://nameservice/user/oozie/share/lib/lib_20160801151935 host = http://192.168.0.100:11000/oozie sharelibDirNew = hdfs://nameservice/user/oozie/share/lib/lib_20160801151935 status = Successful &#x53C2;&#x8003; cloudera: How-to: Use the ShareLib in Apache Oozie (CDH 5) Oozie: Command Line Interface Utilities StackOverflow: Oozie + Sqoop: JDBC Driver Jar Location","categories":[],"tags":[{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"}]},{"title":"Linux iostat监测IO状态","slug":"iostat","date":"2016-11-17T02:02:23.000Z","updated":"2016-11-17T03:06:04.000Z","comments":true,"path":"2016/11/17/iostat/","link":"","permalink":"http://wzktravel.github.io/2016/11/17/iostat/","excerpt":"Linux系统出现了性能问题，一般我们可以通过top、iostat、free、vmstat等命令来查看初步定位问题。其中iostat可以给我们提供丰富的IO状态数据。 常见用法：123$iostat -d -k 1 10 #查看TPS和吞吐量信息iostat -d -x -k 1 10 #查看设备使用率（%util）、响应时间（await）iostat -c 1 10 #查看cpu状态","text":"Linux&#x7CFB;&#x7EDF;&#x51FA;&#x73B0;&#x4E86;&#x6027;&#x80FD;&#x95EE;&#x9898;&#xFF0C;&#x4E00;&#x822C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;top&#x3001;iostat&#x3001;free&#x3001;vmstat&#x7B49;&#x547D;&#x4EE4;&#x6765;&#x67E5;&#x770B;&#x521D;&#x6B65;&#x5B9A;&#x4F4D;&#x95EE;&#x9898;&#x3002;&#x5176;&#x4E2D;iostat&#x53EF;&#x4EE5;&#x7ED9;&#x6211;&#x4EEC;&#x63D0;&#x4F9B;&#x4E30;&#x5BCC;&#x7684;IO&#x72B6;&#x6001;&#x6570;&#x636E;&#x3002; &#x5E38;&#x89C1;&#x7528;&#x6CD5;&#xFF1A;123$iostat -d -k 1 10 #&#x67E5;&#x770B;TPS&#x548C;&#x541E;&#x5410;&#x91CF;&#x4FE1;&#x606F;iostat -d -x -k 1 10 #&#x67E5;&#x770B;&#x8BBE;&#x5907;&#x4F7F;&#x7528;&#x7387;&#xFF08;%util&#xFF09;&#x3001;&#x54CD;&#x5E94;&#x65F6;&#x95F4;&#xFF08;await&#xFF09;iostat -c 1 10 #&#x67E5;&#x770B;cpu&#x72B6;&#x6001; &#x5B89;&#x88C5;iostat&#x5305;&#x542B;&#x5728;sysstat&#x5305;&#x4E2D; 1yum install -y sysstat &#x4F7F;&#x7528; &#x57FA;&#x672C;&#x4F7F;&#x7528; 1$iostat -d -k 1 10 &#x53C2;&#x6570; -d &#x8868;&#x793A;&#xFF0C;&#x663E;&#x793A;&#x8BBE;&#x5907;&#xFF08;&#x78C1;&#x76D8;&#xFF09;&#x4F7F;&#x7528;&#x72B6;&#x6001;&#xFF1B;-k&#x67D0;&#x4E9B;&#x4F7F;&#x7528;block&#x4E3A;&#x5355;&#x4F4D;&#x7684;&#x5217;&#x5F3A;&#x5236;&#x4F7F;&#x7528;Kilobytes&#x4E3A;&#x5355;&#x4F4D;&#xFF1B;1 10&#x8868;&#x793A;&#xFF0C;&#x6570;&#x636E;&#x663E;&#x793A;&#x6BCF;&#x9694;1&#x79D2;&#x5237;&#x65B0;&#x4E00;&#x6B21;&#xFF0C;&#x5171;&#x663E;&#x793A;10&#x6B21;&#x3002; 12345678910111213141516$iostat -d -k 1 10Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 39.29 21.14 1.44 441339807 29990031sda1 0.00 0.00 0.00 1623 523sda2 1.32 1.43 4.54 29834273 94827104sda3 6.30 0.85 24.95 17816289 520725244sda5 0.85 0.46 3.40 9543503 70970116sda6 0.00 0.00 0.00 550 236sda7 0.00 0.00 0.00 406 0sda8 0.00 0.00 0.00 406 0sda9 0.00 0.00 0.00 406 0sda10 60.68 18.35 71.43 383002263 1490928140Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 327.55 5159.18 102.04 5056 100sda1 0.00 0.00 0.00 0 0 tps&#xFF1A;&#x8BE5;&#x8BBE;&#x5907;&#x6BCF;&#x79D2;&#x7684;&#x4F20;&#x8F93;&#x6B21;&#x6570;&#xFF08;Indicate the number of transfers per second that were issued to the device.&#xFF09;&#x3002;&#x201C;&#x4E00;&#x6B21;&#x4F20;&#x8F93;&#x201D;&#x610F;&#x601D;&#x662F;&#x201C;&#x4E00;&#x6B21;I/O&#x8BF7;&#x6C42;&#x201D;&#x3002;&#x591A;&#x4E2A;&#x903B;&#x8F91;&#x8BF7;&#x6C42;&#x53EF;&#x80FD;&#x4F1A;&#x88AB;&#x5408;&#x5E76;&#x4E3A;&#x201C;&#x4E00;&#x6B21;I/O&#x8BF7;&#x6C42;&#x201D;&#x3002;&#x201C;&#x4E00;&#x6B21;&#x4F20;&#x8F93;&#x201D;&#x8BF7;&#x6C42;&#x7684;&#x5927;&#x5C0F;&#x662F;&#x672A;&#x77E5;&#x7684;&#x3002; kB_read/s&#xFF1A;&#x6BCF;&#x79D2;&#x4ECE;&#x8BBE;&#x5907;&#xFF08;drive expressed&#xFF09;&#x8BFB;&#x53D6;&#x7684;&#x6570;&#x636E;&#x91CF;&#xFF1B; kB_wrtn/s&#xFF1A;&#x6BCF;&#x79D2;&#x5411;&#x8BBE;&#x5907;&#xFF08;drive expressed&#xFF09;&#x5199;&#x5165;&#x7684;&#x6570;&#x636E;&#x91CF;&#xFF1B; kB_read&#xFF1A;&#x8BFB;&#x53D6;&#x7684;&#x603B;&#x6570;&#x636E;&#x91CF;&#xFF1B; kB_wrtn&#xFF1A;&#x5199;&#x5165;&#x7684;&#x603B;&#x6570;&#x91CF;&#x6570;&#x636E;&#x91CF;&#xFF1B;&#x8FD9;&#x4E9B;&#x5355;&#x4F4D;&#x90FD;&#x4E3A;Kilobytes&#x3002; &#x4E0A;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x78C1;&#x76D8;sda&#x4EE5;&#x53CA;&#x5B83;&#x7684;&#x5404;&#x4E2A;&#x5206;&#x533A;&#x7684;&#x7EDF;&#x8BA1;&#x6570;&#x636E;&#xFF0C;&#x5F53;&#x65F6;&#x7EDF;&#x8BA1;&#x7684;&#x78C1;&#x76D8;&#x603B;TPS&#x662F;39.29&#xFF0C;&#x4E0B;&#x9762;&#x662F;&#x5404;&#x4E2A;&#x5206;&#x533A;&#x7684;TPS&#x3002;&#xFF08;&#x56E0;&#x4E3A;&#x662F;&#x77AC;&#x95F4;&#x503C;&#xFF0C;&#x6240;&#x4EE5;&#x603B;TPS&#x5E76;&#x4E0D;&#x4E25;&#x683C;&#x7B49;&#x4E8E;&#x5404;&#x4E2A;&#x5206;&#x533A;TPS&#x7684;&#x603B;&#x548C;&#xFF09; -x &#x53C2;&#x6570; &#x4F7F;&#x7528;-x&#x53C2;&#x6570;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x83B7;&#x5F97;&#x66F4;&#x591A;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;&#x3002; 12345$iostat -d -x -k 1 10Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 1.56 28.31 7.80 31.49 42.51 2.92 21.26 1.46 1.16 0.03 0.79 2.62 10.28Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 2.00 20.00 381.00 7.00 12320.00 216.00 6160.00 108.00 32.31 1.75 4.50 2.17 84.20 rrqm/s&#xFF1A;&#x6BCF;&#x79D2;&#x8FD9;&#x4E2A;&#x8BBE;&#x5907;&#x76F8;&#x5173;&#x7684;&#x8BFB;&#x53D6;&#x8BF7;&#x6C42;&#x6709;&#x591A;&#x5C11;&#x88AB;Merge&#x4E86;&#xFF08;&#x5F53;&#x7CFB;&#x7EDF;&#x8C03;&#x7528;&#x9700;&#x8981;&#x8BFB;&#x53D6;&#x6570;&#x636E;&#x7684;&#x65F6;&#x5019;&#xFF0C;VFS&#x5C06;&#x8BF7;&#x6C42;&#x53D1;&#x5230;&#x5404;&#x4E2A;FS&#xFF0C;&#x5982;&#x679C;FS&#x53D1;&#x73B0;&#x4E0D;&#x540C;&#x7684;&#x8BFB;&#x53D6;&#x8BF7;&#x6C42;&#x8BFB;&#x53D6;&#x7684;&#x662F;&#x76F8;&#x540C;Block&#x7684;&#x6570;&#x636E;&#xFF0C;FS&#x4F1A;&#x5C06;&#x8FD9;&#x4E2A;&#x8BF7;&#x6C42;&#x5408;&#x5E76;Merge&#xFF09;&#xFF1B;wrqm/s&#xFF1A;&#x6BCF;&#x79D2;&#x8FD9;&#x4E2A;&#x8BBE;&#x5907;&#x76F8;&#x5173;&#x7684;&#x5199;&#x5165;&#x8BF7;&#x6C42;&#x6709;&#x591A;&#x5C11;&#x88AB;Merge&#x4E86;&#x3002; rsec/s&#xFF1A;&#x6BCF;&#x79D2;&#x8BFB;&#x53D6;&#x7684;&#x6247;&#x533A;&#x6570;&#xFF1B;wsec/s&#xFF1A;&#x6BCF;&#x79D2;&#x5199;&#x5165;&#x7684;&#x6247;&#x533A;&#x6570;&#x3002; r/s&#xFF1A;The number of read requests that were issued to the device per second&#xFF1B;w/s&#xFF1A;The number of write requests that were issued to the device per second&#xFF1B; await&#xFF1A;&#x6BCF;&#x4E00;&#x4E2A;IO&#x8BF7;&#x6C42;&#x7684;&#x5904;&#x7406;&#x7684;&#x5E73;&#x5747;&#x65F6;&#x95F4;&#xFF08;&#x5355;&#x4F4D;&#x662F;&#x5FAE;&#x79D2;&#x6BEB;&#x79D2;&#xFF09;&#x3002;&#x8FD9;&#x91CC;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x4E3A;IO&#x7684;&#x54CD;&#x5E94;&#x65F6;&#x95F4;&#xFF0C;&#x4E00;&#x822C;&#x5730;&#x7CFB;&#x7EDF;IO&#x54CD;&#x5E94;&#x65F6;&#x95F4;&#x5E94;&#x8BE5;&#x4F4E;&#x4E8E;5ms&#xFF0C;&#x5982;&#x679C;&#x5927;&#x4E8E;10ms&#x5C31;&#x6BD4;&#x8F83;&#x5927;&#x4E86;&#x3002; %util&#xFF1A;&#x5728;&#x7EDF;&#x8BA1;&#x65F6;&#x95F4;&#x5185;&#x6240;&#x6709;&#x5904;&#x7406;IO&#x65F6;&#x95F4;&#xFF0C;&#x9664;&#x4EE5;&#x603B;&#x5171;&#x7EDF;&#x8BA1;&#x65F6;&#x95F4;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5982;&#x679C;&#x7EDF;&#x8BA1;&#x95F4;&#x9694;1&#x79D2;&#xFF0C;&#x8BE5;&#x8BBE;&#x5907;&#x6709;0.8&#x79D2;&#x5728;&#x5904;&#x7406;IO&#xFF0C;&#x800C;0.2&#x79D2;&#x95F2;&#x7F6E;&#xFF0C;&#x90A3;&#x4E48;&#x8BE5;&#x8BBE;&#x5907;&#x7684;%util = 0.8/1 = 80%&#xFF0C;&#x6240;&#x4EE5;&#x8BE5;&#x53C2;&#x6570;&#x6697;&#x793A;&#x4E86;&#x8BBE;&#x5907;&#x7684;&#x7E41;&#x5FD9;&#x7A0B;&#x5EA6;&#x3002;&#x4E00;&#x822C;&#x5730;&#xFF0C;&#x5982;&#x679C;&#x8BE5;&#x53C2;&#x6570;&#x662F;100%&#x8868;&#x793A;&#x8BBE;&#x5907;&#x5DF2;&#x7ECF;&#x63A5;&#x8FD1;&#x6EE1;&#x8D1F;&#x8377;&#x8FD0;&#x884C;&#x4E86;&#xFF08;&#x5F53;&#x7136;&#x5982;&#x679C;&#x662F;&#x591A;&#x78C1;&#x76D8;&#xFF0C;&#x5373;&#x4F7F;%util&#x662F;100%&#xFF0C;&#x56E0;&#x4E3A;&#x78C1;&#x76D8;&#x7684;&#x5E76;&#x53D1;&#x80FD;&#x529B;&#xFF0C;&#x6240;&#x4EE5;&#x78C1;&#x76D8;&#x4F7F;&#x7528;&#x672A;&#x5FC5;&#x5C31;&#x5230;&#x4E86;&#x74F6;&#x9888;&#xFF09;&#x3002; -c &#x53C2;&#x6570; iostat&#x8FD8;&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x83B7;&#x53D6;cpu&#x90E8;&#x5206;&#x72B6;&#x6001;&#x503C;&#x3002; 12345$iostat -c 1 10avg-cpu: %user %nice %sys %iowait %idle 1.98 0.00 0.35 11.45 86.22avg-cpu: %user %nice %sys %iowait %idle 1.62 0.00 0.25 34.46 63.67 &#x5B9E;&#x4F8B;&#x5206;&#x6790; 12345678$iostat -d -k 1 |grep sda10Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda10 60.72 18.95 71.53 395637647 1493241908sda10 299.02 4266.67 129.41 4352 132sda10 483.84 4589.90 4117.17 4544 4076sda10 218.00 3360.00 100.00 3360 100sda10 546.00 8784.00 124.00 8784 124sda10 827.00 13232.00 136.00 13232 136 &#x4E0A;&#x9762;&#x770B;&#x5230;&#xFF0C;&#x78C1;&#x76D8;&#x6BCF;&#x79D2;&#x4F20;&#x8F93;&#x6B21;&#x6570;&#x5E73;&#x5747;&#x7EA6;400&#xFF1B;&#x6BCF;&#x79D2;&#x78C1;&#x76D8;&#x8BFB;&#x53D6;&#x7EA6;5MB&#xFF0C;&#x5199;&#x5165;&#x7EA6;1MB&#x3002; 12345iostat -d -x -k 1Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %utilsda 1.56 28.31 7.84 31.50 43.65 3.16 21.82 1.58 1.19 0.03 0.80 2.61 10.29sda 1.98 24.75 419.80 6.93 13465.35 253.47 6732.67 126.73 32.15 2.00 4.70 2.00 85.25sda 3.06 41.84 444.90 54.08 14204.08 2048.98 7102.04 1024.49 32.57 2.10 4.21 1.85 92.24 &#x53EF;&#x4EE5;&#x770B;&#x5230;&#x78C1;&#x76D8;&#x7684;&#x5E73;&#x5747;&#x54CD;&#x5E94;&#x65F6;&#x95F4;80&#x3002;&#x78C1;&#x76D8;&#x54CD;&#x5E94;&#x6B63;&#x5E38;&#xFF0C;&#x4F46;&#x662F;&#x5DF2;&#x7ECF;&#x5F88;&#x7E41;&#x5FD9;&#x4E86;&#x3002; &#x8F6C;&#x8F7D;&#x81EA;http://www.orczhou.com/index.php/2010/03/iostat-detail/","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"读取jar包中文件","slug":"read-file-in-jar","date":"2016-11-06T03:51:55.000Z","updated":"2016-11-07T10:44:23.000Z","comments":true,"path":"2016/11/06/read-file-in-jar/","link":"","permalink":"http://wzktravel.github.io/2016/11/06/read-file-in-jar/","excerpt":"","text":"&#x63D0;&#x4F9B;jar&#x7ED9;&#x5916;&#x754C;&#x4F7F;&#x7528;&#x65F6;&#xFF0C;&#x7ECF;&#x5E38;&#x4F1A;&#x8BFB;&#x53D6;&#x81EA;&#x8EAB;&#x7684;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x7B49;&#x3002;&#x8FD9;&#x4E9B;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x5728;&#x6253;&#x5305;&#x540E;&#x5DF2;&#x7ECF;&#x5728;jar&#x4E2D;&#x4E86;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x80FD;&#x4F7F;&#x7528;&#x666E;&#x901A;&#x7684;&#x8BFB;&#x53D6;&#x6587;&#x4EF6;&#x65B9;&#x5F0F;&#x8BFB;&#x53D6;&#xFF0C;&#x53EA;&#x80FD;&#x4EE5;ClassLoader&#x7684;&#x65B9;&#x5F0F;&#x8BFB;&#x53D6;&#x4E8C;&#x8FDB;&#x5236;&#x6587;&#x4EF6;&#x3002; 123456789101112public static BufferedReader getReader(String name) { try { InputStream in = DicReader.class.getResourceAsStream(&quot;/&quot; + name); if (in != null) { return new BufferedReader(new InputStreamReader(in, &quot;UTF-8&quot;)); } } catch (UnsupportedEncodingException e) { log.error(&quot;Cannot create BufferedReader for {}&quot;, name, e); } log.error(&quot;Cannot read dic: {} &quot;, name); return null;}","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"}]},{"title":"kafka主动下线broker","slug":"shudown-kafka-broker","date":"2016-10-26T11:56:42.000Z","updated":"2017-01-17T03:46:47.000Z","comments":true,"path":"2016/10/26/shudown-kafka-broker/","link":"","permalink":"http://wzktravel.github.io/2016/10/26/shudown-kafka-broker/","excerpt":"","text":"&#x4E3B;&#x52A8;&#x4E0B;&#x7EBF;&#x662F;&#x6307;broker&#x8FD0;&#x884C;&#x6B63;&#x5E38;&#xFF0C;&#x56E0;&#x4E3A;&#x673A;&#x5668;&#x9700;&#x8981;&#x8FD0;&#x7EF4;&#xFF08;&#x5347;&#x7EA7;&#x64CD;&#x4F5C;&#x7CFB;&#x7EDF;&#xFF0C;&#x6DFB;&#x52A0;&#x78C1;&#x76D8;&#x7B49;&#xFF09;&#x800C;&#x4E3B;&#x52A8;&#x505C;&#x6B62;broker&#x3002; &#x5206;&#x4E24;&#x79CD;&#x60C5;&#x51B5;&#x5904;&#x7406;&#xFF1A; &#x6B64;broker&#x4E0A;&#x6240;&#x6709;&#x7684;topic&#x7684;replica &gt;= 2&#x6B64;&#x65F6;&#xFF0C;&#x76F4;&#x63A5;&#x505C;&#x6B62;&#x4E00;&#x4E2A;broker&#xFF0C;&#x4F1A;&#x81EA;&#x52A8;&#x89E6;&#x53D1;leader election&#x64CD;&#x4F5C;&#xFF0C;&#x4E0D;&#x8FC7;&#x76EE;&#x524D;leader election&#x662F;&#x9010;&#x4E2A;partition&#x8FDB;&#x884C;&#xFF0C;&#x7B49;&#x5F85;&#x6240;&#x6709;partition&#x5B8C;&#x6210;leader election&#x8017;&#x65F6;&#x8F83;&#x957F;&#xFF0C;&#x8FD9;&#x6837;&#x4E0D;&#x53EF;&#x670D;&#x52A1;&#x7684;&#x65F6;&#x95F4;&#x5C31;&#x6BD4;&#x8F83;&#x957F;&#x3002;&#x4E3A;&#x4E86;&#x7F29;&#x77ED;&#x4E0D;&#x53EF;&#x670D;&#x52A1;&#x65F6;&#x95F4;&#x7A97;&#x53E3;&#xFF0C;&#x53EF;&#x4EE5;&#x4E3B;&#x52A8;&#x89E6;&#x53D1;&#x505C;&#x6B62;broker&#x64CD;&#x4F5C;&#xFF0C;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x9010;&#x4E2A;partition&#x8F6C;&#x79FB;&#xFF0C;&#x76F4;&#x5230;&#x6240;&#x6709;partition&#x5B8C;&#x6210;&#x8F6C;&#x79FB;&#xFF0C;&#x518D;&#x505C;&#x6B62;broker&#x3002; 1$ bin/kafka-run-class.sh kafka.admin.ShutdownBroker --zookeeper 192.168.2.225:2181 --broker ${brokerId} --num.retries 3 --retry.interval.ms 60 &#x7136;&#x540E;shutdown broker 1$ bin/kafka-server-stop.sh &#x6B64;broker&#x4E0A;&#x5B58;&#x5728;topic&#x7684;replica=1&#x5F53;&#x5B58;&#x5728;topic&#x7684;&#x526F;&#x672C;&#x6570;&#x5C0F;&#x4E8E;2&#xFF0C;&#x53EA;&#x80FD;&#x624B;&#x5DE5;&#x628A;&#x5F53;&#x524D;broker&#x4E0A;&#x8FD9;&#x4E9B;topic&#x5BF9;&#x5E94;&#x7684;partition&#x8F6C;&#x79FB;&#x5230;&#x5176;&#x4ED6;broker&#x4E0A;&#x3002;&#x5F53;&#x6B64;broker&#x4E0A;&#x5269;&#x4F59;&#x7684;topic&#x7684;replica &gt; 2&#x65F6;&#xFF0C;&#x53C2;&#x7167;&#x4E0A;&#x9762;&#x7684;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#x7EE7;&#x7EED;&#x5904;&#x7406;&#x3002;&#x5BF9;kafka&#x8FDB;&#x884C;reassign&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;http://wzktravel.github.io/2015/12/31/kafka-reassign/&#x3002; &#x53C2;&#x8003; http://blog.csdn.net/damacheng/article/details/42393859","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://wzktravel.github.io/tags/kafka/"}]},{"title":"Spark jobserver的安装和使用","slug":"spark-job-server","date":"2016-10-26T02:12:41.000Z","updated":"2016-10-26T02:55:17.000Z","comments":true,"path":"2016/10/26/spark-job-server/","link":"","permalink":"http://wzktravel.github.io/2016/10/26/spark-job-server/","excerpt":"Spark-jobserver 提供了一个 RESTful 接口来提交和管理 spark 的 jobs、jars 和 job contexts。在原项目基础上做了一些本地化和优化工作。 将spark-jobserver中akka版本降级到CDH5.7中akka版本。 spark-jobserver中joda-time版本(2.9.3)与CDH5.7中joda-time版本(1.6)版本冲突，运行时会出现java.lang.NoSuchMethodError: org.joda.time.DateTime.now()异常，将spark-jobserver中joda-time版本降级到1.6。 添加使用mysql作为数据库。 修复提交job后无法查看job信息和结果的问题，参见github issue#516。","text":"Spark-jobserver &#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x4E2A; RESTful &#x63A5;&#x53E3;&#x6765;&#x63D0;&#x4EA4;&#x548C;&#x7BA1;&#x7406; spark &#x7684; jobs&#x3001;jars &#x548C; job contexts&#x3002;&#x5728;&#x539F;&#x9879;&#x76EE;&#x57FA;&#x7840;&#x4E0A;&#x505A;&#x4E86;&#x4E00;&#x4E9B;&#x672C;&#x5730;&#x5316;&#x548C;&#x4F18;&#x5316;&#x5DE5;&#x4F5C;&#x3002; &#x5C06;spark-jobserver&#x4E2D;akka&#x7248;&#x672C;&#x964D;&#x7EA7;&#x5230;CDH5.7&#x4E2D;akka&#x7248;&#x672C;&#x3002; spark-jobserver&#x4E2D;joda-time&#x7248;&#x672C;(2.9.3)&#x4E0E;CDH5.7&#x4E2D;joda-time&#x7248;&#x672C;(1.6)&#x7248;&#x672C;&#x51B2;&#x7A81;&#xFF0C;&#x8FD0;&#x884C;&#x65F6;&#x4F1A;&#x51FA;&#x73B0;java.lang.NoSuchMethodError: org.joda.time.DateTime.now()&#x5F02;&#x5E38;&#xFF0C;&#x5C06;spark-jobserver&#x4E2D;joda-time&#x7248;&#x672C;&#x964D;&#x7EA7;&#x5230;1.6&#x3002; &#x6DFB;&#x52A0;&#x4F7F;&#x7528;mysql&#x4F5C;&#x4E3A;&#x6570;&#x636E;&#x5E93;&#x3002; &#x4FEE;&#x590D;&#x63D0;&#x4EA4;job&#x540E;&#x65E0;&#x6CD5;&#x67E5;&#x770B;job&#x4FE1;&#x606F;&#x548C;&#x7ED3;&#x679C;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x53C2;&#x89C1;github issue#516&#x3002; &#x4ECB;&#x7ECD;git&#x5730;&#x5740; github&#x5730;&#x5740;: https://github.com/spark-jobserver/spark-jobserver &#x6DFB;&#x52A0;cdh&#x652F;&#x6301;github&#x5730;&#x5740;: https://github.com/bjoernlohrmann/spark-jobserver &#x4F18;&#x5316;&#x540E;&#x7684;github&#x5730;&#x5740;: https://github.com/wzktravel/spark-jobserver &#x7279;&#x6027; &#x201C;Spark as Service&#x201D;&#xFF1A;&#x9488;&#x5BF9; job &#x548C; contexts &#x7684;&#x5404;&#x4E2A;&#x65B9;&#x9762;&#x63D0;&#x4F9B;&#x4E86; REST &#x98CE;&#x683C;&#x7684; api &#x63A5;&#x53E3;&#x8FDB;&#x884C;&#x7BA1;&#x7406; &#x652F;&#x6301; SparkSQL&#x3001;Hive&#x3001;Streaming Contexts/jobs &#x4EE5;&#x53CA;&#x5B9A;&#x5236; job contexts&#xFF01;&#x5177;&#x4F53;&#x53C2;&#x8003;Contexts &#x901A;&#x8FC7;&#x96C6;&#x6210; Apache Shiro &#x6765;&#x652F;&#x6301; LDAP &#x6743;&#x9650;&#x9A8C;&#x8BC1; &#x901A;&#x8FC7;&#x957F;&#x671F;&#x8FD0;&#x884C;&#x7684;job contexts&#x652F;&#x6301;&#x4E9A;&#x79D2;&#x7EA7;&#x522B;&#x4F4E;&#x5EF6;&#x8FDF;&#x7684;&#x4EFB;&#x52A1; &#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7ED3;&#x675F; context &#x6765;&#x505C;&#x6B62;&#x8FD0;&#x884C;&#x7684;&#x4F5C;&#x4E1A;(job) &#x5206;&#x5272; jar &#x4E0A;&#x4F20;&#x6B65;&#x9AA4;&#x4EE5;&#x63D0;&#x9AD8; job &#x7684;&#x542F;&#x52A8; &#x5F02;&#x6B65;&#x548C;&#x540C;&#x6B65;&#x7684; job API&#xFF0C;&#x5176;&#x4E2D;&#x540C;&#x6B65; API &#x5BF9;&#x4F4E;&#x5EF6;&#x65F6;&#x4F5C;&#x4E1A;&#x975E;&#x5E38;&#x6709;&#x6548; &#x652F;&#x6301; Standalone Spark &#x548C; Mesos&#x3001;yarn Job &#x548C; jar &#x4FE1;&#x606F;&#x901A;&#x8FC7;&#x4E00;&#x4E2A;&#x53EF;&#x63D2;&#x62D4;&#x7684; DAO &#x63A5;&#x53E3;&#x6765;&#x6301;&#x4E45;&#x5316; &#x5BF9;RDD&#x6216;DataFrame&#x5BF9;&#x8C61;&#x547D;&#x540D;&#x5E76;&#x7F13;&#x5B58;&#xFF0C;&#x901A;&#x8FC7;&#x8BE5;&#x540D;&#x79F0;&#x83B7;&#x53D6;RDD&#x6216;DataFrame&#x3002;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x63D0;&#x9AD8;&#x5BF9;&#x8C61;&#x5728;&#x4F5C;&#x4E1A;&#x95F4;&#x7684;&#x5171;&#x4EAB;&#x548C;&#x91CD;&#x7528; &#x652F;&#x6301; Scala 2.10 &#x7248;&#x672C;&#x548C; 2.11 &#x7248;&#x672C; &#x5B89;&#x88C5;&#x53C2;&#x8003;https://github.com/spark-jobserver/spark-jobserver#deployment &#x914D;&#x7F6E;&#x548C;&#x5B89;&#x88C5;&#x8BBE;&#x5B9A;&#x914D;&#x7F6E;&#x7684;&#x73AF;&#x5883;&#x662F;firstshare&#x3002; &#x590D;&#x5236;conf&#x76EE;&#x5F55;&#x4E0B;local.sh.template&#x4E3A;firstshare.sh&#xFF0C;&#x6839;&#x636E;&#x5B9E;&#x9645;&#x60C5;&#x51B5;&#x4FEE;&#x6539;&#x91CC;&#x9762;&#x5185;&#x5BB9;&#x3002;&#x5176;&#x4E2D;DEPLOY_HOSTS&#x662F;&#x8981;&#x5C06;&#x670D;&#x52A1;&#x90E8;&#x7F72;&#x5230;&#x54EA;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#xFF0C;APP_USER&#x548C;APP_GROUP&#x662F;&#x670D;&#x52A1;&#x6587;&#x4EF6;&#x7684;&#x6240;&#x6709;&#x8005;&#x548C;&#x6240;&#x5728;&#x7EC4;&#x3002; &#x590D;&#x5236;conf&#x76EE;&#x5F55;&#x4E0B;local.conf.template&#x4E3A;firstshare.conf&#xFF0C;&#x6839;&#x636E;&#x9700;&#x8981;&#x4FEE;&#x6539;&#x3002; &#x9644;&#x4E0A;&#x90E8;&#x5206;&#x914D;&#x7F6E;&#xFF0C;&#x4E3B;&#x8981;&#x4FEE;&#x6539;&#x4E86;&#x4EE5;&#x4E0B;&#x5185;&#x5BB9;&#xFF1A; master&#x4F7F;&#x7528;yarn-client&#xFF0C;&#x4E0D;&#x80FD;&#x662F;yarn-cluster&#xFF0C;yarn-client&#x53EF;&#x4EE5;&#x4FDD;&#x6301;SparkContext&#x4E0D;&#x5173;&#x95ED;&#x3002; &#x6570;&#x636E;&#x5E93;&#x4F7F;&#x7528;mysql&#x3002; &#x4FEE;&#x6539;web&#x7AEF;&#x53E3;&#x4E3A;8099 123456789101112131415161718spark { master = &quot;yarn-client&quot; jobserver { port = 8099 context-per-jvm = false jobdao = spark.jobserver.io.JobSqlDAO #&#x4F7F;&#x7528;file&#x6216;&#x6570;&#x636E;&#x5E93; sqldao { slick-driver=slick.driver.MySQLDriver jdbc-driver=com.mysql.jdbc.Driver jdbc { url=&quot;jdbc:mysql://db_host/spark_jobserver?characterEncoding=UTF-8&quot; user=&quot;secret&quot; password=&quot;secret&quot; } } }}flyway.locations=&quot;db/mysql/migration&quot; &#x5982;&#x6709;&#x9700;&#x8981;&#xFF0C;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;shiro&#x7684;&#x914D;&#x7F6E;&#xFF0C;&#x9700;&#x8981;&#x8BBE;&#x7F6E;authentication = on&#x3002; sh bin/server_deploy.sh firstshare&#x8FDB;&#x884C;&#x5B89;&#x88C5;&#xFF0C;&#x5B89;&#x88C5;&#x8FC7;&#x7A0B;&#x4E2D;&#x9700;&#x8981;&#x51E0;&#x6B21;&#x8F93;&#x5165;&#x5BC6;&#x7801;&#x3002; &#x4F7F;&#x7528;server_start.sh&#x548C;server_stop.sh&#x8FDB;&#x884C;&#x542F;&#x505C;&#x3002; &#x66F4;&#x65B0;&#x5982;&#x679C;&#x5BF9;&#x4EE3;&#x7801;&#x8FDB;&#x884C;&#x4E86;&#x66F4;&#x65B0;&#xFF0C;&#x76F4;&#x63A5;&#x4F7F;&#x7528;sbt ++2.10.5 job-server-extras/assembly&#x6253;&#x5305;&#xFF0C;&#x66FF;&#x6362;&#x5B89;&#x88C5;&#x76EE;&#x5F55;&#x4E0B;&#x7684;spark-job-server.jar&#x5373;&#x53EF;&#x3002; &#x9700;&#x8981;&#x4F7F;&#x7528;&#x81EA;&#x5E26;&#x7684;&#x6D4B;&#x8BD5;&#x7528;&#x4F8B;&#x65F6;&#xFF0C;&#x4F7F;&#x7528;sbt job-server-tests/package&#x8FDB;&#x884C;&#x6253;&#x5305;&#x3002; APIjar&#x5305;&#x64CD;&#x4F5C;12GET /jars - lists all the jars and the last upload timestampPOST /jars/&lt;appName&gt; - uploads a new jar under &lt;appName&gt; &#x63D0;&#x4EA4;jar&#x5305;&#x6253;&#x5305;&#x65F6;&#x4E0D;&#x5EFA;&#x8BAE;&#x6253;assembly&#x5305;&#xFF0C;&#x63A8;&#x8350;&#x4F7F;&#x7528;dependent-jar-uris&#x6765;&#x6DFB;&#x52A0;&#x4F9D;&#x8D56;&#x3002; 12curl --data-binary @job-server-tests/target/scala-2.10/job-server-tests_2.10-0.7.0-SNAPSHOT_cdh-5.7.jar localhost:8099/jars/testcurl --data-binary @target/scala-2.10/spark-jobserver-mongo_2.10-1.0.0-SNAPSHOT.jar localhost:8099/jars/test-mongo &#x67E5;&#x770B;&#x6240;&#x6709;jar&#x5305;1curl localhost:8099/jars context&#x64CD;&#x4F5C;1234GET /contexts - lists all current contextsPOST /contexts/&lt;name&gt; - creates a new contextDELETE /contexts/&lt;name&gt; - stops a context and all jobs running in itPUT /contexts?reset=reboot - kills all contexts and re-loads only the contexts from config &#x521B;&#x5EFA;context &#x8BBE;&#x5B9A;yarn&#x961F;&#x5217;&#xFF0C;&#x8BBE;&#x5B9A;spark.yarn.queue&#x53C2;&#x6570; 1curl -d &quot;&quot; &apos;localhost:8099/contexts/test-context?spark.yarn.queue=test&apos; &#x589E;&#x52A0;&#x4F9D;&#x8D56;jar&#x5305;&#xFF0C;&#x8BBE;&#x5B9A;dependent-jar-uris&#x53C2;&#x6570; 1curl -d &quot;&quot; &apos;localhost:8099/contexts/mongo-context?spark.yarn.queue=test&amp;dependent-jar-uris=file:///opt/fs/job-server/aux-lib/mongo-spark-connector_2.10-1.1.0.jar,file:///opt/fs/job-server/aux-lib/mongo-java-driver-3.2.2.jar&apos; &#x5220;&#x9664;context1curl -X DELETE localhost:8099/contexts/test-context job&#x64CD;&#x4F5C;&#x8FD9;&#x91CC;&#x7684;job&#x4E0D;&#x662F;&#x666E;&#x901A;&#x7684;spark&#x4EFB;&#x52A1;&#xFF0C;&#x800C;&#x662F;&#x5B9E;&#x73B0;spark-jobserver api&#x7684;&#x4EFB;&#x52A1;&#xFF0C;&#x7EE7;&#x627F;&#x5176;api&#x4E2D;SparkJob trait&#xFF0C;&#x5E76;&#x5B9E;&#x73B0;runJob&#x65B9;&#x6CD5;&#x3002; 12345GET /jobs - Lists the last N jobsPOST /jobs - Starts a new job, use ?sync=true to wait for resultsGET /jobs/&lt;jobId&gt; - Gets the result or status of a specific jobDELETE /jobs/&lt;jobId&gt; - Kills the specified jobGET /jobs/&lt;jobId&gt;/config - Gets the job configuration &#x63D0;&#x4EA4;job &#x63D0;&#x4EA4;&#x5E26;&#x53C2;&#x6570;&#x4EFB;&#x52A1; 1curl -d &quot;input.string = a b c a b see&quot; &apos;localhost:8099/jobs?appName=spark-mongo&amp;classPath=com.fxiaoke.dataplatform.WordCountExample&amp;context=mongo-context&apos; &#x63D0;&#x4EA4;&#x4EFB;&#x52A1;&#x5230;&#x6307;&#x5B9A;&#x7684;context&#xFF0C;&#x8BBE;&#x7F6E;context&#x53C2;&#x6570;&#x503C;&#xFF0C;context&#x9700;&#x8981;&#x63D0;&#x524D;&#x521B;&#x5EFA; 12345678curl -X POST &apos;localhost:8099/jobs?appName=spark-mongo&amp;classPath=com.fxiaoke.dataplatform.MongoSparkSQL&amp;context=mongo-context&amp;sync=true&amp;timeout=10000&apos; -d &apos;{ mongo.ip = &quot;192.168.2.19&quot; mongo.database = mydb mongo.collection = myCollection mongo.sql = &quot;select name,age from mydb.myCollection where age &gt;= 20&quot;}&apos; &#x7B49;&#x5F85;&#x4EFB;&#x52A1;&#x6267;&#x884C;&#x5B8C;&#x6210;&#xFF0C;&#x8BBE;&#x5B9A;sync=true&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;timeout&#x53C2;&#x6570;&#xFF0C;&#x9ED8;&#x8BA4;40s&#x3002; 1curl -d &quot;input.string = a b c a b see&quot; &apos;localhost:8099/jobs?appName=test&amp;classPath=spark.jobserver.WordCountExample&amp;sync=true&amp;timeout=10000000&apos; &#x67E5;&#x770B;job&#x4FE1;&#x606F;12345678910$ curl localhost:8099/jobs/1b8f60f8-067e-4d83-b198-8fc6017227e8{ &quot;duration&quot;: &quot;3.0 secs&quot;, &quot;classPath&quot;: &quot;com.fxiaoke.dataplatform.MongoSparkSQL&quot;, &quot;startTime&quot;: &quot;2016-10-21T18:37:01.000+08:00&quot;, &quot;context&quot;: &quot;mongo-context&quot;, &quot;result&quot;: [&quot;{\\&quot;name\\&quot;:\\&quot;Thorin\\&quot;,\\&quot;age\\&quot;:195}&quot;, &quot;{\\&quot;name\\&quot;:\\&quot;Balin\\&quot;,\\&quot;age\\&quot;:178}&quot;, &quot;{\\&quot;name\\&quot;:\\&quot;Dwalin\\&quot;,\\&quot;age\\&quot;:169}&quot;, &quot;{\\&quot;name\\&quot;:\\&quot;\\u00d3in\\&quot;,\\&quot;age\\&quot;:167}&quot;, &quot;{\\&quot;name\\&quot;:\\&quot;Gl\\u00f3in\\&quot;,\\&quot;age\\&quot;:158}&quot;], &quot;status&quot;: &quot;FINISHED&quot;, &quot;jobId&quot;: &quot;1b8f60f8-067e-4d83-b198-8fc6017227e8&quot;} &#x521B;&#x5EFA;Spark JobServer&#x5DE5;&#x7A0B;&#x6DFB;&#x52A0;&#x4F9D;&#x8D56;&#x7531;&#x4E8E;&#x81EA;&#x5DF1;&#x4FEE;&#x6539;&#x4E86;spark-jobserver&#x4EE3;&#x7801;&#xFF0C;&#x6240;&#x4EE5;&#x9700;&#x8981;&#x81EA;&#x5DF1;&#x751F;&#x6210;api jar&#x5305;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;sbt publish-local&#x547D;&#x4EE4;&#xFF0C;&#x6253;&#x5305;&#x5E76;publish&#x5230;&#x672C;&#x5730;ivy&#x4ED3;&#x5E93;&#x3002; 1234sbt ++2.10.5 job-server-api/publish-local sbt ++2.10.5 job-server/publish-local sbt ++2.10.5 job-server-extras/publish-local sbt ++2.10.5 akka-app/publish-local &#x5728;build.sbt&#x4E2D;&#x6DFB;&#x52A0;spark-jobserver&#x4F9D;&#x8D56;&#xFF0C;&#x5176;&#x4ED6;&#x4F9D;&#x8D56;&#x6309;&#x9700;&#x8981;&#x6DFB;&#x52A0;&#x3002;12libraryDependencies += &quot;spark.jobserver&quot; %% &quot;job-server-api&quot; % &quot;0.7.0-SNAPSHOT_cdh-5.7&quot; % &quot;provided&quot;libraryDependencies += &quot;spark.jobserver&quot; %% &quot;job-server-extras&quot; % &quot;0.7.0-SNAPSHOT_cdh-5.7&quot; % &quot;provided&quot; SparkJob API0.7&#x7248;&#x672C;&#x7684;spark jobserver&#x4F7F;&#x7528;&#x4E86;&#x65B0;&#x7684;api&#xFF0C;&#x76F4;&#x63A5;&#x7EE7;&#x627F;SparkJob&#xFF0C;&#x5E76;&#x5B9E;&#x73B0;runJob&#x548C;validate&#x65B9;&#x6CD5;&#x5373;&#x53EF;&#x3002; &#x793A;&#x4F8B;: 1234567891011121314151617181920import com.typesafe.config.Configimport org.apache.spark.SparkContextimport org.scalactic._import spark.jobserver.api.{JobEnvironment, SingleProblem, SparkJob, ValidationProblem}import scala.util.Tryobject WordCountExample extends SparkJob { type JobData = Seq[String] //&#x53EF;&#x4EE5;&#x81EA;&#x5B9A;&#x4E49;JobData&#x548C;JobOutput&#x7C7B;&#x578B; type JobOutput = collection.Map[String, Long] def runJob(sc: SparkContext, runtime: JobEnvironment, data: JobData): JobOutput = { sc.parallelize(data).countByValue } def validate(sc: SparkContext, runtime: JobEnvironment, config: Config): JobData Or Every[ValidationProblem] = { Try(config.getString(&quot;input.string&quot;).split(&quot; &quot;).toSeq) .map(words =&gt; Good(words)) .getOrElse(Bad(One(SingleProblem(&quot;No input.string param&quot;)))) }} Named Objects&#x53C2;&#x8003;https://github.com/spark-jobserver/spark-jobserver#named-objects &#x53EF;&#x4EE5;&#x521B;&#x5EFA;&#x81EA;&#x5B9A;&#x4E49;&#x7684;RDD&#x548C;&#x5BF9;&#x8C61;&#xFF0C;&#x5728;&#x591A;&#x4E2A;job&#x5171;&#x4EAB;rdd&#x3002; Exceptions Exception in thread &#x201C;main&#x201D; java.lang.NoSuchMethodError: akka.util.Helpers$.ConfigOps(Lcom/typesafe/config/Config;)Lcom/typesafe/config/Config; &#x8FD9;&#x662F;&#x7531;&#x4E8E;CDH5.7&#x4E2D;akka&#x7248;&#x672C;&#x6BD4;&#x8F83;&#x4F4E;&#xFF0C;&#x800C;spark-jobserver&#x4E2D;akka&#x7248;&#x672C;&#x6BD4;&#x8F83;&#x9AD8;&#x5F15;&#x8D77;&#x7684;&#x3002;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6DFB;&#x52A0;cdh&#x652F;&#x6301;&#x7684;&#x7248;&#x672C;https://github.com/bjoernlohrmann/spark-jobserver&#xFF0C;&#x627E;&#x5230;&#x9002;&#x7528;&#x4E8E;CDH&#x7684;&#x5206;&#x652F;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x7684;&#x662F;0.7.0-SNAPSHOT_cdh-5.7&#x3002; &#x53C2;&#x8003;: https://github.com/spark-jobserver/spark-jobserver/issues/394 https://github.com/spark-jobserver/spark-jobserver/issues/592 org.apache.spark.SparkException: Found both spark.executor.extraClassPath and SPARK_CLASSPATH. Use only the former. &#x5220;&#x9664;spark-env.sh&#x4E2D;&#x7684;SPARK_CLASSPATH. Spark1.4&#x4E4B;&#x540E;&#x4E0D;&#x518D;&#x4F7F;&#x7528;SPARK_CLASSPATH&#xFF0C;&#x4F7F;&#x7528;spark-defaults.conf&#x4E2D;spark.executor.extraClassPath&#x4EE3;&#x66FF;&#x3002; java.lang.NoSuchMethodError: org.joda.time.DateTime.now()spark-jobserver&#x4E2D;joda-time&#x7248;&#x672C;(2.9.3)&#x4E0E;CDH5.7&#x4E2D;joda-time&#x7248;&#x672C;(1.6)&#x51B2;&#x7A81;&#xFF0C;&#x5C06;spark-jobserver&#x4E2D;joda-time&#x7248;&#x672C;&#x964D;&#x5230;1.6&#xFF0C;&#x5E76;&#x5C06;DateTime.now()&#x5168;&#x90E8;&#x66FF;&#x6362;&#x4E3A;new DateTime()&#x3002; &#x63D0;&#x4EA4;job&#x540E;&#x65E0;&#x6CD5;&#x67E5;&#x770B;job&#x4FE1;&#x606F;&#x548C;&#x7ED3;&#x679C;&#x53C2;&#x89C1;github issue#516&#x5DF2;&#x7ECF;&#x89E3;&#x51B3;&#xFF0C;commit#109210c 1git cherry-pick 109210c &#x66F4;&#x65B0;jar&#x5305;&#x540E;&#xFF0C;&#x5728;&#x540C;&#x4E00;&#x4E2A;context&#x4E2D;&#x6267;&#x884C;&#xFF0C;&#x53D1;&#x73B0;&#x7ED3;&#x679C;&#x6CA1;&#x6709;&#x968F;jar&#x5305;&#x66F4;&#x65B0;&#x800C;&#x66F4;&#x65B0;&#x5176;&#x5B9E;&#x8FD9;&#x4E0D;&#x662F;&#x4E00;&#x4E2A;bug&#x6216;exception&#xFF0C;&#x53C2;&#x89C1;github issue#218 What is happening is this. Each SparkContext has one custom classloader. In the JVM you cannot update JAR code live &#x2013; it&#x2019;s not a job server limitation, but a fundamental JVM limitation. Once you load in the classes for jar1, you cannot try to load in newer versions of those classes, because the classloader will keep using the class names that are already loaded. &#x4F7F;&#x7528;mysql&#x4F5C;&#x4E3A;&#x6570;&#x636E;&#x5E93;&#x540E;&#xFF0C;&#x63D0;&#x4EA4;&#x7684;job&#x72B6;&#x6001;&#x9ED8;&#x8BA4;&#x662F;FINISHED&#x5728;WebApi.scala&#x6587;&#x4EF6;&#x4E2D;&#x67E5;&#x770B;getJobReport&#x65B9;&#x6CD5; 12345678910111213def getJobReport(jobInfo: JobInfo, jobStarted: Boolean = false): Map[String, Any] = { val statusMap = if (jobStarted) Map(StatusKey -&gt; &quot;STARTED&quot;) else (jobInfo match { case JobInfo(_, _, _, _, _, None, _) =&gt; Map(StatusKey -&gt; &quot;RUNNING&quot;) //&#x6CE8;&#x91CA;1: &#x5F53;END_TIME&#x4E3A;NONE&#xFF0C;&#x5C31;&#x5224;&#x65AD;&#x4E3A;RUNNING case JobInfo(_, _, _, _, _, _, Some(ex)) =&gt; Map(StatusKey -&gt; &quot;ERROR&quot;, ResultKey -&gt; formatException(ex)) case JobInfo(_, _, _, _, _, Some(e), None) =&gt; Map(StatusKey -&gt; &quot;FINISHED&quot;) //&#x6CE8;&#x91CA;2 }) Map(&quot;jobId&quot; -&gt; jobInfo.jobId, &quot;startTime&quot; -&gt; jobInfo.startTime.toString(), &quot;classPath&quot; -&gt; jobInfo.classPath, &quot;context&quot; -&gt; (if (jobInfo.contextName.isEmpty) &quot;&lt;&lt;ad-hoc&gt;&gt;&quot; else jobInfo.contextName), &quot;duration&quot; -&gt; getJobDurationString(jobInfo)) ++ statusMap} &#x4ECE;&#x6CE8;&#x91CA;1&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x5F53;&#x7B2C;&#x516D;&#x4E2A;&#x53C2;&#x6570;&#x5373;END_TIME&#x4E3A;None&#x65F6;&#xFF0C;&#x4EFB;&#x52A1;job&#x5904;&#x4E8E;RUNNING&#x72B6;&#x6001;&#x3002; &#x4F46;&#x5728;mysql&#x7684;JOBS&#x8868;&#x4E2D;&#xFF0C;END_TIME&#x5B57;&#x6BB5;&#x4E3A;timestamp&#x7C7B;&#x578B;&#xFF0C;&#x6709;&#x9ED8;&#x8BA4;&#x503C;&#x201D;0000-00-00 00:00&#x201D;&#xFF0C;&#x6240;&#x4EE5;&#x4E00;&#x76F4;&#x6709;&#x503C;&#xFF0C;&#x8D70;&#x5230;&#x6CE8;&#x91CA;2&#x5904;&#xFF0C;&#x8868;&#x73B0;&#x4E3A;FINISHED&#x3002; &#x89E3;&#x51B3;&#x65B9;&#x6CD5;&#xFF1A; &#x8BBE;&#x7F6E;mysql&#x7684;END_TIME&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;null&#x3002;&#x5728;mysql&#x4E2D;timestamp&#x7C7B;&#x578B;&#x6BD4;&#x8F83;&#x7279;&#x6B8A;&#xFF0C;&#x4E0D;&#x80FD;&#x4F7F;&#x7528;default NULL&#x8BBE;&#x7F6E;&#x9ED8;&#x8BA4;&#x503C;&#x3002; 1alter table JOBS modify column END_TIME timestamp NULL; &#x53C2;&#x8003; sbt publish local jar Scala&#x6559;&#x7A0B;&#xFF1A;&#x7B80;&#x5355;&#x6784;&#x5EFA;&#x5DE5;&#x5177;SBT &#x4F7F;&#x7528;&#x672C;&#x5730;maven&#x79C1;&#x670D;&#x52A0;&#x901F;sbt&#x4E0B;&#x8F7D;","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"}]},{"title":"使用本地maven私服加速sbt下载","slug":"use-local-maven-repository-faster-sbt","date":"2016-10-20T12:24:39.000Z","updated":"2016-10-20T14:28:38.000Z","comments":true,"path":"2016/10/20/use-local-maven-repository-faster-sbt/","link":"","permalink":"http://wzktravel.github.io/2016/10/20/use-local-maven-repository-faster-sbt/","excerpt":"","text":"&#x516C;&#x53F8;&#x4F7F;&#x7528;JFrog Artifactory&#x642D;&#x5EFA;maven&#x79C1;&#x670D;&#xFF0C;&#x914D;&#x7F6E;sbt&#x4F7F;&#x7528;maven&#x79C1;&#x670D;&#x4E0B;&#x8F7D;&#x3002; &#x9996;&#x5148;&#x5728;~/.sbt/repositories&#x4E2D;&#x6DFB;&#x52A0;local-maven&#x4E3A;&#x516C;&#x53F8;&#x5185;&#x90E8;maven&#x79C1;&#x670D;&#x5730;&#x5740;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x6B64;&#x6587;&#x4EF6;&#xFF0C;&#x9700;&#x8981;&#x5148;&#x521B;&#x5EFA;&#x3002;123456789~ &#x27A4; cat ~/.sbt/repositories[repositories] local local-maven: http://${your-maven-address}/artifactory/libs-release/ central: http://repo2.maven.org/maven2/ typesafe: http://repo.typesafe.com/typesafe/ivy-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly sonatype-oss-releases maven-central sonatype-oss-snapshots &#x5982;&#x679C;&#x4F7F;&#x7528;idea&#x4F5C;&#x4E3A;&#x5F00;&#x53D1;&#x5DE5;&#x5177;&#xFF0C;&#x4FEE;&#x6539;Preference -&gt; Build, Execution, Deployment -&gt; Build Tools -&gt; SBT&#x4E2D;&#x4FEE;&#x6539;JVM Options&#xFF0C;&#x6DFB;&#x52A0;-Dsbt.override.build.repos=true&#xFF0C;&#x8FD9;&#x6837;&#x81EA;&#x5B9A;&#x4E49;&#x7684;resolvers&#x4F1A;&#x88AB;~/.sbt/repositories&#x4E2D;&#x914D;&#x7F6E;&#x8986;&#x76D6;&#x3002; &#x53C2;&#x8003;&#xFF1A; JFrog: SBT Repositories Github&#x9879;&#x76EE;Repox:&#x6539;&#x5584;sbt&#x89E3;&#x51B3;&#x4F9D;&#x8D56;&#x7684;&#x901F;&#x5EA6;","categories":[],"tags":[{"name":"maven","slug":"maven","permalink":"http://wzktravel.github.io/tags/maven/"},{"name":"sbt","slug":"sbt","permalink":"http://wzktravel.github.io/tags/sbt/"}]},{"title":"mongo-spark-connector使用说明","slug":"use-mongo-spark-connector","date":"2016-10-20T10:39:51.000Z","updated":"2016-12-17T11:03:08.000Z","comments":true,"path":"2016/10/20/use-mongo-spark-connector/","link":"","permalink":"http://wzktravel.github.io/2016/10/20/use-mongo-spark-connector/","excerpt":"mongoDB的spark connector使用说明，mongo版本为2.6.12，spark版本为1.6.0。官网为https://docs.mongodb.com/spark-connector/。","text":"mongoDB&#x7684;spark connector&#x4F7F;&#x7528;&#x8BF4;&#x660E;&#xFF0C;mongo&#x7248;&#x672C;&#x4E3A;2.6.12&#xFF0C;spark&#x7248;&#x672C;&#x4E3A;1.6.0&#x3002;&#x5B98;&#x7F51;&#x4E3A;https://docs.mongodb.com/spark-connector/&#x3002; Getting Startedhttps://docs.mongodb.com/spark-connector/getting-started/ &#x542F;&#x52A8;spark-shell123spark-shell --conf &quot;spark.mongodb.input.uri=mongodb://192.168.2.12/fs-form.form?readPreference=primaryPreferred&quot; \\ --conf &quot;spark.mongodb.output.uri=mongodb://192.168.2.12/mydb.test4&quot; \\ --packages org.mongodb.spark:mongo-spark-connector_2.10:1.1.0 --packages&#x4F1A;&#x81EA;&#x52A8;&#x4E0B;&#x8F7D;&#x4F9D;&#x8D56;&#x5305; &#x5411;Mongo&#x4E2D;&#x5199;&#x5165;&#x6570;&#x636E;&#x53C2;&#x8003;https://docs.mongodb.com/spark-connector/getting-started/#write-to-mongodb 12345scala&gt; import com.mongodb.spark._ //import MongoDB connector packagescala&gt; import com.mongodb.spark.config._scala&gt; import org.bson.Document //import bsonscala&gt; val sparkDocuments = sc.parallelize((1 to 10).map(i =&gt; Document.parse(s&quot;{spark: $i}&quot;)))scala&gt; sparkDocuments.saveToMongoDB(WriteConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;))) // Uses the WriteConfig &#x4FDD;&#x5B58;&#x65F6;&#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x53E6;&#x5916;&#x4E00;&#x79CD;&#x5F62;&#x5F0F;12scala&gt; val writeConfig = WriteConfig(Map(&quot;collection&quot; -&gt; &quot;spark&quot;, &quot;writeConcern.w&quot; -&gt; &quot;majority&quot;), Some(WriteConfig(sc)))scala&gt; MongoSpark.save(sparkDocuments, writeConfig) &#x67E5;&#x770B;mongo&#x4E2D;&#x6570;&#x636E;:1234567891011StandAlone:PRIMARY&gt; db.test4.find(){ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f7ab0584e&quot;), &quot;spark&quot; : 6 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f7ab0584f&quot;), &quot;spark&quot; : 7 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f64d99533&quot;), &quot;spark&quot; : 1 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f7ab05850&quot;), &quot;spark&quot; : 8 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f64d99534&quot;), &quot;spark&quot; : 2 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f7ab05851&quot;), &quot;spark&quot; : 9 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f64d99535&quot;), &quot;spark&quot; : 3 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f7ab05852&quot;), &quot;spark&quot; : 10 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f64d99536&quot;), &quot;spark&quot; : 4 }{ &quot;_id&quot; : ObjectId(&quot;58086a308ad6b14f64d99537&quot;), &quot;spark&quot; : 5 } &#x4ECE;Mongo&#x4E2D;&#x8BFB;&#x53D6;&#x5E76;&#x5206;&#x6790;&#x6570;&#x636E;&#x5982;&#x679C;mongo&#x7248;&#x672C;&#x4F4E;&#x4E8E;3.2&#xFF0C;&#x76F4;&#x63A5;&#x4F7F;&#x7528;MongoSpark.load(sc)&#x4F1A;&#x62A5;&#x9519;&#xFF0C;ERROR partitioner.DefaultMongoPartitioner&#x3002;&#x9700;&#x8981;&#x4F7F;&#x7528;ReadConfig&#xFF0C;&#x6307;&#x5B9A;partitioner&#x53C2;&#x6570;&#x3002; 12345scala&gt; val readConfig = ReadConfig(Map(&quot;database&quot; -&gt; &quot;mydb&quot;, &quot;collection&quot; -&gt; &quot;test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;), Some(ReadConfig(sc)))readConfig: com.mongodb.spark.config.ReadConfig = ReadConfig(mydb,test4,Some(mongodb://192.168.2.12/fs-form.form?readPreference=primaryPreferred),1000,com.mongodb.spark.rdd.partitioner.MongoShardedPartitioner@368e1bf3,Map(),15,ReadPreferenceConfig(primaryPreferred,None),ReadConcernConfig(None),false)scala&gt; val customRdd = MongoSpark.load(sc, readConfig)scala&gt; println(customRdd.first.toJson){ &quot;_id&quot; : { &quot;$oid&quot; : &quot;58086a308ad6b14f64d99533&quot; }, &quot;spark&quot; : 1 } &#x6216;&#x76F4;&#x63A5;&#x4F7F;&#x7528;sc.loadFromMongoDB(ReadConfig)&#x3002; 123scala&gt; val rdd = sc.loadFromMongoDB(ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;)))scala&gt; println(rdd.first.toJson){ &quot;_id&quot; : { &quot;$oid&quot; : &quot;58086a308ad6b14f64d99533&quot; }, &quot;spark&quot; : 1 } Spark SQLhttps://docs.mongodb.com/spark-connector/spark-sql/ &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x7684;spark&#x662F;1.6.0&#xFF0C;&#x800C;SparkSession&#x662F;Spark2.0&#x5F15;&#x5165;&#x7684;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x80FD;&#x53C2;&#x8003;master&#x7684;&#x6587;&#x4EF6;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#x4E4B;&#x524D;&#x7684;&#x7248;&#x672C;https://github.com/mongodb/mongo-spark/blob/1.x/examples/src/test/scala/tour/SparkSQL.scala &#x4F7F;&#x7528;DataFrame12345678910111213141516scala&gt; import org.apache.spark.sql.SQLContextscala&gt; import com.mongodb.spark._scala&gt; import com.mongodb.spark.config._scala&gt; import com.mongodb.spark.sql._scala&gt; import org.bson.Documentscala&gt; val sqlContext = SQLContext.getOrCreate(sc)scala&gt; val df = sqlContext.loadFromMongoDB(ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;)))scala&gt; df.filter(df(&quot;age&quot;) &lt; 100).show()+--------------------+---+-------------+| _id|age| name|+--------------------+---+-------------+|[58087ec39a1ca7ec...| 50|Bilbo Baggins||[58087ec39a1ca7ec...| 77| K&#xED;li||[58087ec49a1ca7ec...| 82| F&#xED;li|+--------------------+---+-------------+ &#x663E;&#x5F0F;&#x4F7F;&#x7528;DataFrame&#x548C;DataSet&#x76F4;&#x63A5;&#x4ECE;mongo&#x8BFB;&#x53D6;&#x65F6;&#x88C5;&#x8F7D;&#x4E3A;DataFrame12345678scala&gt; case class Character(name: String, age: Int)scala&gt; val sqlContext = SQLContext.getOrCreate(sc)scala&gt; val df = sqlContext.loadFromMongoDB[Character](ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;)))scala&gt; df.printSchema()root |-- name: string (nullable = true) |-- age: integer (nullable = false)scala&gt; val dataset = df.as[Character] &#x6216;&#x4ECE;RDD&#x8F6C;&#x6362;&#x4E3A;DataFrame&#x6216;DataSet1234scala&gt; val rdd = sc.loadFromMongoDB(ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;)))scala&gt; val dfInferredSchema = rdd.toDF()scala&gt; val dfExplicitSchema = rdd.toDF[Character]()scala&gt; val ds = rdd.toDS[Character]() &#x4F7F;&#x7528;Spark SQL1234567891011scala&gt; val sqlContext = SQLContext.getOrCreate(sc)scala&gt; val df = sqlContext.loadFromMongoDB(ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://192.168.2.12/mydb.test4&quot;, &quot;partitioner&quot; -&gt; &quot;MongoShardedPartitioner&quot;)))scala&gt; df.registerTempTable(&quot;characters&quot;)scala&gt; sqlContext.sql(&quot;SELECT * FROM test6 WHERE age &gt;= 100 and age &lt; 170&quot;).show()+------+---+| name|age|+------+---+|Dwalin|169|| &#xD3;in|167|| Gl&#xF3;in|158|+------+---+ ExceptionsERROR partitioner.DefaultMongoPartitionermongodb&#x7248;&#x672C;&#x4F4E;&#x4E8E;3.2&#x65F6;&#xFF0C;&#x8BFB;&#x53D6;&#x6570;&#x636E;&#x65F6;&#x5982;&#x679C;&#x4E0D;&#x6307;&#x5B9A;ReadConfig&#x4E2D;partitioner&#xFF0C;&#x4F1A;&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x7684;DefaultMongoPartitioner&#xFF0C;&#x8FD9;&#x65F6;&#x5019;&#x4F1A;&#x62A5;&#x9519;&#x3002;12345678910111213141516171816/10/20 15:12:39 ERROR partitioner.DefaultMongoPartitioner:----------------------------------------WARNING: MongoDB version &lt; 3.2 detected.----------------------------------------With legacy MongoDB installations you will need to explicitly configure the Spark Connector with a partitioner.This can be done by: * Setting a &quot;spark.mongodb.input.partitioner&quot; in SparkConf. * Setting in the &quot;partitioner&quot; parameter in ReadConfig. * Passing the &quot;partitioner&quot; option to the DataFrameReader.The following Partitioners are available: * MongoShardedPartitioner - for sharded clusters, requires read access to the config database. * MongoSplitVectorPartitioner - for single nodes or replicaSets. Utilises the SplitVector command on the primary. * MongoPaginateByCountPartitioner - creates a specific number of partitions. Slow as requires a query for every partition. * MongoPaginateBySizePartitioner - creates partitions based on data size. Slow as requires a query for every partition. &#x9519;&#x8BEF;&#x4FE1;&#x606F;&#x7ED9;&#x51FA;&#x7684;&#x63D0;&#x793A;&#x6BD4;&#x8F83;&#x660E;&#x663E;&#xFF0C;DefaultMongoPartitioner&#x5728;3.2&#x624D;&#x4F1A;&#x5B58;&#x5728;&#xFF0C;&#x9700;&#x8981;&#x6307;&#x5B9A;partitioner&#x4E3A;&#x5176;&#x4ED6;&#x51E0;&#x79CD;&#x3002; ReadConfig&#x914D;&#x7F6E;&#x9879;: https://docs.mongodb.com/spark-connector/configuration/#input-configuration Partitioner&#x914D;&#x7F6E;&#x9879;: https://docs.mongodb.com/spark-connector/configuration/#partitioner-conf &#x5B89;&#x88C5;mongo&#x53C2;&#x8003;https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/ &#x6DFB;&#x52A0;mongo2.6 repo123456cat &gt; /etc/yum.repos.d/mongodb-org-2.6.repo[mongodb-org-2.6]name=MongoDB 2.6 Repositorybaseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/gpgcheck=0enabled=1 &#x8FDB;&#x884C;&#x5B89;&#x88C5; &#x5B89;&#x88C5;&#x6240;&#x6709;&#x5305; 1sudo yum install -y mongodb-org &#x53EA;&#x5B89;&#x88C5;shell 1sudo yum install -y mongodb-org-shell &#x53C2;&#x8003; mongo shell&#x5E38;&#x7528;&#x547D;&#x4EE4; MongoDB Connector for Spark RDD, DataFrame, DataSet&#x533A;&#x522B;","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"},{"name":"mongo","slug":"mongo","permalink":"http://wzktravel.github.io/tags/mongo/"}]},{"title":"查看linux发行版本和kernel版本","slug":"check-linux-and-kernel-version","date":"2016-09-29T11:00:07.000Z","updated":"2016-09-30T01:28:29.000Z","comments":true,"path":"2016/09/29/check-linux-and-kernel-version/","link":"","permalink":"http://wzktravel.github.io/2016/09/29/check-linux-and-kernel-version/","excerpt":"","text":"&#x67E5;&#x770B;linux&#x53D1;&#x884C;&#x7248;&#x672C;12$ cat /etc/issue$ lsb_release -a &#x67E5;&#x770B;kernel&#x7248;&#x672C;12$ uname -a$ cat /proc/version # &#x9644;&#x6709;gcc&#x4FE1;&#x606F;&#x7B49; &#x67E5;&#x770B;lsb&#x4FE1;&#x606F;12$ cat /etc/lsb-release$ lsb_release -a","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"发行版本释义","slug":"release-versions","date":"2016-09-29T10:53:37.000Z","updated":"2016-09-29T10:55:43.000Z","comments":true,"path":"2016/09/29/release-versions/","link":"","permalink":"http://wzktravel.github.io/2016/09/29/release-versions/","excerpt":"","text":"&#x5F88;&#x591A;&#x8F6F;&#x4EF6;&#x5728;&#x6B63;&#x5F0F;&#x53D1;&#x5E03;&#x524D;&#x90FD;&#x4F1A;&#x53D1;&#x5E03;&#x4E00;&#x4E9B;&#x9884;&#x89C8;&#x7248;&#x6216;&#x8005;&#x6D4B;&#x8BD5;&#x7248;&#xFF0C;&#x4E00;&#x822C;&#x90FD;&#x53EB;&#x201C;beta&#x7248;&#x201D;&#x6216;&#x8005; &#x201C;rc&#x7248;&#x201D;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x5F00;&#x6E90;&#x8F6F;&#x4EF6;&#xFF0C;&#x751A;&#x81F3;&#x6709;&#x201C;alpha&#x7248;&#x201D;&#xFF0C;&#x4E0B;&#x9762;&#x6765;&#x89E3;&#x91CA;&#x4E00;&#x4E0B;&#x5404;&#x4E2A;&#x7248;&#x672C;&#x7684;&#x610F;&#x601D;&#x3002; alpha&#x7248;&#xFF1A;&#x5185;&#x90E8;&#x6D4B;&#x8BD5;&#x7248;&#x3002;&#x3B1;&#x662F;&#x5E0C;&#x814A;&#x5B57;&#x6BCD;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#xFF0C;&#x8868;&#x793A;&#x6700;&#x65E9;&#x7684;&#x7248;&#x672C;&#xFF0C;&#x4E00;&#x822C;&#x7528;&#x6237;&#x4E0D;&#x8981;&#x4E0B;&#x8F7D;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#xFF0C;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x5305;&#x542B;&#x5F88;&#x591A;BUG&#xFF0C;&#x529F;&#x80FD;&#x4E5F;&#x4E0D;&#x5168;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x7ED9;&#x5F00;&#x53D1;&#x4EBA;&#x5458;&#x548C; &#x6D4B;&#x8BD5;&#x4EBA;&#x5458;&#x6D4B;&#x8BD5;&#x548C;&#x627E;BUG&#x7528;&#x7684;&#x3002; beta&#x7248;&#xFF1A;&#x516C;&#x5F00;&#x6D4B;&#x8BD5;&#x7248;&#x3002;&#x3B2;&#x662F;&#x5E0C;&#x814A;&#x5B57;&#x6BCD;&#x7684;&#x7B2C;&#x4E8C;&#x4E2A;&#xFF0C;&#x987E;&#x540D;&#x601D;&#x4E49;&#xFF0C;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x6BD4;alpha&#x7248;&#x53D1;&#x5E03;&#x5F97;&#x665A;&#x4E00;&#x4E9B;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x7ED9;&#x201C;&#x90E8;&#x843D;&#x201D;&#x7528;&#x6237;&#x548C;&#x5FE0;&#x5B9E;&#x7528;&#x6237;&#x6D4B;&#x8BD5;&#x7528;&#x7684;&#xFF0C;&#x8BE5;&#x7248;&#x672C;&#x4EFB;&#x7136;&#x5B58; &#x5728;&#x5F88;&#x591A;BUG&#xFF0C;&#x4F46;&#x662F;&#x76F8;&#x5BF9;alpha&#x7248;&#x8981;&#x7A33;&#x5B9A;&#x4E00;&#x4E9B;&#x3002;&#x8FD9;&#x4E2A;&#x9636;&#x6BB5;&#x7248;&#x672C;&#x7684;&#x8F6F;&#x4EF6;&#x8FD8;&#x4F1A;&#x4E0D;&#x65AD;&#x589E;&#x52A0;&#x65B0;&#x529F;&#x80FD;&#x3002;&#x5982;&#x679C;&#x4F60;&#x662F;&#x53D1;&#x70E7;&#x53CB;&#xFF0C;&#x53EF;&#x4EE5;&#x4E0B;&#x8F7D;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x3002; rc&#x7248;&#xFF1A;&#x5168;&#x5199;&#xFF1A;Release Candidate&#xFF08;&#x5019;&#x9009;&#x7248;&#x672C;&#xFF09;&#xFF0C;&#x8BE5;&#x7248;&#x672C;&#x53C8;&#x8F83;beta&#x7248;&#x66F4;&#x8FDB;&#x4E00;&#x6B65;&#x4E86;&#xFF0C;&#x8BE5;&#x7248;&#x672C;&#x529F;&#x80FD;&#x4E0D;&#x518D;&#x589E;&#x52A0;&#xFF0C;&#x548C;&#x6700;&#x7EC8;&#x53D1;&#x5E03;&#x7248;&#x529F;&#x80FD;&#x4E00;&#x6837;&#x3002;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x6709;&#x70B9;&#x50CF;&#x6700;&#x7EC8;&#x53D1;&#x884C;&#x7248;&#x4E4B;&#x524D;&#x7684;&#x4E00;&#x4E2A;&#x7C7B;&#x4F3C; &#x9884;&#x89C8;&#x7248;&#xFF0C;&#x8FD9;&#x4E2A;&#x7684;&#x53D1;&#x5E03;&#x5C31;&#x6807;&#x660E;&#x79BB;&#x6700;&#x7EC8;&#x53D1;&#x884C;&#x7248;&#x4E0D;&#x8FDC;&#x4E86;&#x3002;&#x4F5C;&#x4E3A;&#x666E;&#x901A;&#x7528;&#x6237;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x5F88;&#x6025;&#x7740;&#x7528;&#x8FD9;&#x4E2A;&#x8F6F;&#x4EF6;&#x7684;&#x8BDD;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x4E0B;&#x8F7D;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x3002; stable&#x7248;&#xFF1A;&#x7A33;&#x5B9A;&#x7248;&#x3002;&#x5728;&#x5F00;&#x6E90;&#x8F6F;&#x4EF6;&#x4E2D;&#xFF0C;&#x90FD;&#x6709;stable&#x7248;&#xFF0C;&#x8FD9;&#x4E2A;&#x5C31;&#x662F;&#x5F00;&#x6E90;&#x8F6F;&#x4EF6;&#x7684;&#x6700;&#x7EC8;&#x53D1;&#x884C;&#x7248;&#xFF0C;&#x7528;&#x6237;&#x53EF;&#x4EE5;&#x653E;&#x5FC3;&#x5927;&#x80C6;&#x7684;&#x7528;&#x4E86;&#x3002; &#x53E6;&#x5916;&#xFF0C;&#x5BF9;&#x4E8E;&#x5546;&#x4E1A;&#x8F6F;&#x4EF6;&#xFF0C;&#x8FD8;&#x6709;&#x4EE5;&#x4E0B;&#x7248;&#x672C;&#xFF1A;RTM&#x7248;&#xFF1A;&#x5168;&#x79F0;&#x4E3A;Release to Manufacture&#x3002;&#x5DE5;&#x5382;&#x7248;&#x3002;&#x6539;&#x7248;&#x7A0B;&#x5E8F;&#x5DF2;&#x7ECF;&#x56FA;&#x5B9A;&#xFF0C;&#x5C31;&#x5DEE;&#x5DE5;&#x5382;&#x5305;&#x88C5;&#x3001;&#x5149;&#x76D8;&#x5370;&#x56FE;&#x6848;&#x7B49;&#x5DE5;&#x4F5C;&#x4E86;&#x3002;OEM&#x7248;&#xFF1A;&#x5382;&#x5546;&#x5B9A;&#x5236;&#x7248;&#x3002;EVAL&#x7248;&#xFF1A;&#x8BC4;&#x4F30;&#x7248;&#x3002;&#x5C31;&#x662F;&#x6709;30&#x6216;&#x8005;60&#x5929;&#x7B49;&#x4F7F;&#x7528;&#x671F;&#x9650;&#x7684;&#x7248;&#x672C;&#x3002;RTL&#x7248;&#xFF1A;Retail(&#x96F6;&#x552E;&#x7248;)&#xFF0C;&#x8FD9;&#x4E2A;&#x7248;&#x672C;&#x5C31;&#x662F;&#x771F;&#x6B63;&#x53D1;&#x552E;&#x7684;&#x7248;&#x672C;&#xFF0C;&#x6709;&#x6F02;&#x4EAE;&#x7684;&#x5305;&#x88C5;&#x3001;&#x5149;&#x76D8;&#x3001;&#x8BF4;&#x660E;&#x4E66;&#x7B49;&#x4E1C;&#x897F;&#x548C;&#x9AD8;&#x6602;&#x7684;&#x4EF7;&#x683C;&#x3002;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"mac隐藏dock上的程序图标","slug":"how-to-hide-application-icon","date":"2016-09-23T11:31:38.000Z","updated":"2016-09-24T12:08:00.000Z","comments":true,"path":"2016/09/23/how-to-hide-application-icon/","link":"","permalink":"http://wzktravel.github.io/2016/09/23/how-to-hide-application-icon/","excerpt":"","text":"&#x53F3;&#x51FB;&#x7A0B;&#x5E8F;&#x663E;&#x793A;&#x5305;&#x5185;&#x5BB9;&#x3002; &#x5728; Contents &#x6587;&#x4EF6;&#x5939;&#x4E2D;&#x627E;&#x5230; Info.plist &#x6587;&#x4EF6;&#xFF0C;&#x4F7F;&#x7528;&#x7F16;&#x8F91;&#x5668;&#x6253;&#x5F00;&#x3002; &#x6DFB;&#x52A0;LSUIElement&#x9879;&#xFF0C;&#x503C;&#x4E3A;1&#xFF0C;&#x91CD;&#x542F;&#x7A0B;&#x5E8F;&#x5373;&#x53EF;&#x3002; 12345&lt;dict&gt; &lt;key&gt;LSUIElement&lt;/key&gt; &lt;string&gt;1&lt;/string&gt; ....&lt;/dict&gt;","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"http://wzktravel.github.io/tags/mac/"}]},{"title":"hadoop lzo介绍和使用","slug":"hadoop-lzo","date":"2016-09-19T01:59:25.000Z","updated":"2016-09-19T02:20:27.000Z","comments":true,"path":"2016/09/19/hadoop-lzo/","link":"","permalink":"http://wzktravel.github.io/2016/09/19/hadoop-lzo/","excerpt":"整理一下lzo相关知识和一些使用方法。附上对指定目录下日志进行lzo压缩的代码：https://github.com/wzktravel/hadoop-codec","text":"&#x6574;&#x7406;&#x4E00;&#x4E0B;lzo&#x76F8;&#x5173;&#x77E5;&#x8BC6;&#x548C;&#x4E00;&#x4E9B;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#x3002;&#x9644;&#x4E0A;&#x5BF9;&#x6307;&#x5B9A;&#x76EE;&#x5F55;&#x4E0B;&#x65E5;&#x5FD7;&#x8FDB;&#x884C;lzo&#x538B;&#x7F29;&#x7684;&#x4EE3;&#x7801;&#xFF1A;https://github.com/wzktravel/hadoop-codec LZO is a compression codec which gives better compression and decompression speed than gzip, and also the capability to split. LZO allows this because its composed of many smaller (~256K) blocks of compressed data, allowing jobs to be split along block boundaries, as opposed to gzip where the dictionary for the whole file is written at the top. When you specify mapred.output.compression.codec as LzoCodec, hadoop will generate .lzo_deflate files. These contain the raw compressed data without any header, and cannot be decompressed with lzop -d command. Hadoop can read these files in the map phase, but this makes your life hard. When you specify LzopCodec as the compression.codec, hadoop will generate .lzo files. These contain the header and can be decompressed using lzop -d However, neither .lzo nor .lzo_deflate files are splittable by default. This is where LzoIndexer comes into play. It generates an index file which tells you where the record boundary is. This way, multiple map tasks can process the same file. See this cloudera blog post and LzoIndexer for more info. &#x521B;&#x5EFA;&#x7D22;&#x5F15;lzo&#x683C;&#x5F0F;&#x9ED8;&#x8BA4;&#x662F;&#x4E0D;&#x652F;&#x6301;splittable&#x7684;&#xFF0C;&#x9700;&#x8981;&#x4E3A;&#x5176;&#x6DFB;&#x52A0;&#x7D22;&#x5F15;&#x6587;&#x4EF6;&#xFF0C;&#x624D;&#x80FD;&#x652F;&#x6301;&#x591A;&#x4E2A;map&#x5E76;&#x884C;&#x5BF9;lzo&#x6587;&#x4EF6;&#x8FDB;&#x884C;&#x5904;&#x7406; MapReduce&#x8F93;&#x51FA;&#x65F6;&#x521B;&#x5EFA;&#x7D22;&#x5F15; &#x4F7F;&#x7528;lzo&#x7D22;&#x5F15;&#x751F;&#x6210;&#x5668; 123// &#x4F7F;&#x7528;lzo&#x7D22;&#x5F15;&#x751F;&#x6210;&#x5668;LzoIndexer lzoIndexer = new LzoIndexer(conf);lzoIndexer.index(new Path(outputPath)); &#x6216;&#x8005;&#x4F7F;&#x7528;&#x5206;&#x5E03;&#x5F0F;&#x7D22;&#x5F15;&#x751F;&#x6210;&#x5668; 123DistributedLzoIndexer lzoIndexer = new DistributedLzoIndexer();lzoIndexer.setConf(conf);lzoIndexer.run(new String[]{outputPath}); &#x5BF9;&#x5DF2;&#x7ECF;&#x662F;lzo&#x7684;&#x6587;&#x4EF6;&#x5EFA;&#x7ACB;&#x7D22;&#x5F15;12345## &#x5355;&#x673A;&#x7248;$ hadoop jar /opt/cloudera/parcels/GPLEXTRAS/lib/hadoop/lib/hadoop-lzo.jar com.hadoop.compression.lzo.LzoIndexer /path/to/lzo/part-00000.lzo## &#x5206;&#x5E03;&#x5F0F;&#x7248;$ hadoop jar /opt/cloudera/parcels/GPLEXTRAS/lib/hadoop/lib/hadoop-lzo.jar com.hadoop.compression.lzo.DistributedLzoIndexer /path/to/lzo/part-00000.lzo &#x7D22;&#x5F15;&#x6587;&#x4EF6;&#x4E0E;&#x6E90;&#x6587;&#x4EF6;&#x5728;&#x76F8;&#x540C;&#x76EE;&#x5F55;&#x4E0B;&#x3002; beachmark&#x4F7F;&#x7528;MapReduce&#x505A;wordcount &#x8F93;&#x5165; &#x8F93;&#x5165;&#x5927;&#x5C0F; &#x8F93;&#x51FA;&#x5927;&#x5C0F; cpu memory map&#x8017;&#x65F6; reduce&#x8017;&#x65F6; &#x603B;&#x8017;&#x65F6; Text 70G 55G 190 389G 2&#x5206;4&#x79D2; 10&#x5206;15&#x79D2; 12&#x5206;24&#x79D2; Lzo 4.3G 3.1G 36 78G 1&#x5206;55&#x79D2; 6&#x5206;11&#x79D2; 8&#x5206;10&#x79D2; &#x6BD4;&#x7387; 6.14% 5.64% 18.95% 20.05% 92.74% 60.33% 65.86% &#x5982;&#x4F55;&#x4F7F;&#x7528;lzojava123456789101112131415public static void compress(String codecClassName) throws Exception { Class&lt;?&gt; codecClass = Class.forName(codecClassName); Configuration conf = new Configuration(); FileSystem fs = FileSystem.get(conf); CompressionCodec codec = (CompressionCodec)ReflectionUtils.newInstance(codecClass, conf); //&#x6307;&#x5B9A;&#x538B;&#x7F29;&#x6587;&#x4EF6;&#x8DEF;&#x5F84; FSDataOutputStream outputStream = fs.create(new Path(/user/hadoop/text.gz)); //&#x6307;&#x5B9A;&#x8981;&#x88AB;&#x538B;&#x7F29;&#x7684;&#x6587;&#x4EF6;&#x8DEF;&#x5F84; FSDataInputStream in = fs.open(new Path(/user/hadoop/aa.txt)); //&#x521B;&#x5EFA;&#x538B;&#x7F29;&#x8F93;&#x51FA;&#x6D41; CompressionOutputStream out = codec.createOutputStream(outputStream); IOUtils.copyBytes(in, out, conf); IOUtils.closeStream(in); IOUtils.closeStream(out);} MapReduce&#x8BFB;&#x53D6;lzo&#x6587;&#x4EF6;1job.setInputFormatClass(LzoTextInputFormat.class); map&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x4F7F;&#x7528;lzo&#x538B;&#x7F29;12conf.set(&quot;mapreduce.map.output.compress&quot;, &quot;true&quot;);conf.set(&quot;mapreduce.map.output.compress.codec&quot;, &quot;com.hadoop.compression.lzo.LzoCodec&quot;); &#x8F93;&#x51FA;lzo&#x6587;&#x4EF6;1234567891011FileOutputFormat.setCompressOutput(job, true);FileOutputFormat.setOutputCompressorClass(job, LzopCodec.class);int result = job.waitForCompletion(true) ? 0 : 1;// &#x4E0A;&#x9762;&#x7684;&#x8BED;&#x53E5;&#x6267;&#x884C;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x4F1A;&#x751F;&#x6210;&#x6700;&#x540E;&#x7684;&#x8F93;&#x51FA;&#x6587;&#x4EF6;&#xFF0C;&#x9700;&#x8981;&#x5728;&#x6B64;&#x57FA;&#x7840;&#x4E0A;&#x6DFB;&#x52A0;lzo&#x7684;&#x7D22;&#x5F15;// &#x4F7F;&#x7528;lzo&#x7D22;&#x5F15;&#x751F;&#x6210;&#x5668;LzoIndexer lzoIndexer = new LzoIndexer(conf);lzoIndexer.index(new Path(outputPath));// &#x6216;&#x8005;&#x4F7F;&#x7528;&#x5206;&#x5E03;&#x5F0F;&#x7D22;&#x5F15;&#x751F;&#x6210;&#x5668;// DistributedLzoIndexer lzoIndexer = new DistributedLzoIndexer();// lzoIndexer.setConf(conf);// lzoIndexer.run(new String[]{outputPath}); Spark&#x8BFB;&#x53D6;lzo&#x6587;&#x4EF6;spark&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x8BFB;&#x53D6;lzo&#x6587;&#x4EF6;&#x3002; 123scala&gt; val lzoFile = sc.textFile(&quot;/path/to/lzo/*.lzo&quot;)scala&gt; val lzoWordCounts = lzoFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey((a,b) =&gt; a + b)scala&gt; lzoWordCounts.collect() &#x8F93;&#x51FA;lzo&#x6587;&#x4EF6;save&#x65F6;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x683C;&#x5F0F;&#xFF0C;classOf[com.hadoop.compression.lzo.LzopCodec]&#x3002; 12val textFile = sc.textFile(&quot;/xxx/in&quot;)textFile.saveAsTextFile(&quot;/xxx/out/&quot;, classOf[com.hadoop.compression.lzo.LzopCodec]) Hive&#x521B;&#x5EFA;&#x8868;&#x65F6;&#x6307;&#x5B9A;&#x4E3A;lzo&#x5B58;&#x50A8;&#x683C;&#x5F0F;12345678910CREATE EXTERNAL TABLE foo ( columnA string, columnB string) PARTITIONED BY (date string)ROW FORMAT DELIMITEDFIELDS TERMINATED BY &quot;\\t&quot;STORED ASINPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;LOCATION &apos;/path/to/hive/tables/foo&apos;; &#x4FEE;&#x6539;&#x8868;&#x4E3A;lzo&#x5B58;&#x50A8;&#x683C;&#x5F0F;&#x5BF9;&#x4E8E;&#x5DF2;&#x7ECF;&#x521B;&#x5EFA;&#x597D;&#x7684;&#x8868;&#xFF0C;&#x4F7F;&#x7528;alter&#x8BED;&#x53E5;&#xFF0C;&#x5C06;&#x5176;&#x4FEE;&#x6539;&#x4E3A;lzo&#x5B58;&#x50A8;&#x683C;&#x5F0F; 1234ALTER TABLE fooSET FILEFORMATINPUTFORMAT &quot;com.hadoop.mapred.DeprecatedLzoTextInputFormat&quot;OUTPUTFORMAT &quot;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&quot;; &#x63D2;&#x5165;&#x6570;&#x636E;&#x9700;&#x8981;&#x6DFB;&#x52A0;&#x4E0B;&#x9762;&#x4E24;&#x4E2A;&#x53C2;&#x6570; 12SET hive.exec.compress.output=true;SET mapred.output.compression.codec=com.hadoop.compression.lzo.LzopCodec; hadoop&#x538B;&#x7F29;&#x65B9;&#x6848; &#x5355;&#x7EAF;hdfs&#x6587;&#x4EF6;&#xFF0C;&#x63A8;&#x8350;&#x4F7F;&#x7528;lzo&#x683C;&#x5F0F;&#xFF0C;&#x89E3;&#x538B;&#x7F29;&#x548C;&#x538B;&#x7F29;&#x6BD4;&#x90FD;&#x6BD4;&#x8F83;&#x5747;&#x8861;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4F7F;&#x7528;hadoop fs -text xx.log &#x67E5;&#x770B;&#x6587;&#x4EF6;&#x5185;&#x5BB9; hive&#x63A8;&#x8350;&#x4F7F;&#x7528;ORCfile Hbase&#x63A8;&#x8350;&#x4F7F;&#x7528;snappy&#x8FDB;&#x884C;&#x538B;&#x7F29; spark sql&#x548C;impala&#xFF0C;&#x63A8;&#x8350;&#x4F7F;&#x7528;parquet &#x53C2;&#x8003; Hadoop at Twitter (part 1): Splittable LZO Compression Do we need to create an index file (with lzop) if compression type is RECORD instead of block? What&#x2019;s the difference between the LzoCodec and the LzopCodec in Hadoop-LZO? HDFS&#x4E2D;&#x6587;&#x4EF6;&#x7684;&#x538B;&#x7F29;&#x4E0E;&#x89E3;&#x538B; Hadoop, how to compress mapper output but not the reducer output mapreduce&#x4E2D;&#x7684;&#x538B;&#x7F29; mapred-default.xml Hadoop&#x5217;&#x5F0F;&#x5B58;&#x50A8;&#x5F15;&#x64CE;Parquet/ORC&#x548C;snappy&#x538B;&#x7F29; IBM Developerworks: Hadoop &#x538B;&#x7F29;&#x5B9E;&#x73B0;&#x5206;&#x6790;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"}]},{"title":"HBase数据丢失恢复","slug":"hbase-meta-repair","date":"2016-09-12T15:46:46.000Z","updated":"2016-10-19T10:02:04.000Z","comments":true,"path":"2016/09/12/hbase-meta-repair/","link":"","permalink":"http://wzktravel.github.io/2016/09/12/hbase-meta-repair/","excerpt":"关于HBase数据丢失恢复，可以详细看一下华为的这篇文章http://support.huawei.com/ecommunity/bbs/10242725.html，里面不止对原理进行讲解，而且有具体的场景演示和解决方案。","text":"&#x5173;&#x4E8E;HBase&#x6570;&#x636E;&#x4E22;&#x5931;&#x6062;&#x590D;&#xFF0C;&#x53EF;&#x4EE5;&#x8BE6;&#x7EC6;&#x770B;&#x4E00;&#x4E0B;&#x534E;&#x4E3A;&#x7684;&#x8FD9;&#x7BC7;&#x6587;&#x7AE0;http://support.huawei.com/ecommunity/bbs/10242725.html&#xFF0C;&#x91CC;&#x9762;&#x4E0D;&#x6B62;&#x5BF9;&#x539F;&#x7406;&#x8FDB;&#x884C;&#x8BB2;&#x89E3;&#xFF0C;&#x800C;&#x4E14;&#x6709;&#x5177;&#x4F53;&#x7684;&#x573A;&#x666F;&#x6F14;&#x793A;&#x548C;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002; &#x4ECA;&#x5929;hbase&#x7684;&#x4E00;&#x53F0;region server&#x6302;&#x6389;&#xFF0C;&#x91CD;&#x542F;&#x540E;&#x8FDB;&#x884C;&#x67E5;&#x8BE2;&#xFF0C;&#x53D1;&#x73B0;&#x6709;&#x4E9B;&#x7EAA;&#x5F55;&#x67E5;&#x8BE2;&#x5931;&#x8D25;&#xFF0C;&#x62A5;Region is not online&#x7684;&#x5F02;&#x5E38;&#x3002; 12345org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.NotServingRegionException): org.apache.hadoop.hbase.NotServingRegionException: Region HJSTATE,9223370681872375807_199999,1459388712948.cfc561817b17589e451b2d585105580a. is not online on hbaseserver1,60020,1473686838114at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2920)at org.apache.hadoop.hbase.regionserver.RSRpcServices.getRegion(RSRpcServices.java:1053)at org.apache.hadoop.hbase.regionserver.RSRpcServices.scan(RSRpcServices.java:2385)... &#x9996;&#x5148;&#x68C0;&#x67E5;&#x4E86;HDFS&#x662F;&#x5426;&#x5B58;&#x5728;&#x6570;&#x636E;&#x4E22;&#x5931;&#x7684;&#x60C5;&#x51B5;&#xFF0C; 1hdfs fsck -list-corruptfileblocks &#x6CA1;&#x6709;&#x53D1;&#x73B0;&#x6709;&#x574F;&#x5757;&#x3002; &#x7136;&#x540E;&#x68C0;&#x67E5;hbase&#x96C6;&#x7FA4;&#x72B6;&#x6001;&#xFF0C; 1hbase hbck &#x679C;&#x7136;&#x51FA;&#x73B0;&#x4E00;&#x4E9B;ERROR&#x4FE1;&#x606F;&#xFF0C;&#x8FDB;&#x884C;&#x4FEE;&#x590D;&#xFF0C; 1hbase hbck -repair HBase&#x67D0;&#x4E9B;&#x6B63;&#x5E38;&#x6D41;&#x7A0B;(Region split, Region assign&#x7B49;)&#xFF0C;&#x4F1A;&#x5BFC;&#x81F4;HBCK&#x68C0;&#x67E5;&#x51FA;&#x96C6;&#x7FA4;&#x72B6;&#x6001;&#x4E3A;&#x5F02;&#x5E38;&#x3002;&#x8981;&#x786E;&#x5B9A;&#x96C6;&#x7FA4;&#x5F02;&#x5E38;&#xFF0C;&#x6700;&#x597D;&#x8FDE;&#x7EED;&#x6267;&#x884C;HBCK&#xFF0C;&#x4E14;&#x6BCF;&#x6B21;&#x5F02;&#x5E38;&#x90FD;&#x76F8;&#x540C;&#xFF0C;&#x624D;&#x80FD;&#x786E;&#x5B9A;&#x96C6;&#x7FA4;&#x51FA;&#x73B0;&#x5F02;&#x5E38;&#x3002; hbck&#x547D;&#x4EE4;&#x8BE6;&#x60C5;&#x67E5;&#x8BE2;&#x5B98;&#x7F51;http://hbase.apache.org/book.html#hbck.in.depth","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hbase","slug":"hbase","permalink":"http://wzktravel.github.io/tags/hbase/"}]},{"title":"Hbase修改表名","slug":"how-to-rename-hbase-table","date":"2016-09-09T10:53:23.000Z","updated":"2016-09-09T10:56:37.000Z","comments":true,"path":"2016/09/09/how-to-rename-hbase-table/","link":"","permalink":"http://wzktravel.github.io/2016/09/09/how-to-rename-hbase-table/","excerpt":"","text":"&#x9700;&#x8981;&#x5F00;&#x542F;&#x5FEB;&#x7167;&#x529F;&#x80FD;&#xFF0C;&#x5728;hbase-site.xml&#x6587;&#x4EF6;&#x4E2D;&#x6DFB;&#x52A0;&#x5982;&#x4E0B;&#x914D;&#x7F6E;&#x9879;&#xFF1A; 1234&lt;property&gt; &lt;name&gt;hbase.snapshot.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; &#x8FDB;&#x5165;hbase shell&#x6267;&#x884C;&#xFF1A; 12345hbase shell&gt; disable &apos;tableName&apos;hbase shell&gt; snapshot &apos;tableName&apos;, &apos;tableSnapshot&apos;hbase shell&gt; clone_snapshot &apos;tableSnapshot&apos;, &apos;newTableName&apos;hbase shell&gt; delete_snapshot &apos;tableSnapshot&apos;hbase shell&gt; drop &apos;tableName&apos;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hbase","slug":"hbase","permalink":"http://wzktravel.github.io/tags/hbase/"}]},{"title":"elasticsearch2.3.1升级到2.3.5过程","slug":"elasticsearch-upgrade","date":"2016-09-01T06:09:33.000Z","updated":"2017-02-06T12:10:41.000Z","comments":true,"path":"2016/09/01/elasticsearch-upgrade/","link":"","permalink":"http://wzktravel.github.io/2016/09/01/elasticsearch-upgrade/","excerpt":"由于在使用2.3.1版本elasticsearch过程中发现经常出现异常RemoteTransportException - AlreadyClosedException[this IndexReader is closed]，发现是在2.3.0中引入的一个bug，在2.3.3中进行了修复，所以对其进行了升级。在小版本之间升级可以进行滚动升级(Rolling upgrades)，但大版本之间就只能集群重启升级(Full cluster restart upgrade)。 异常相关信息可以参考https://discuss.elastic.co/t/remotetransportexception-alreadyclosedexception-this-indexreader-is-closed/49577","text":"&#x7531;&#x4E8E;&#x5728;&#x4F7F;&#x7528;2.3.1&#x7248;&#x672C;elasticsearch&#x8FC7;&#x7A0B;&#x4E2D;&#x53D1;&#x73B0;&#x7ECF;&#x5E38;&#x51FA;&#x73B0;&#x5F02;&#x5E38;RemoteTransportException - AlreadyClosedException[this IndexReader is closed]&#xFF0C;&#x53D1;&#x73B0;&#x662F;&#x5728;2.3.0&#x4E2D;&#x5F15;&#x5165;&#x7684;&#x4E00;&#x4E2A;bug&#xFF0C;&#x5728;2.3.3&#x4E2D;&#x8FDB;&#x884C;&#x4E86;&#x4FEE;&#x590D;&#xFF0C;&#x6240;&#x4EE5;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x4E86;&#x5347;&#x7EA7;&#x3002;&#x5728;&#x5C0F;&#x7248;&#x672C;&#x4E4B;&#x95F4;&#x5347;&#x7EA7;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x6EDA;&#x52A8;&#x5347;&#x7EA7;(Rolling upgrades)&#xFF0C;&#x4F46;&#x5927;&#x7248;&#x672C;&#x4E4B;&#x95F4;&#x5C31;&#x53EA;&#x80FD;&#x96C6;&#x7FA4;&#x91CD;&#x542F;&#x5347;&#x7EA7;(Full cluster restart upgrade)&#x3002; &#x5F02;&#x5E38;&#x76F8;&#x5173;&#x4FE1;&#x606F;&#x53EF;&#x4EE5;&#x53C2;&#x8003;https://discuss.elastic.co/t/remotetransportexception-alreadyclosedexception-this-indexreader-is-closed/49577 &#x5148;&#x51B3;&#x51C6;&#x5907;&#x4E0B;&#x8F7D;&#x89E3;&#x538B;&#x4ECE;ElasticSearch Download&#x9875;&#x9762;&#x4E0B;&#x8F7D;&#x6700;&#x65B0;&#x7684;&#x7A33;&#x5B9A;&#x7248;&#x672C;&#xFF0C;&#x5F53;&#x524D;&#x662F;2.3.5&#x3002; &#x6211;&#x4EEC;&#x7684;&#x670D;&#x52A1;&#x4E00;&#x822C;&#x653E;&#x7F6E;&#x5728;/opt/fs&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;fssvc0035&#x7528;&#x6237;&#x542F;&#x52A8;&#xFF0C;&#x6240;&#x4EE5;&#x5C06;&#x4E0B;&#x8F7D;&#x7684;tar&#x5305;&#x89E3;&#x538B;&#x5230;/opt/fs&#x76EE;&#x5F55;&#x4E0B;&#x5373;&#x53EF;&#x3002; 12345[fssvc0035@machine fs]$ lltotal 68216lrwxrwxrwx 1 fssvc0035 fsgrp0023 19 Aug 31 18:39 elasticsearch -&gt; elasticsearch-2.3.1drwxr-sr-x 8 fssvc0035 fsgrp0023 4096 Aug 31 18:38 elasticsearch-2.3.1drwxr-sr-x 7 fssvc0035 fsgrp0023 4096 Aug 31 19:57 elasticsearch-2.3.5 &#x4E3A;&#x4E86;&#x4FBF;&#x4E8E;&#x5347;&#x7EA7;&#x548C;supervisor&#x6258;&#x7BA1;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x8F6F;&#x94FE;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x4F7F;elasticsearch&#x4FDD;&#x6301;&#x6307;&#x5411;&#x6700;&#x65B0;&#x7684;&#x7248;&#x672C;&#x3002;&#x5F53;&#x524D;&#x672A;&#x5347;&#x7EA7;&#x4E4B;&#x524D;&#x6307;&#x5411;2.3.1&#x7248;&#x672C;&#xFF0C;&#x5347;&#x7EA7;&#x5B8C;&#x4E4B;&#x540E;&#x9700;&#x8981;&#x624B;&#x52A8;&#x4FEE;&#x6539;&#x8F6F;&#x94FE;&#x5230;2.3.5&#x7248;&#x672C;&#x3002; bin/elasticsearch.in.sh&#x914D;&#x7F6E; es&#x9ED8;&#x8BA4;xms&#x662F;256m&#xFF0C;xmx&#x662F;1g&#xFF0C;&#x5728;&#x751F;&#x4EA7;&#x73AF;&#x5883;&#x4E2D;&#x592A;&#x5C40;&#x4FC3;&#x4E86;&#xFF0C;&#x9700;&#x8981;&#x4FEE;&#x6539;&#x3002; 123456if [ &quot;x$ES_MIN_MEM&quot; = &quot;x&quot; ]; then ES_MIN_MEM=6gfiif [ &quot;x$ES_MAX_MEM&quot; = &quot;x&quot; ]; then ES_MAX_MEM=6gfi &#x4FEE;&#x6539;gc&#x7B97;&#x6CD5;&#xFF0C;&#x7531;CMS&#x6539;&#x4E3A;G1 12345678if [ &quot;x$ES_GC_OPTS&quot; = &quot;x&quot; ]; then# ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:+UseParNewGC&quot;# ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:+UseConcMarkSweepGC&quot;# ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:CMSInitiatingOccupancyFraction=75&quot;# ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:+UseCMSInitiatingOccupancyOnly&quot; ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:+UseG1GC&quot; ES_GC_OPTS=&quot;$ES_GC_OPTS -XX:MaxGCPauseMillis=200&quot;fi conf/elasticsearch.yml&#x914D;&#x7F6E;&#x4ECE;&#x4E4B;&#x524D;&#x7684;es&#x914D;&#x7F6E;&#x4E2D;&#x590D;&#x5236;&#x4E00;&#x4EFD;&#x5373;&#x53EF;&#xFF0C;&#x6709;&#x51E0;&#x4E2A;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x5730;&#x65B9;: cluster.name&#x4E0E;&#x4E4B;&#x524D;&#x4FDD;&#x6301;&#x4E00;&#x81F4; node.name&#x6839;&#x636E;&#x9700;&#x8981;&#x4FEE;&#x6539;&#xFF0C;&#x65B0;&#x589E;&#x8282;&#x70B9;&#x6216;&#x8005;&#x8FC1;&#x79FB;&#x673A;&#x5668;&#x9700;&#x8981;&#x6CE8;&#x610F; path.data path.logs discovery.zen.ping.unicast.hosts&#x6839;&#x636E;&#x9700;&#x8981;&#x4FEE;&#x6539;&#xFF0C;&#x65B0;&#x589E;&#x8282;&#x70B9;&#x6216;&#x8005;&#x8FC1;&#x79FB;&#x673A;&#x5668;&#x9700;&#x8981;&#x6CE8;&#x610F; &#x53BB;&#x9664;marvel&#x63D2;&#x4EF6;&#x914D;&#x7F6E;&#xFF0C;&#x4E0D;&#x518D;&#x4F7F;&#x7528;marvel&#x6765;&#x505A;&#x76D1;&#x63A7; &#x5176;&#x4ED6;&#x4E00;&#x4E9B;&#x914D;&#x7F6E; 123456789101112131415161718192021222324252627script.engine.groovy.inline.aggs: onscript.engine.groovy.inline.update: ondiscovery.zen.ping_timeout: 20sdiscovery.zen.ping_retries: 6discovery.zen.ping.multicast.enabled: falseindex.cache.field.type: softindex.cache.field.max_size: 10000000index.cache.field.expire: 10mindex.unassigned.node_left.delayed_timeout: 5mcluster.routing.allocation.node_initial_primaries_recoveries: 10cluster.routing.allocation.node_concurrent_recoveries: 5indices.recovery.max_bytes_per_sec: 100mbindices.recovery.concurrent_streams: 5index.search.slowlog.threshold.query.warn: 10sindex.search.slowlog.threshold.query.info: 5sindex.search.slowlog.threshold.query.debug: 2sindex.search.slowlog.threshold.query.trace: 500msindex.search.slowlog.threshold.fetch.warn: 1sindex.search.slowlog.threshold.fetch.info: 800msindex.search.slowlog.threshold.fetch.debug: 500msindex.search.slowlog.threshold.fetch.trace: 200msindex.indexing.slowlog.threshold.index.warn: 10sindex.indexing.slowlog.threshold.index.info: 5sindex.indexing.slowlog.threshold.index.debug: 2sindex.indexing.slowlog.threshold.index.trace: 500ms &#x5B89;&#x88C5;&#x63D2;&#x4EF6;&#x63D2;&#x4EF6;&#x6E05;&#x5355;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#xFF1A;Elasticsearch 2.2.0 &#x63D2;&#x4EF6;&#x7BC7;&#xFF1A;&#x63D2;&#x4EF6;&#x6E05;&#x5355; &#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x4F7F;&#x7528;&#x8FD9;&#x4E24;&#x4E2A;&#x63D2;&#x4EF6;&#xFF0C;&#x5728;es&#x76EE;&#x5F55;&#x4E0B;&#x6267;&#x884C;&#x4E0B;&#x9762;&#x4E24;&#x4E2A;&#x547D;&#x4EE4; 12$ bin/plugin install license$ bin/plugin install lmenezes/elasticsearch-kopf elasticsearch&#x6709;&#x5F88;&#x591A;&#x4F18;&#x79C0;&#x7684;&#x63D2;&#x4EF6;&#xFF0C;&#x6839;&#x636E;&#x9700;&#x8981;&#x6DFB;&#x52A0;&#x3002;&#x6CE8;&#x610F;&#x63D2;&#x4EF6;&#x5728;&#x5347;&#x7EA7;elasticsearch&#x65F6;&#x9700;&#x8981;&#x4E00;&#x8D77;&#x5347;&#x7EA7;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x6709;&#x4E9B;&#x63D2;&#x4EF6;&#x9700;&#x8981;&#x81EA;&#x5DF1;&#x7F16;&#x8BD1;&#xFF0C;&#x4E0D;&#x80FD;&#x5355;&#x7EAF;&#x4F7F;&#x7528;&#x4E0A;&#x9762;&#x7684;&#x547D;&#x4EE4;&#x5B89;&#x88C5;&#x3002; supervisor&#x6258;&#x7BA1;&#x6211;&#x4EEC;&#x4F7F;&#x7528;supervisor&#x5BF9;elasticsearch&#x8FDB;&#x884C;&#x6258;&#x7BA1;&#xFF0C;&#x8001;&#x7684;elasticsearch&#x76EE;&#x5F55;&#x4E0B;&#x5DF2;&#x7ECF;&#x5B58;&#x5728;service.sh&#xFF0C;&#x5C06;&#x6B64;&#x6587;&#x4EF6;&#x590D;&#x5236;&#x5230;&#x65B0;&#x7684;elasticsearch&#x76EE;&#x5F55;&#x4E0B;&#x5373;&#x53EF;&#xFF0C;&#x4F7F;&#x7528;&#x6B64;&#x811A;&#x672C;&#x53EF;&#x4EE5;&#x5BF9;&#x670D;&#x52A1;&#x8FDB;&#x884C;&#x542F;&#x505C;&#x7B49;&#x64CD;&#x4F5C;&#x3002; &#x6EDA;&#x52A8;&#x5B89;&#x88C5;&#x57FA;&#x672C;&#x6309;&#x7167;&#x5B98;&#x7F51;Rolling upgrades&#x6765;&#x64CD;&#x4F5C;&#xFF0C;&#x6709;&#x4E9B;&#x7EC6;&#x8282;&#x6839;&#x636E;&#x6211;&#x4EEC;&#x7684;&#x73AF;&#x5883;&#x505A;&#x4E86;&#x76F8;&#x5E94;&#x6539;&#x53D8;&#x3002; Step 1: Disable shard allocation12345$ curl -XPUT localhost:9200/_cluster/settings -d &apos;{ &quot;transient&quot;: { &quot;cluster.routing.allocation.enable&quot; : &quot;none&quot; }}&apos; Step 2: Stop non-essential indexing and perform a synced flush (Optional)1$ curl -XPOST localhost:9200/_flush/synced &#x6267;&#x884C;&#x65F6;&#x95F4;&#x7565;&#x957F;&#xFF0C;&#x7A0D;&#x4F5C;&#x7B49;&#x5F85;&#x3002; Step 3: Stop and upgrade a single node&#x524D;&#x9762;&#x5DF2;&#x7ECF;&#x8BF4;&#x8FC7;&#xFF0C;&#x4F7F;&#x7528;supervisor&#x6258;&#x7BA1;&#xFF0C;&#x6240;&#x4EE5;&#x76F4;&#x63A5;&#x6267;&#x884C;sh service.sh stop&#x5373;&#x53EF;&#x3002; Step 4: Start the upgraded node&#x6B64;&#x65F6;&#x9700;&#x8981;&#x4FEE;&#x6539;elasticsearch&#x8F6F;&#x94FE;&#x7684;&#x6307;&#x5411;&#x4F4D;&#x7F6E;&#xFF0C;&#x4F7F;&#x5176;&#x6307;&#x5411;&#x65B0;&#x7684;&#x7248;&#x672C;&#x3002; 12345[fssvc0035@machine fs]$ lltotal 68216lrwxrwxrwx 1 fssvc0035 fsgrp0023 19 Aug 31 18:39 elasticsearch -&gt; elasticsearch-2.3.5drwxr-sr-x 8 fssvc0035 fsgrp0023 4096 Aug 31 18:38 elasticsearch-2.3.1drwxr-sr-x 7 fssvc0035 fsgrp0023 4096 Aug 31 19:57 elasticsearch-2.3.5 &#x7136;&#x540E;&#x8FDB;&#x5165;elasticsearch&#x76EE;&#x5F55;(&#x4E0D;&#x53EF;&#x4EE5;&#x662F;elasticsearch-2.3.5&#x76EE;&#x5F55;&#xFF0C;&#x8FD9;&#x4E0E;supervisor&#x4E2D;elasticsearch&#x914D;&#x7F6E;&#x6709;&#x5173;&#xFF0C;&#x6307;&#x5411;&#x7684;&#x8DEF;&#x5F84;&#x662F;elasticsearch&#xFF0C;&#x800C;&#x4E0D;&#x662F;elasticsearch-2.3.5)&#xFF0C;&#x4E0E;&#x505C;&#x6B62;elasticsearch&#x7C7B;&#x4F3C;&#xFF0C;&#x4F7F;&#x7528;sh service.sh start&#x5373;&#x53EF;&#x542F;&#x52A8;&#x670D;&#x52A1;&#x3002; &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x7684;&#x547D;&#x4EE4;&#x67E5;&#x770B;&#x672C;&#x673A;&#x72B6;&#x6001; 1curl -XGET localhost:9200 &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x7684;&#x547D;&#x4EE4;&#x67E5;&#x770B;&#x6B64;&#x8282;&#x70B9;&#x662F;&#x5426;&#x5DF2;&#x7ECF;&#x52A0;&#x5165;&#x5230;&#x96C6;&#x7FA4;&#x4E2D;&#x3002; 1curl -XGET localhost:9200/_cat/nodes &#x542F;&#x52A8;&#x65F6;&#x9047;&#x5230;&#x8FC7;&#x5F02;&#x5E38;No custom metadata prototype registered for type [licenses], node like missing plugins]&#xFF0C;&#x7ECF;&#x67E5;&#x662F;&#x6CA1;&#x6709;license&#x63D2;&#x4EF6;&#x5F15;&#x8D77;&#x7684;&#xFF0C;&#x53EA;&#x9700;&#x6309;&#x51C6;&#x5907;&#x9636;&#x6BB5;&#x6B65;&#x9AA4;&#x5B89;&#x88C5;&#x76F8;&#x5173;&#x63D2;&#x4EF6;&#x5373;&#x53EF;&#x3002; Step 5: Reenable shard allocation12345678$ curl -XPUT localhost:9200/_cluster/settings -d &apos;{ &quot;transient&quot;: { &quot;cluster.routing.allocation.enable&quot; : &quot;all&quot; }}&apos;## result{&quot;acknowledged&quot;:true,&quot;persistent&quot;:{},&quot;transient&quot;:{&quot;cluster&quot;:{&quot;routing&quot;:{&quot;allocation&quot;:{&quot;enable&quot;:&quot;all&quot;}}}}} Step 6: Wait for the node to recover&#x4F7F;&#x7528;&#x4EE5;&#x4E0B;&#x547D;&#x4EE4;&#x68C0;&#x67E5;&#x96C6;&#x7FA4;&#x72B6;&#x6001;&#xFF0C;&#x5206;&#x4E3A;red, yellow, green&#x4E09;&#x79CD;&#x72B6;&#x6001;&#x3002; 1curl -XGET localhost:9200/_cat/health &#x4F7F;&#x7528;&#x4EE5;&#x4E0B;&#x547D;&#x4EE4;&#x67E5;&#x770B;&#x6062;&#x590D;&#x60C5;&#x51B5; 1curl -XGET localhost:9200/_cat/recovery Step 7: Repeat&#x7B49;&#x5230;&#x96C6;&#x7FA4;&#x5B8C;&#x5168;&#x6062;&#x590D;&#x540E;(&#x96C6;&#x7FA4;&#x72B6;&#x6001;&#x4E3A;green&#xFF0C;reshard&#x7ED3;&#x675F;)&#xFF0C;&#x518D;&#x8FDB;&#x884C;&#x4E0B;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x7684;&#x5347;&#x7EA7;&#x3002; &#x53C2;&#x8003; ElasticSearch Rolling upgrades ElasticSearch Download Elasticsearch 2.2.0 &#x63D2;&#x4EF6;&#x7BC7;&#xFF1A;&#x63D2;&#x4EF6;&#x6E05;&#x5355;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://wzktravel.github.io/tags/elasticsearch/"}]},{"title":"自动登录到linux机器","slug":"auto-login-using-ssh","date":"2016-08-24T07:28:06.000Z","updated":"2016-09-01T06:10:16.000Z","comments":true,"path":"2016/08/24/auto-login-using-ssh/","link":"","permalink":"http://wzktravel.github.io/2016/08/24/auto-login-using-ssh/","excerpt":"使用sshpass实现的一个自动登录脚本。","text":"&#x4F7F;&#x7528;sshpass&#x5B9E;&#x73B0;&#x7684;&#x4E00;&#x4E2A;&#x81EA;&#x52A8;&#x767B;&#x5F55;&#x811A;&#x672C;&#x3002; 12345678910111213141516171819#!/bin/bashuser=userpassword=passwordip=$1prefix=192.12.port=22cmd=pwdrealip=flag=$(echo $ip | awk &apos;/${prefix}|vlnx|VLNX/&apos;)if [[ $flag = &quot;&quot; ]]; then realip=${prefix}${ip}else realip=${ip}fiecho &quot;ssh ${user}@${realip}&quot;sshpass -p ${password} ssh -o BatchMode=no -o StrictHostKeyChecking=no -l ${user} -p ${port} ${realip} -t &quot;$cmd; bash --login&quot; &#x53C2;&#x8003; http://tcl.tk/man/tcl8.6/TclCmd/Tcl.htm sshpass man page [sshpass sourceforge][https://sourceforge.net/projects/sshpass/]","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"一个有趣的canvas","slug":"have-fun-with-canvas","date":"2016-08-24T03:17:22.000Z","updated":"2016-12-28T10:02:33.000Z","comments":true,"path":"2016/08/24/have-fun-with-canvas/","link":"","permalink":"http://wzktravel.github.io/2016/08/24/have-fun-with-canvas/","excerpt":"发现一个有趣的canvas，可以改改给女朋友一个惊喜。","text":"&#x53D1;&#x73B0;&#x4E00;&#x4E2A;&#x6709;&#x8DA3;&#x7684;canvas&#xFF0C;&#x53EF;&#x4EE5;&#x6539;&#x6539;&#x7ED9;&#x5973;&#x670B;&#x53CB;&#x4E00;&#x4E2A;&#x60CA;&#x559C;&#x3002; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Canvas&lt;/title&gt; &lt;style&gt; html,body{height:100%}body{margin:0;padding:0;width:100%;background-color:#000;color:#b0bec5;display:table;font-weight:100;font-family:&apos;Lato&apos;}.container{text-align:center;display:table-cell;vertical-align:middle}.content{text-align:center;display:inline-block}.title{font-size:96px;margin-bottom:40px}.quote{font-size:24px}.qr{margin:20px 20px 0 0} &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;div&gt; &lt;canvas id=&quot;canvas&quot; width=&quot;1920&quot; height=&quot;454&quot;&gt;&lt;/canvas&gt; &lt;/div&gt; &lt;/div&gt; &lt;script&gt; function tick() { ctx.clearRect(0, 0, cw, ch), ctx.drawImage(bufferCanvas, 0, 0, current, txtH, sx, sy, current, txtH), ctx.save(), ctx.globalAlpha = .05, ctx.globalCompositeOperation = &quot;lighter&quot;, drawRays(current) ? (current++, current = Math.min(current, txtW), window.requestAnimationFrame(tick)) : fadeOut(), ctx.restore() } function fadeOut() { ctx.clearRect(0, 0, cw, ch), ctx.globalAlpha *= .95, ctx.drawImage(bufferCanvas, 0, 0, current, txtH, sx, sy, current, txtH), ctx.globalAlpha &gt; .01 ? window.requestAnimationFrame(fadeOut) : window.setTimeout(restart, 500) } function restart() { for (var t = 0; t &lt; rays.length; t++) rays[t].reset(); ctx.globalAlpha = 1, buffer.clearRect(0, 0, txtW, txtH), current = 0, tick() } function drawRays(t) { var a = 0; ctx.beginPath(); for (var r = 0; r &lt; rays.length; r++) { var e = rays[r]; e.col &lt; t &amp;&amp; (a += e.draw()) } return ctx.stroke(), a !== rays.length } function Ray(t, a, r) { this.col = a, this.row = t; var e = sx + a, i = sy + t, n = r, x = txtH / 1.5, o = pi2 * (this.row - .5 * x) / x; 0 === o &amp;&amp; (o = (Math.random() - .5) * pi2); var c = .02 * Math.sign(o), s = 2 * pi * (this.col - .5 * txtW) / txtW; 0 === s &amp;&amp; (s = (Math.random() - .5) * pi); var l = .02 * Math.sign(s); c += .005 * (Math.random() - .5); var h = 0, d = 2 * Math.random() + 2, f = !1; this.reset = function () { s = 2 * pi * (this.col - .5 * txtW) / txtW, o = pi2 * (this.row - .5 * x) / x, 0 === o &amp;&amp; (o = .5 * -pi2), h = 0, f = !1 }; this.draw = function () { return 0 &gt; h ? (f || (buffer.fillStyle = n, buffer.fillRect(this.col, this.row, 1, 1), f = !0), 1) : (ctx.moveTo(e, i), ctx.quadraticCurveTo(e + Math.cos(s) * h * .5, i + Math.sin(s) * h * .5, e + Math.cos(o) * h, i + Math.sin(o) * h), o += c, s += l, h += Math.cos(o) * d, 0) } } var txt = &quot;Fuck you!&quot;, txtH = 50, font = &quot;sans-serif&quot;, bg = &quot;#000&quot;, rayColor1 = &quot;#f50057&quot;, rayColor2 = &quot;#e040fb&quot;, rayColor3 = &quot;#ffff00&quot;, canvas = document.getElementById(&quot;canvas&quot;), ctx = canvas.getContext(&quot;2d&quot;), cw = canvas.width = window.innerWidth, ch = canvas.height = window.innerHeight*0.5, w2 = cw / 2, h2 = ch / 2, pi = Math.PI, pi2 = .5 * pi, txtCanvas = document.createElement(&quot;canvas&quot;), txtCtx = txtCanvas.getContext(&quot;2d&quot;); txtCtx.font = txtH + &quot;px &quot; + font, txtCtx.textBaseline = &quot;middle&quot;; var txtW = Math.floor(txtCtx.measureText(txt).width); txtCanvas.width = txtW, txtCanvas.height = 1.2 * txtH; var gradient = ctx.createRadialGradient(w2, h2, 0, w2, h2, txtW); gradient.addColorStop(0, rayColor3), gradient.addColorStop(.5, rayColor2), gradient.addColorStop(1, rayColor1), ctx.strokeStyle = gradient, txtCtx.fillStyle = gradient, txtCtx.font = txtH + &quot;px &quot; + font, txtCtx.textBaseline = &quot;middle&quot;, txtCtx.fillText(txt, 0, .5 * txtH) txtH *= 1.5; var bufferCanvas = document.createElement(&quot;canvas&quot;); bufferCanvas.width = txtW, bufferCanvas.height = txtH; for (var buffer = bufferCanvas.getContext(&quot;2d&quot;), sx = .5 * (cw - txtW), sy = .5 * (ch - txtH), rays = [], txtData = txtCtx.getImageData(0, 0, txtW, txtH), i = 0; i &lt; txtData.data.length; i += 4) { var ii = i / 4, row = Math.floor(ii / txtW), col = ii % txtW, alpha = txtData.data[i + 3]; if (0 !== alpha) { var c = &quot;rgba(&quot;; c += [txtData.data[i], txtData.data[i + 1], txtData.data[i + 2], alpha / 255], c += &quot;)&quot;, rays.push(new Ray(Math.floor(ii / txtW), ii % txtW, c)) } } var current = 0; tick(); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;","categories":[],"tags":[{"name":"web","slug":"web","permalink":"http://wzktravel.github.io/tags/web/"}]},{"title":"如何在pg_dump时传入密码","slug":"How-to-pass-in-password-to-pg-dump","date":"2016-08-23T12:52:00.000Z","updated":"2016-08-23T13:11:53.000Z","comments":true,"path":"2016/08/23/How-to-pass-in-password-to-pg-dump/","link":"","permalink":"http://wzktravel.github.io/2016/08/23/How-to-pass-in-password-to-pg-dump/","excerpt":"在做postgres的备份时，需要定时执行pg_dump命令，这就需要在人不介入的情况传入密码，有两种方式可以实现。一是使用环境变量PGPASSWORD，二是使用.pgpass文件。","text":"&#x5728;&#x505A;postgres&#x7684;&#x5907;&#x4EFD;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x5B9A;&#x65F6;&#x6267;&#x884C;pg_dump&#x547D;&#x4EE4;&#xFF0C;&#x8FD9;&#x5C31;&#x9700;&#x8981;&#x5728;&#x4EBA;&#x4E0D;&#x4ECB;&#x5165;&#x7684;&#x60C5;&#x51B5;&#x4F20;&#x5165;&#x5BC6;&#x7801;&#xFF0C;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;&#x3002;&#x4E00;&#x662F;&#x4F7F;&#x7528;&#x73AF;&#x5883;&#x53D8;&#x91CF;PGPASSWORD&#xFF0C;&#x4E8C;&#x662F;&#x4F7F;&#x7528;.pgpass&#x6587;&#x4EF6;&#x3002; &#x4F7F;&#x7528;&#x73AF;&#x5883;&#x53D8;&#x91CF;PGPASSWORD&#x4F7F;&#x7528;crontab&#x6267;&#x884C;shell&#x811A;&#x672C;&#xFF0C;&#x5728;pg_dump&#x4E4B;&#x524D;&#xFF0C;&#x8BBE;&#x7F6E;&#x73AF;&#x5883;&#x53D8;&#x91CF;&#x3002;&#x793A;&#x4F8B;&#xFF1A; 12export PGPASSWORD=&quot;$pg_password&quot;pg_dump -p 7432 -U scm &gt; pg.dump &#x6216;&#x8005;&#x5728;&#x4E00;&#x884C;&#x547D;&#x4EE4;&#x4E2D; 1PGPASSWORD=&quot;$pg_password&quot; pg_dump -p 7432 -U scm &gt; pg.dump &#x6CE8;&#x610F;&#xFF1A;&#x8FD9;&#x79CD;&#x65B9;&#x6CD5;&#x56E0;&#x4E3A;&#x5B89;&#x5168;&#x6027;&#x95EE;&#x9898;&#xFF0C;&#x6240;&#x4EE5;&#x4E0D;&#x63A8;&#x8350;&#x4F7F;&#x7528;&#x3002; PGPASSWORD behaves the same as the password connection parameter. Use of this environment variable is not recommended for security reasons, as some operating systems allow non-root users to see process environment variables via ps; instead consider using the ~/.pgpass file @https://www.postgresql.org/docs/current/static/libpq-envars.html &#x4F7F;&#x7528;.pgpass&#x6587;&#x4EF6;&#x53C2;&#x8003;https://www.postgresql.org/docs/current/static/libpq-pgpass.html &#x5728;&#x4E3B;&#x76EE;&#x5F55;&#x4E0B;&#x65B0;&#x5EFA;~/.pgpass&#x6587;&#x4EF6;&#xFF0C;&#x5E76;&#x8D4B;&#x6743;&#x9650;&#x4E3A;600&#xFF0C;&#x6587;&#x4EF6;&#x5185;&#x5BB9;&#x4E3A; 1hostname:port:database:username:password","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"http://wzktravel.github.io/tags/sql/"},{"name":"postgres","slug":"postgres","permalink":"http://wzktravel.github.io/tags/postgres/"}]},{"title":"hive join遇到的问题及解决方法","slug":"hive-join-problem","date":"2016-08-22T07:29:16.000Z","updated":"2016-08-22T15:02:42.000Z","comments":true,"path":"2016/08/22/hive-join-problem/","link":"","permalink":"http://wzktravel.github.io/2016/08/22/hive-join-problem/","excerpt":"这几天遇到一个问题，hive在执行join操作时报错，return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask，又没有特别有用的信息，经过一番分析和搜索找到解决方法。在这里记录一下。","text":"&#x8FD9;&#x51E0;&#x5929;&#x9047;&#x5230;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;hive&#x5728;&#x6267;&#x884C;join&#x64CD;&#x4F5C;&#x65F6;&#x62A5;&#x9519;&#xFF0C;return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask&#xFF0C;&#x53C8;&#x6CA1;&#x6709;&#x7279;&#x522B;&#x6709;&#x7528;&#x7684;&#x4FE1;&#x606F;&#xFF0C;&#x7ECF;&#x8FC7;&#x4E00;&#x756A;&#x5206;&#x6790;&#x548C;&#x641C;&#x7D22;&#x627E;&#x5230;&#x89E3;&#x51B3;&#x65B9;&#x6CD5;&#x3002;&#x5728;&#x8FD9;&#x91CC;&#x8BB0;&#x5F55;&#x4E00;&#x4E0B;&#x3002; &#x95EE;&#x9898;&#x5728;&#x505A;&#x5927;&#x5C0F;&#x8868;&#x7684;join&#x65F6;&#x51FA;&#x73B0;&#x7684;&#xFF0C;&#x9519;&#x8BEF;&#x4FE1;&#x606F;&#x5982;&#x4E0B;&#x3002; 1234567891011121314org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:374) at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:180) at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:72) at org.apache.hive.service.cli.operation.SQLOperation$2$1.run(SQLOperation.java:232) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693) at org.apache.hive.service.cli.operation.SQLOperation$2.run(SQLOperation.java:245) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) &#x89E3;&#x51B3;&#x9996;&#x5148;&#x6CE8;&#x610F;&#x5230;&#x662F;MapredLocalTask&#xFF0C;&#x5F00;&#x542F;&#x4E86;&#x672C;&#x5730;&#x6A21;&#x5F0F;&#x3002;&#x90A3;&#x5173;&#x95ED;&#x672C;&#x5730;&#x6A21;&#x5F0F;&#x8BD5;&#x4E00;&#x4E0B;&#xFF0C; 1set hive.exec.mode.local.auto=false; &#x7ED3;&#x679C;&#x8FD8;&#x662F;&#x62A5;&#x76F8;&#x540C;&#x9519;&#x8BEF;&#xFF0C;&#x53EA;&#x80FD;&#x4ECE;&#x5176;&#x4ED6;&#x65B9;&#x9762;&#x8003;&#x8651;&#x3002; &#x5728;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;hive&#x7684;join&#x7B56;&#x7565;&#x662F;&#x8FDB;&#x884C;reduce side join&#xFF0C;&#x4F46;&#x662F;&#x5F53;&#x4E24;&#x4E2A;&#x8868;&#x4E2D;&#x6709;&#x4E00;&#x4E2A;&#x662F;&#x5C0F;&#x8868;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x5C31;&#x4F1A;&#x4F7F;&#x7528;map join&#xFF0C;&#x628A;&#x5176;&#x4E2D;&#x8F83;&#x5C0F;&#x7684;&#x4E00;&#x4E2A;&#x8868;&#x590D;&#x5236;&#x5230;&#x6240;&#x6709;&#x8282;&#x70B9;&#xFF0C;&#x8FD9;&#x6837;&#x53E6;&#x4E00;&#x4E2A;&#x8868;&#x5728;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;&#x4E0A;&#x9762;&#x7684;&#x5206;&#x7247;&#x5C31;&#x53EF;&#x4EE5;&#x8DDF;&#x8FD9;&#x4E2A;&#x5B8C;&#x6574;&#x7684;&#x8868;join&#x3002;&#x5206;&#x6790;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;job&#x4F7F;&#x7528;map join&#x65F6;&#x53EF;&#x80FD;&#x9020;&#x6210;&#x5185;&#x5B58;&#x6EA2;&#x51FA;&#xFF0C;&#x5173;&#x95ED;&#x5176;&#x81EA;&#x52A8;&#x88C5;&#x6362;&#x5C1D;&#x8BD5;&#x4E00;&#x4E0B;&#x3002; 1set hive.auto.convert.join = false; &#x679C;&#x7136;ok&#x4E86;&#x3002; &#x77E5;&#x8BC6;hive&#x672C;&#x5730;&#x6A21;&#x5F0F; 0.7&#x7248;&#x672C;&#x540E;Hive&#x5F00;&#x59CB;&#x652F;&#x6301;&#x4EFB;&#x52A1;&#x6267;&#x884C;&#x9009;&#x62E9;&#x672C;&#x5730;&#x6A21;&#x5F0F;(local mode)&#x3002;&#x5927;&#x591A;&#x6570;&#x7684;Hadoop job&#x662F;&#x9700;&#x8981;hadoop&#x63D0;&#x4F9B;&#x7684;&#x5B8C;&#x6574;&#x7684;&#x53EF;&#x6269;&#x5C55;&#x6027;&#x6765;&#x5904;&#x7406;&#x5927;&#x6570;&#x636E;&#x7684;&#x3002;&#x4E0D;&#x8FC7;&#xFF0C;&#x6709;&#x65F6;hive&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x91CF;&#x662F;&#x975E;&#x5E38;&#x5C0F;&#x7684;&#x3002;&#x5728;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x4E3A;&#x67E5;&#x8BE2;&#x51FA;&#x53D1;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x7684;&#x65F6;&#x95F4;&#x6D88;&#x8017;&#x53EF;&#x80FD;&#x4F1A;&#x6BD4;&#x5B9E;&#x9645;job&#x7684;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x8981;&#x591A;&#x7684;&#x591A;&#x3002;&#x5BF9;&#x4E8E;&#x5927;&#x591A;&#x6570;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;hive&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x672C;&#x5730;&#x6A21;&#x5F0F;&#x5728;&#x5355;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x5904;&#x7406;&#x6240;&#x6709;&#x7684;&#x4EFB;&#x52A1;&#x3002;&#x5BF9;&#x4E8E;&#x5C0F;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x4F1A;&#x660E;&#x663E;&#x88AB;&#x7F29;&#x77ED;&#x3002;&#x5982;&#x6B64;&#x4E00;&#x6765;&#xFF0C;&#x5BF9;&#x6570;&#x636E;&#x91CF;&#x6BD4;&#x8F83;&#x5C0F;&#x7684;&#x64CD;&#x4F5C;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x5728;&#x672C;&#x5730;&#x6267;&#x884C;&#xFF0C;&#x8FD9;&#x6837;&#x8981;&#x6BD4;&#x63D0;&#x4EA4;&#x4EFB;&#x52A1;&#x5230;&#x96C6;&#x7FA4;&#x6267;&#x884C;&#x6548;&#x7387;&#x8981;&#x5FEB;&#x5F88;&#x591A;&#x3002; &#x5F00;&#x542F;hive&#x672C;&#x5730;&#x6A21;&#x5F0F;&#x9700;&#x8981;&#x4E3B;&#x52A8;&#x914D;&#x7F6E;&#x5982;&#x4E0B;&#x53C2;&#x6570;:1hive&gt; set hive.exec.mode.local.auto=true; ## &#x9ED8;&#x8BA4;&#x4E3A;false &#x53E6;&#x5916;&#xFF0C;&#x5F00;&#x542F;&#x672C;&#x5730;&#x6A21;&#x5F0F;&#x540E;&#xFF0C;&#x4E5F;&#x9700;&#x8981;job&#x6EE1;&#x8DB3;&#x4E00;&#x5B9A;&#x6761;&#x4EF6;&#x624D;&#x80FD;&#x771F;&#x6B63;&#x4F7F;&#x7528;&#x672C;&#x5730;&#x6A21;&#x5F0F;: job&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x5927;&#x5C0F;&#x5FC5;&#x987B;&#x5C0F;&#x4E8E;&#x53C2;&#x6570;&#xFF1A;hive.exec.mode.local.auto.inputbytes.max&#xFF0C;&#x9ED8;&#x8BA4;128MB job&#x7684;map&#x6570;&#x5FC5;&#x987B;&#x5C0F;&#x4E8E;&#x53C2;&#x6570;&#xFF1A;hive.exec.mode.local.auto.tasks.max&#xFF0C;&#x9ED8;&#x8BA4;&#x4E3A;4 job&#x7684;reduce&#x6570;&#x5FC5;&#x987B;&#x4E3A;0&#x6216;&#x8005;1 hive join&#x7B97;&#x6CD5;&#x5904;&#x7406;&#x5206;&#x5E03;&#x5F0F;join&#xFF0C;&#x4E00;&#x822C;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#xFF1A; replication join&#xFF1A;&#x628A;&#x5176;&#x4E2D;&#x4E00;&#x4E2A;&#x8868;&#x590D;&#x5236;&#x5230;&#x6240;&#x6709;&#x8282;&#x70B9;&#xFF0C;&#x8FD9;&#x6837;&#x53E6;&#x4E00;&#x4E2A;&#x8868;&#x5728;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;&#x4E0A;&#x9762;&#x7684;&#x5206;&#x7247;&#x5C31;&#x53EF;&#x4EE5;&#x8DDF;&#x8FD9;&#x4E2A;&#x5B8C;&#x6574;&#x7684;&#x8868;join&#x4E86;&#xFF1B;&#x5728;M/R job&#x4E2D;&#x5BF9;&#x5E94;map side join&#x3002; repartition join&#xFF1A;&#x628A;&#x4E24;&#x4EFD;&#x6570;&#x636E;&#x6309;&#x7167;join key&#x8FDB;&#x884C;hash&#x91CD;&#x5206;&#x5E03;&#xFF0C;&#x8BA9;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;&#x5904;&#x7406;hash&#x503C;&#x76F8;&#x540C;&#x7684;join key&#x6570;&#x636E;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x505A;&#x5C40;&#x90E8;&#x7684;join&#xFF0C;&#x5728;M/R job&#x4E2D;&#x5BF9;&#x5E94;reduce side join&#x3002; reduce side join&#x5728;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;hive&#x7684;join&#x7B56;&#x7565;&#x662F;&#x8FDB;&#x884C;reduce side join&#x3002; map side join&#x5F53;&#x5927;&#x5C0F;&#x8868;&#x8FDB;&#x884C;join&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;map side join&#xFF0C;&#x56E0;&#x4E3A;&#x5C0F;&#x8868;&#x590D;&#x5236;&#x7684;&#x4EE3;&#x4EF7;&#x4F1A;&#x597D;&#x8FC7;&#x5927;&#x8868;Shuffle&#x7684;&#x4EE3;&#x4EF7;&#x3002;&#x4F7F;&#x7528;map side join&#xFF0C;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#xFF1A; &#x76F4;&#x63A5;&#x5728;sql&#x4E2D;&#x5199;hint&#xFF0C;&#x8BED;&#x6CD5;&#x662F;/*+MapJOIN (tbl)*/&#xFF0C;&#x5176;&#x4E2D;tbl&#x5C31;&#x662F;&#x4F60;&#x60F3;&#x8981;&#x505A;replication&#x7684;&#x8868;&#x3002; &#x8BBE;&#x7F6E;hive.auto.convert.join = true&#xFF0C;&#x8FD9;&#x6837;Hive&#x4F1A;&#x81EA;&#x52A8;&#x5224;&#x65AD;&#x5F53;&#x524D;&#x7684;join&#x64CD;&#x4F5C;&#x662F;&#x5426;&#x5408;&#x9002;&#x505A;map join&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x627E;join&#x7684;&#x4E24;&#x4E2A;&#x8868;&#x4E2D;&#x6709;&#x6CA1;&#x6709;&#x5C0F;&#x8868;&#x3002;&#x81F3;&#x4E8E;&#x591A;&#x5927;&#x7684;&#x8868;&#x7B97;&#x5C0F;&#x8868;&#xFF0C;&#x5219;&#x662F;&#x7531;hive.smalltable.filesize&#x51B3;&#x5B9A;&#xFF0C;&#x9ED8;&#x8BA4;25MB&#x3002; bucket map join&#x5F53;&#x6CA1;&#x6709;&#x4E00;&#x4E2A;&#x8868;&#x8DB3;&#x591F;&#x5C0F;&#x5230;&#x80FD;&#x591F;&#x653E;&#x8FDB;&#x5185;&#x5B58;&#xFF0C;&#x4F46;&#x662F;&#x8FD8;&#x662F;&#x60F3;&#x7528;map join&#x600E;&#x4E48;&#x529E;&#xFF1F;&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#x5C31;&#x8981;&#x7528;&#x5230;bucket map join&#x3002;&#x5176;&#x65B9;&#x6CD5;&#x662F;&#x4E24;&#x4E2A;join&#x8868;&#x5728;join key&#x4E0A;&#x90FD;&#x505A;hash bucket&#xFF0C;&#x5E76;&#x4E14;&#x628A;&#x4F60;&#x6253;&#x7B97;&#x590D;&#x5236;&#x7684;&#x90A3;&#x4E2A;&#xFF08;&#x76F8;&#x5BF9;&#xFF09;&#x5C0F;&#x8868;&#x7684;bucket&#x6570;&#x8BBE;&#x7F6E;&#x4E3A;&#x5927;&#x8868;&#x7684;&#x500D;&#x6570;&#x3002;&#x8FD9;&#x6837;&#x6570;&#x636E;&#x5C31;&#x4F1A;&#x6309;&#x7167;join key&#x505A;hash bucket&#x3002;&#x5C0F;&#x8868;&#x4F9D;&#x7136;&#x590D;&#x5236;&#x5230;&#x6240;&#x6709;&#x8282;&#x70B9;&#xFF0C;Map join&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x5C0F;&#x8868;&#x7684;&#x6BCF;&#x4E00;&#x7EC4;bucket&#x52A0;&#x8F7D;&#x6210;hashtable&#xFF0C;&#x4E0E;&#x5BF9;&#x5E94;&#x7684;&#x4E00;&#x4E2A;&#x5927;&#x8868;bucket&#x505A;&#x5C40;&#x90E8;join&#xFF0C;&#x8FD9;&#x6837;&#x6BCF;&#x6B21;&#x53EA;&#x9700;&#x8981;&#x52A0;&#x8F7D;&#x90E8;&#x5206;hashtable&#x5C31;&#x53EF;&#x4EE5;&#x4E86;&#x3002; sort merge bucket map join&#x5728;&#x4E24;&#x4E2A;&#x8868;&#x7684;join key&#x90FD;&#x5177;&#x6709;&#x552F;&#x4E00;&#x6027;&#x7684;&#x65F6;&#x5019;&#xFF08;&#x4E5F;&#x5C31;&#x662F;&#x53EF;&#x505A;&#x4E3B;&#x952E;&#xFF09;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x8FDB;&#x4E00;&#x6B65;&#x505A;sort merge bucket map join&#x3002;&#x505A;&#x6CD5;&#x8FD8;&#x662F;&#x4E24;&#x8FB9;&#x8981;&#x505A;hash bucket&#xFF0C;&#x800C;&#x4E14;&#x6BCF;&#x4E2A;bucket&#x5185;&#x90E8;&#x8981;&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#x3002;&#x8FD9;&#x6837;&#x4E00;&#x6765;&#x5F53;&#x4E24;&#x8FB9;bucket&#x8981;&#x505A;&#x5C40;&#x90E8;join&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x7528;&#x7C7B;&#x4F3C;merge Sort&#x7B97;&#x6CD5;&#x4E2D;&#x7684;merge&#x64CD;&#x4F5C;&#x4E00;&#x6837;&#x628A;&#x4E24;&#x4E2A;bucket&#x987A;&#x5E8F;&#x904D;&#x5386;&#x4E00;&#x904D;&#x5373;&#x53EF;&#x5B8C;&#x6210;&#xFF0C;&#x8FD9;&#x6837;&#x751A;&#x81F3;&#x90FD;&#x4E0D;&#x7528;&#x628A;&#x4E00;&#x4E2A;bucket&#x5B8C;&#x6574;&#x7684;&#x52A0;&#x8F7D;&#x6210;hashtable&#xFF0C;&#x8FD9;&#x5BF9;&#x6027;&#x80FD;&#x7684;&#x63D0;&#x5347;&#x4F1A;&#x6709;&#x5F88;&#x5927;&#x5E2E;&#x52A9;&#x3002; &#x53C2;&#x8003; hive join&#x9047;&#x5230;&#x95EE;&#x9898; &#x6DF1;&#x5165;&#x6D45;&#x51FA;&#x6570;&#x636E;&#x4ED3;&#x5E93;&#x4E2D;SQL&#x6027;&#x80FD;&#x4F18;&#x5316;&#x4E4B;Hive&#x7BC7; Hive Setting&#x8C03;&#x4F18;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hive","slug":"hive","permalink":"http://wzktravel.github.io/tags/hive/"}]},{"title":"elasticsearch搜索示例","slug":"elasticsearch-search-sample","date":"2016-08-21T06:09:26.000Z","updated":"2016-08-22T10:53:05.000Z","comments":true,"path":"2016/08/21/elasticsearch-search-sample/","link":"","permalink":"http://wzktravel.github.io/2016/08/21/elasticsearch-search-sample/","excerpt":"elasticsearch restful api和java api搜索示例。","text":"elasticsearch restful api&#x548C;java api&#x641C;&#x7D22;&#x793A;&#x4F8B;&#x3002; elasticsearch restful api1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768POST /datapt-logstatistic/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;range&quot;: { &quot;time&quot;: { &quot;lte&quot;: &quot;2016-08-22&quot;, &quot;gte&quot;: &quot;2016-08-21&quot; } } }, &quot;must&quot;: [ { &quot;term&quot;: { &quot;nav&quot;: &quot;iOS&quot; } }, { &quot;term&quot;: { &quot;key&quot;: &quot;M99.M1&quot; } } ] } }, &quot;size&quot;: 0, &quot;aggs&quot;: { &quot;stat&quot;: { &quot;terms&quot;: { &quot;field&quot;: &quot;value&quot;, &quot;size&quot;: 0, &quot;order&quot;: { &quot;totalCount&quot;: &quot;desc&quot; } }, &quot;aggs&quot;: { &quot;totalCount&quot;: { &quot;sum&quot;: { &quot;field&quot;: &quot;totalCount&quot; } }, &quot;successCount&quot;: { &quot;sum&quot;: { &quot;field&quot;: &quot;successCount&quot; } }, &quot;failCount&quot;: { &quot;sum&quot;: { &quot;field&quot;: &quot;failCount&quot; } }, &quot;failPercent&quot;: { &quot;bucket_script&quot;: { &quot;buckets_path&quot;: { &quot;fail&quot;: &quot;failCount&quot;, &quot;total&quot;: &quot;totalCount&quot; }, &quot;script&quot;: { &quot;lang&quot;: &quot;expression&quot;, &quot;inline&quot;: &quot;fail / total * 100&quot; } } } } } }} java api123456789101112131415161718192021222324252627282930313233343536List&lt;Map&lt;String, Object&gt;&gt; aggList = Lists.newLinkedList();// &#x805A;&#x5408;&#x524D;&#x8FDB;&#x884C;&#x67E5;&#x8BE2;, &#x5148;&#x8FC7;&#x6EE4;&#x51FA;&#x9700;&#x8981;&#x7684;&#x5185;&#x5BB9;BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();// &#x65F6;&#x95F4;&#x8303;&#x56F4;RangeQueryBuilder timeRangeBuilder = QueryBuilders.rangeQuery(&quot;time&quot;).lte(timeTo).gte(timeFrom);boolQuery.filter(timeRangeBuilder);// &#x5FC5;&#x987B;&#x5339;&#x914D;nav&#x548C;keyif (! Strings.isNullOrEmpty(nav)) { boolQuery.must(QueryBuilders.termQuery(&quot;nav&quot;, nav));}boolQuery.must(QueryBuilders.termQuery(&quot;key&quot;, key));SumBuilder totalCountAgg = AggregationBuilders.sum(&quot;totalCount&quot;).field(&quot;totalCount&quot;);SumBuilder successCountAgg = AggregationBuilders.sum(&quot;successCount&quot;).field(&quot;successCount&quot;);SumBuilder failCountAgg = AggregationBuilders.sum(&quot;failCount&quot;).field(&quot;failCount&quot;);TermsBuilder aggBuilder = AggregationBuilders .terms(&quot;stat&quot;) .field(&quot;value&quot;) .size(0) .order(Terms.Order.aggregation(&quot;totalCount&quot;, false)) .subAggregation(totalCountAgg) .subAggregation(successCountAgg) .subAggregation(failCountAgg);SearchRequestBuilder builder = ElasticSearchHelper.newBuilder(LOG_STATISTIC_INDEX);SearchResponse response;try { response = builder.setQuery(boolQuery) .addAggregation(aggBuilder) .get();} catch (Exception e) { LOG.error(&quot;Cannot get aggregations for nav {} and key {}&quot;, nav, key, e);}","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://wzktravel.github.io/tags/elasticsearch/"}]},{"title":"Memory Reserved on YARN","slug":"What-is-Memory-reserved-on-Yarn","date":"2016-08-17T07:57:44.000Z","updated":"2016-08-17T11:24:39.000Z","comments":true,"path":"2016/08/17/What-is-Memory-reserved-on-Yarn/","link":"","permalink":"http://wzktravel.github.io/2016/08/17/What-is-Memory-reserved-on-Yarn/","excerpt":"","text":"&#x5728;yarn&#x7684;resource manager&#x9875;&#x9762;&#x4E2D;&#x6709;&#x4E00;&#x9879;&#x662F;Memory Reserved&#xFF0C;&#x89E3;&#x91CA;&#x5982;&#x4E0B;: An implementation detail of this change that prevents applications from starving under this new flexibility is the notion of reserved containers. Imagine two jobs are running that each have enough tasks to saturate more than the entire cluster. One job wants each of its mappers to get 1GB, and another job wants its mappers to get 2GB. Suppose the first job starts and fills up the entire cluster. Whenever one of its task finishes, it will leave open a 1GB slot. Even though the second job deserves the space, a naive policy will give it to the first one because it&#x2019;s the only job with tasks that fit. This could cause the second job to be starved indefinitely. To prevent this unfortunate situation, when space on a node is offered to an application, if the application cannot immediately use it, it reserves it, and no other application can be allocated a container on that node until the reservation is fulfilled. Each node may have only one reserved container. The total reserved memory amount is reported in the ResourceManager UI. A high number means that it may take longer for new jobs to get space. &#x53C2;&#x8003;http://stackoverflow.com/a/28567229","categories":[],"tags":[{"name":"yarn","slug":"yarn","permalink":"http://wzktravel.github.io/tags/yarn/"}]},{"title":"linux删除文件后空间未释放的解决方法","slug":"recover-free-space-on-deleted-files","date":"2016-08-15T03:22:22.000Z","updated":"2016-09-05T03:10:23.000Z","comments":true,"path":"2016/08/15/recover-free-space-on-deleted-files/","link":"","permalink":"http://wzktravel.github.io/2016/08/15/recover-free-space-on-deleted-files/","excerpt":"在linux下有时会遇到一种情况，某个文件删除了，但是磁盘空间并没有释放。这是因为仍然有进程在使用此文件，其文件句柄没有被释放。下面介绍两种方式来解决此问题。","text":"&#x5728;linux&#x4E0B;&#x6709;&#x65F6;&#x4F1A;&#x9047;&#x5230;&#x4E00;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;&#x67D0;&#x4E2A;&#x6587;&#x4EF6;&#x5220;&#x9664;&#x4E86;&#xFF0C;&#x4F46;&#x662F;&#x78C1;&#x76D8;&#x7A7A;&#x95F4;&#x5E76;&#x6CA1;&#x6709;&#x91CA;&#x653E;&#x3002;&#x8FD9;&#x662F;&#x56E0;&#x4E3A;&#x4ECD;&#x7136;&#x6709;&#x8FDB;&#x7A0B;&#x5728;&#x4F7F;&#x7528;&#x6B64;&#x6587;&#x4EF6;&#xFF0C;&#x5176;&#x6587;&#x4EF6;&#x53E5;&#x67C4;&#x6CA1;&#x6709;&#x88AB;&#x91CA;&#x653E;&#x3002;&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#x6765;&#x89E3;&#x51B3;&#x6B64;&#x95EE;&#x9898;&#x3002; &#x91CD;&#x542F;&#x670D;&#x52A1;&#xFF0C;&#x91CA;&#x653E;&#x6587;&#x4EF6;&#x53E5;&#x67C4; &#x4F7F;&#x7528;lsof&#x627E;&#x5230;&#x8FD8;&#x5728;&#x4F7F;&#x7528;&#x6B64;&#x6587;&#x4EF6;&#x7684;&#x8FDB;&#x7A0B;&#x3002; 1$ lsof | fgrep &quot;deleted&quot; &#x6839;&#x636E;&#x4E0A;&#x9762;&#x5F97;&#x5230;&#x7684;pid&#xFF0C;&#x8FDB;&#x884C;&#x8FDB;&#x7A0B;&#x91CD;&#x542F;&#x6216;&#x76F4;&#x63A5;kill&#x6389;&#x6B64;&#x8FDB;&#x7A0B;&#xFF0C;&#x6B64;&#x65F6;&#x7A7A;&#x95F4;&#x4F1A;&#x88AB;&#x91CA;&#x653E;&#x3002; &#x4E0D;&#x91CD;&#x542F;&#x8FDB;&#x7A0B;&#x7684;&#x65B9;&#x6CD5; &#x4F7F;&#x7528;lsof&#x627E;&#x5230;&#x8FD8;&#x5728;&#x4F7F;&#x7528;&#x6B64;&#x6587;&#x4EF6;&#x7684;&#x8FDB;&#x7A0B;&#x3002; 1$ lsof | fgrep &quot;deleted&quot; &#x627E;&#x5230;&#x6587;&#x4EF6;&#x63CF;&#x8FF0;&#x7B26;&#x6240;&#x5728;&#x5730; 1ls -l /proc/${pid}/fd/ | fgrep &quot;deleted&quot; &#x76F4;&#x63A5;&#x622A;&#x65AD;&#x6587;&#x4EF6;&#x63CF;&#x8FF0;&#x7B26; 1234# &#x6E05;&#x7A7A;fd&gt; /proc/${pid}/fd/${id}# &#x6216;&#x76F4;&#x63A5;&#x8C03;&#x7528;truncate&#x547D;&#x4EE4;truncate -s 0 /proc/${pid}/fd/${id} &#x8FD8;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x6062;&#x590D; &#x4F7F;&#x7528;lsof&#x627E;&#x5230;&#x8FD8;&#x5728;&#x4F7F;&#x7528;&#x6B64;&#x6587;&#x4EF6;&#x7684;&#x8FDB;&#x7A0B;&#x3002; 1$ lsof | fgrep &quot;deleted&quot; &#x627E;&#x5230;&#x6587;&#x4EF6;&#x63CF;&#x8FF0;&#x7B26;&#x6240;&#x5728;&#x5730; 1ls -l /proc/${pid}/fd/ | fgrep &quot;deleted&quot; &#x8FDB;&#x884C;&#x6062;&#x590D; 1cat /proc/${pid}/fd/${id} &gt; /tmp/${file} &#x53C2;&#x8003; How to recover free space on deleted files without restarting the referencing processes? &#x4F7F;&#x7528;lsof&#x5904;&#x7406;&#x6587;&#x4EF6;&#x6062;&#x590D;&#x3001;&#x53E5;&#x67C4;&#x4EE5;&#x53CA;&#x7A7A;&#x95F4;&#x91CA;&#x653E;&#x95EE;&#x9898;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"java中判断是否在夜间","slug":"determine-night-mode-in-java","date":"2016-07-28T03:03:48.000Z","updated":"2016-08-15T03:46:26.000Z","comments":true,"path":"2016/07/28/determine-night-mode-in-java/","link":"","permalink":"http://wzktravel.github.io/2016/07/28/determine-night-mode-in-java/","excerpt":"在夜间模式时间段可以自定义的情况下，判断传入的时间在不在夜间模式时间段内。使用JodaTime进行时间操作。","text":"&#x5728;&#x591C;&#x95F4;&#x6A21;&#x5F0F;&#x65F6;&#x95F4;&#x6BB5;&#x53EF;&#x4EE5;&#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x5224;&#x65AD;&#x4F20;&#x5165;&#x7684;&#x65F6;&#x95F4;&#x5728;&#x4E0D;&#x5728;&#x591C;&#x95F4;&#x6A21;&#x5F0F;&#x65F6;&#x95F4;&#x6BB5;&#x5185;&#x3002;&#x4F7F;&#x7528;JodaTime&#x8FDB;&#x884C;&#x65F6;&#x95F4;&#x64CD;&#x4F5C;&#x3002; 1234567891011121314151617181920212223private boolean isInNight(long timeInMillis) { DateTime from = new LocalTime(&quot;22:00&quot;).toDateTimeToday(); DateTime to = new LocalTime(&quot;11:00&quot;).toDateTimeToday(); DateTime nextDayOfNightModeTo = to; if (to.compareTo(from) &lt; 0) { // to &lt; from nextDayOfNightModeTo = to.plusDays(1); } long millisOfNightMode = Seconds.secondsBetween(from, nextDayOfNightModeTo).getSeconds() * 1000L; DateTime dateTime = new DateTime(timeInMillis); if (dateTime.compareTo(from) &gt; 0) { long millisBetween = dateTime.getMillis() - from.getMillis(); if (millisOfNightMode &gt; millisBetween) { return true; } } else if (dateTime.compareTo(to) &lt; 0) { long millisBetween = to.getMillis() - from.getMillis(); if (millisOfNightMode &gt; millisBetween) { return true; } } return false;}","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"},{"name":"jodatime","slug":"jodatime","permalink":"http://wzktravel.github.io/tags/jodatime/"}]},{"title":"bash和expect中map的用法","slug":"map-in-expect-and-bash","date":"2016-07-26T07:19:17.000Z","updated":"2016-08-17T11:31:01.000Z","comments":true,"path":"2016/07/26/map-in-expect-and-bash/","link":"","permalink":"http://wzktravel.github.io/2016/07/26/map-in-expect-and-bash/","excerpt":"在bash和expect中，都有类似于map的数据结构，但用法有比较大差异。","text":"&#x5728;bash&#x548C;expect&#x4E2D;&#xFF0C;&#x90FD;&#x6709;&#x7C7B;&#x4F3C;&#x4E8E;map&#x7684;&#x6570;&#x636E;&#x7ED3;&#x6784;&#xFF0C;&#x4F46;&#x7528;&#x6CD5;&#x6709;&#x6BD4;&#x8F83;&#x5927;&#x5DEE;&#x5F02;&#x3002; bash&#x4E2D;&#x7684;map bash&#x4E2D;&#x6709;&#x4E24;&#x79CD;&#x6570;&#x7EC4;&#xFF1A;&#x4E00;&#x79CD;&#x662F;&#x7D22;&#x5F15;&#x6570;&#x7EC4;(indexed array)&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x901A;&#x8FC7;&#x6574;&#x6570;&#x4E0B;&#x6807;&#x6765;&#x7D22;&#x5F15;&#x6570;&#x7EC4;&#xFF0C;&#x5BF9;&#x5E94;&#x9AD8;&#x7EA7;&#x8BED;&#x8A00;&#x4E2D;&#x7684;&#x6570;&#x7EC4;(array)&#xFF1B;&#x53E6;&#x4E00;&#x79CD;&#x662F;&#x5173;&#x8054;&#x6570;&#x7EC4;(associative array)&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x901A;&#x8FC7;&#x4EFB;&#x610F;&#x5B57;&#x7B26;&#x4E32;&#x6765;&#x67E5;&#x627E;&#x5143;&#x7D20;&#xFF0C;&#x5BF9;&#x5E94;&#x9AD8;&#x7EA7;&#x8BED;&#x8A00;&#x4E2D;&#x7684;&#x6620;&#x5C04;&#x8868;(map&#x6216;&#x8005;hash map)&#x3002;bash&#x53EA;&#x652F;&#x6301;&#x4E00;&#x7EF4;&#x6570;&#x7EC4;&#xFF0C;&#x4E0D;&#x8FC7;&#x6570;&#x7EC4;&#x5927;&#x5C0F;&#x6CA1;&#x6709;&#x9650;&#x5236;&#x3002;&#x6CE8;&#x610F;&#x7D22;&#x5F15;&#x6570;&#x7EC4;&#x7684;&#x4E0B;&#x6807;&#x662F;&#x4ECE;0&#x5F00;&#x59CB;&#x7684;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x5173;&#x8054;&#x6570;&#x7EC4;&#x53EA;&#x5728;bash 4.0&#x4EE5;&#x4E0A;&#x7248;&#x672C;&#x652F;&#x6301;&#x3002; &#x58F0;&#x660E;&#x6570;&#x7EC4; &#x58F0;&#x660E;&#x4E00;&#x4E2A;&#x7D22;&#x5F15;&#x6570;&#x7EC4;&#xFF1A; 12declare -a arr # &#x5168;&#x5C40;&#x53D8;&#x91CF; local -a arr # &#x51FD;&#x6570;&#x7684;&#x5C40;&#x90E8;&#x53D8;&#x91CF; &#x58F0;&#x660E;&#x4E00;&#x4E2A;&#x5173;&#x8054;&#x6570;&#x7EC4;&#xFF1A; 12declare -A map # &#x5168;&#x5C40;&#x53D8;&#x91CF; local -A map # &#x51FD;&#x6570;&#x7684;&#x5C40;&#x90E8;&#x53D8;&#x91CF; &#x6570;&#x7EC4;&#x7684;&#x8D4B;&#x503C;&#x548C;&#x5F15;&#x7528; &#x7D22;&#x5F15;&#x6570;&#x7EC4; 12arr=(var0 var1 var2 var3)echo ${arr[0]} &#x5173;&#x8054;&#x6570;&#x7EC4; 12map=([&quot;a&quot;]=&quot;var1&quot; [&quot;bc&quot;]=&quot;var2&quot; [&quot;def&quot;]=&quot;var3&quot;)echo ${map[&quot;a&quot;]} &#x6570;&#x7EC4;&#x7684;&#x904D;&#x5386; &#x7D22;&#x5F15;&#x6570;&#x7EC4; 123456declare -a arrarr=(&quot;a&quot; &quot;b&quot; &quot;c&quot;)echo &quot;array length: &quot;${#arr[@]}for k in ${!arr[@]}; do echo $k&quot; = &quot;${arr[$k]}done &#x5173;&#x8054;&#x6570;&#x7EC4; 123456declare -A mapmap=([&quot;a&quot;]=&quot;hello&quot; [&quot;b&quot;]=&quot;world&quot; [&quot;c&quot;]=&quot;!&quot;)echo &quot;map length: &quot;${#map[@]}for m in ${!map[@]}; do echo $m&quot; = &quot;${map[$m]}done expect&#x4E2D;&#x7684;mapexpect&#x662F;&#x4E00;&#x79CD;tcl(Tool Control Language)&#x8BED;&#x8A00;&#xFF0C;tcl&#x5B98;&#x7F51;https://www.tcl.tk/&#x3002; array&#x793A;&#x4F8B;12345678array set colors { red #ff0000 green #00ff00 blue #0000ff}foreach name [array names colors] { puts &quot;$name is $colors($name)&quot;} &#x5177;&#x4F53;expect&#x793A;&#x4F8B;&#x6279;&#x91CF;&#x8FDB;&#x884C;ssh-copy-id 12345678910111213141516#!/usr/bin/expectarray set arrays { ip1 password1 ip2 password2 ip3 password3 }foreach h [array names arrays] { set ip $h set passwd $arrays($h) spawn ssh-copy-id -i /root/.ssh/id_rsa.pub $ip expect { &quot;(yes/no)*&quot; { send &quot;yes\\r&quot;; exp_continue } &quot;*assword*&quot; { send &quot;$passwd\\r&quot; } } #expect eof} &#x53E6;&#x9644;&#x4E00;&#x4E2A;expect&#x793A;&#x4F8B;&#x6839;&#x636E;&#x4F20;&#x8FDB;&#x6765;&#x7684;server&#x53C2;&#x6570;&#xFF0C;ssh&#x5230;&#x6B64;server&#x4E0A;&#x8FDB;&#x884C;rsync&#x64CD;&#x4F5C; 12345678910111213#!/usr/bin/expectset timeout 1000set server [lindex $argv 0]set user &quot;user&quot;set passwd &quot;password&quot;set cmd &quot;export RSYNC_PASSWORD=password; rsync -avz /data/*/*2016-06-04-{14..23}.log data@172.31.10.10::data/rsync_history/&quot;spawn ssh -l $user $server $cmdexpect { &quot;(yes/no)&quot; { send &quot;yes\\r&quot;; exp_continue } &quot;*assword*&quot; { send &quot;$passwd\\r&quot; }}expect eof &#x53C2;&#x8003; Arrays In Bash: http://www.gnu.org/software/bash/manual/html_node/Arrays.html Array In TCL: http://wiki.tcl.tk/1032","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"使用Python获取yarn任务状态","slug":"yarn-history","date":"2016-07-18T09:05:46.000Z","updated":"2016-07-21T12:22:26.000Z","comments":true,"path":"2016/07/18/yarn-history/","link":"","permalink":"http://wzktravel.github.io/2016/07/18/yarn-history/","excerpt":"使用Python获取yarn任务状态","text":"&#x4F7F;&#x7528;Python&#x83B7;&#x53D6;yarn&#x4EFB;&#x52A1;&#x72B6;&#x6001; yarn history&#x4F7F;&#x7528;yarn history server rest api, &#x53C2;&#x8003;http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html 12345678910111213141516171819202122232425import httplibimport urllibimport jsonimport time yarnHistoryServer = &quot;172.31.103.124&quot;conn = httplib.HTTPConnection(yarnHistoryServer, port=&quot;19888&quot;)headers = {&quot;accept&quot;: &quot;application/json&quot;}body = {&quot;limit&quot;: 100, &quot;user&quot;: &quot;chenlong&quot;, &quot;state&quot;: &quot;SUCCEEDED&quot;}url = &quot;/ws/v1/history/mapreduce/jobs?%s&quot; % urllib.urlencode(body)conn.request(&quot;GET&quot;, url, headers=headers)response = conn.getresponse()data = response.read()conn.close()json = json.loads(data)jobs = json[&apos;jobs&apos;][&apos;job&apos;]for job in jobs: if job[&apos;state&apos;] == &apos;SUCCEEDED&apos;: submitTime = job[&apos;submitTime&apos;] submitTimeFormat = time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;, time.localtime(submitTime / 1000)) duration = job[&apos;finishTime&apos;] - job[&apos;startTime&apos;] print &apos;%s\\t%s\\t%s\\t%s&apos; % (submitTimeFormat, job[&apos;user&apos;], job[&apos;name&apos;], duration) spark history&#x53C2;&#x8003;https://github.com/apache/spark/blob/master/docs/monitoring.md 123456789101112131415161718192021222324252627282930import urllibimport httplibimport jsonimport timesparkHistoryServer = &quot;172.31.103.128&quot;conn = httplib.HTTPConnection(sparkHistoryServer, port=&quot;18088&quot;)body = {&quot;minDate&quot;: &quot;2016-06-01&quot;, &quot;status&quot;: &quot;completed&quot;}url = &quot;/api/v1/applications?%s&quot; % urllib.urlencode(body)conn.request(&quot;GET&quot;, url)response = conn.getresponse()data = response.read()conn.close()jobs = json.loads(data)for job in jobs: name = job[&apos;name&apos;] attempts = job[&apos;attempts&apos;] firstAttempt = attempts[0] user = firstAttempt[&apos;sparkUser&apos;] if user == &quot;chenb&quot; and &quot;App C&quot; in name: startTime = firstAttempt[&apos;startTime&apos;] endTime = firstAttempt[&apos;endTime&apos;] startTimeStamp = time.mktime(time.strptime(startTime, &quot;%Y-%m-%dT%H:%M:%S.%f%Z&quot;)) endTimeStamp = time.mktime(time.strptime(endTime, &quot;%Y-%m-%dT%H:%M:%S.%f%Z&quot;)) duration = endTimeStamp - startTimeStamp print &apos;%s\\t%s\\t%s\\t%s&apos; % (startTime, user, name, duration)","categories":[],"tags":[{"name":"yarn","slug":"yarn","permalink":"http://wzktravel.github.io/tags/yarn/"}]},{"title":"搭建proxy伺服器","slug":"proxy-server","date":"2016-07-15T10:08:23.000Z","updated":"2016-08-17T11:29:54.000Z","comments":true,"path":"2016/07/15/proxy-server/","link":"","permalink":"http://wzktravel.github.io/2016/07/15/proxy-server/","excerpt":"近期使用爬虫爬取数据，需要使用代理，记录一下搭建proxy伺服器的过程，这里使用的是squid.","text":"&#x8FD1;&#x671F;&#x4F7F;&#x7528;&#x722C;&#x866B;&#x722C;&#x53D6;&#x6570;&#x636E;&#xFF0C;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x4EE3;&#x7406;&#xFF0C;&#x8BB0;&#x5F55;&#x4E00;&#x4E0B;&#x642D;&#x5EFA;proxy&#x4F3A;&#x670D;&#x5668;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x8FD9;&#x91CC;&#x4F7F;&#x7528;&#x7684;&#x662F;squid. &#x642D;&#x5EFA;proxy&#x4F3A;&#x670D;&#x5668;&#x8FD9;&#x91CC;&#x4F7F;&#x7528;&#x7684;&#x662F;squid. &#x5B89;&#x88C5;1yum install -y squid &#x914D;&#x7F6E;&#x56E0;&#x4E3A;&#x662F;&#x5728;&#x5185;&#x7F51;&#x73AF;&#x5883;&#x4E2D;&#xFF0C;&#x6240;&#x4EE5;&#x53EA;&#x5BF9;squid&#x8FDB;&#x884C;&#x4E86;&#x7B80;&#x5355;&#x7684;&#x914D;&#x7F6E;&#x3002;&#x5404;&#x914D;&#x7F6E;&#x9879;&#x542B;&#x4E49;&#x548C;&#x5176;&#x4ED6;&#x914D;&#x7F6E;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#x9CE5;&#x54E5;&#x7684; Linux &#x79C1;&#x623F;&#x83DC;: Proxy &#x4F3A;&#x670D;&#x5668;&#x3002; &#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E3A;/etc/squid/squid.conf, &#x7B80;&#x5355;&#x4FEE;&#x6539;&#x4EE5;&#x4E0B;&#x51E0;&#x4E2A;&#x65B9;&#x9762;: &#x589E;&#x52A0;&#x4E00;&#x884C;http_access allow all&#x3002; http_access&#x548C;http_deny&#x662F;&#x6709;&#x987A;&#x5E8F;&#x7684;, &#x5339;&#x914D;&#x5230;&#x7B2C;&#x4E00;&#x4E2A;&#x540E;&#x5C31;&#x4E0D;&#x518D;&#x7EE7;&#x7EED;&#x5339;&#x914D;, &#x6240;&#x4EE5;&#x7279;&#x522B;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x987A;&#x5E8F;. &#x4FEE;&#x6539;http_port&#x4E3A;8999&#xFF0C;&#x4E0D;&#x8981;&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x7684;3128&#xFF0C;&#x4F1A;&#x88AB;&#x5F88;&#x591A;&#x7F51;&#x7AD9;&#x5C4F;&#x853D;&#x3002; &#x542F;&#x52A8; &#x542F;&#x52A8;&#x524D;&#x6267;&#x884C;squid -z&#xFF0C;&#x6839;&#x636E;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x91CD;&#x5EFA;&#x7F13;&#x5B58;&#x3002; /etc/init.d/squid start&#x542F;&#x52A8;&#x3002; &#x5982;&#x679C;&#x60F3;&#x5F00;&#x542F;&#x542F;&#x52A8;squid&#xFF0C;&#x6267;&#x884C;chkconfig squid on&#x3002; java&#x4E2D;&#x4F7F;&#x7528;12345678910111213141516171819202122232425262728293031323334353637import org.apache.http.HttpHost;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.util.EntityUtils;public class HttpClientTest { public static void main(String args[]) throws Exception { CloseableHttpClient httpclient = HttpClients.createDefault(); try { HttpHost target = new HttpHost(&quot;www.baidu.com&quot;); HttpHost proxy = new HttpHost(&quot;myproxy.server&quot;, 8999, &quot;http&quot;); RequestConfig config = RequestConfig.custom() .setProxy(proxy) .build(); HttpGet request = new HttpGet(&quot;/&quot;); request.setConfig(config); System.out.println(&quot;Executing request &quot; + request.getRequestLine() + &quot; to &quot; + target + &quot; via &quot; + proxy); CloseableHttpResponse response = httpclient.execute(target, request); try { System.out.println(&quot;----------------------------------------&quot;); System.out.println(response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); } finally { response.close(); } } finally { httpclient.close(); } }} &#x53C2;&#x8003; &#x9CE5;&#x54E5;&#x7684; Linux &#x79C1;&#x623F;&#x83DC;: Proxy &#x4F3A;&#x670D;&#x5668;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"}]},{"title":"升级CDH到5.7.0","slug":"upgrade-cdh-to-5-7-0","date":"2016-05-24T10:08:23.000Z","updated":"2016-08-24T07:25:13.000Z","comments":true,"path":"2016/05/24/upgrade-cdh-to-5-7-0/","link":"","permalink":"http://wzktravel.github.io/2016/05/24/upgrade-cdh-to-5-7-0/","excerpt":"最近对CDH进行升级，从5.4.8升级到5.7.0，主要想升级spark和hbase。","text":"&#x6700;&#x8FD1;&#x5BF9;CDH&#x8FDB;&#x884C;&#x5347;&#x7EA7;&#xFF0C;&#x4ECE;5.4.8&#x5347;&#x7EA7;&#x5230;5.7.0&#xFF0C;&#x4E3B;&#x8981;&#x60F3;&#x5347;&#x7EA7;spark&#x548C;hbase&#x3002; What&#x2019;s New In CDH 5.7.x&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#x53C2;&#x8003;What&#x2019;s New In CDH 5.7.x &#x64CD;&#x4F5C;&#x7CFB;&#x7EDF;&#x652F;&#x6301; RHEL/CentOS 6.6, 6.7, 7.1, 7.2 JDK&#x7248;&#x672C;&#x5FC5;&#x987B;1.7&#x6216;&#x4EE5;&#x4E0A;&#x3002; Spark&#x5347;&#x7EA7;&#x5230;1.6.0&#xFF0C;&#x652F;&#x6301;hive on spark &#x5404;&#x670D;&#x52A1;&#x7248;&#x672C;: Component Package Version Apache Hadoop hadoop-2.6.0+cdh5.7.0+1280 HBase hbase-1.2.0+cdh5.7.0+129 Apache Hive hive-1.1.0+cdh5.7.0+522 Hue hue-3.9.0+cdh5.7.0+1759 Apache Impala impala-2.5.0+cdh5.7.0+0 Apache Oozie oozie-4.1.0+cdh5.7.0+267 Apache Sentry sentry-1.5.1+cdh5.7.0+184 Apache Spark spark-1.6.0+cdh5.7.0+180 Apache Sqoop sqoop-1.4.6+cdh5.7.0+56 Apache Sqoop2 sqoop2-1.99.5+cdh5.7.0+38 Zookeeper zookeeper-3.4.5+cdh5.7.0+94 &#x66F4;&#x591A;&#x670D;&#x52A1;&#x7684;&#x7248;&#x672C;&#x548C;&#x4E0B;&#x8F7D;&#x5730;&#x5740;&#x53C2;&#x8003;: CDH 5.7.x Packaging and Tarball Information CDH&#x5347;&#x7EA7;&#x6570;&#x636E;&#x5E93;&#x5907;&#x4EFD;cloudera manager&#x6570;&#x636E;&#x5907;&#x4EFD;cloudera manager&#x4F7F;&#x7528;postgres&#x6765;&#x5B58;&#x50A8;&#xFF0C;&#x6570;&#x636E;&#x5E93;&#x4FE1;&#x606F;&#x53EF;&#x4EE5;&#x5728;/etc/cloudera-scm-server/db.properties&#x4E2D;&#x627E;&#x5230;&#x3002; &#x5907;&#x4EFD;&#x547D;&#x4EE4;: 1pg_dump -p 7432 -U scm &gt; /data/backup/scm_server_db_backup.$(date +%Y%m%d) &#x670D;&#x52A1;&#x6570;&#x636E;&#x5907;&#x4EFD;&#x4F7F;&#x7528;&#x7684;&#x662F;mysql&#xFF0C;&#x6D89;&#x53CA;&#x7684;&#x5E93;&#x6709;hive, hue, sentry, oozie, sqoop mysqldump -h vlnx107010 -uroot -p hive &gt; /data/backup/hive-backup.$(date +%Y%m%d).sql mysqldump -h vlnx107010 -uroot -p hue &gt; /data/backup/hue-backup.$(date +%Y%m%d).sql mysqldump -h vlnx107010 -uroot -p sentry &gt; /data/backup/sentry-backup.$(date +%Y%m%d).sql mysqldump -h vlnx107010 -uroot -p oozie_oozie_server &gt; /data/backup/oozie-backup.$(date +%Y%m%d).sql mysqldump -h vlnx107010 -uroot -p sqoop &gt; /data/backup/sqoop-backup.$(date +%Y%m%d).sql &#x66F4;&#x65B0;cloudera manager server&#x4F7F;&#x7528;packages&#x65B9;&#x5F0F;&#x66F4;&#x65B0;&#x3002; &#x505C;&#x6B62;cloudera manager server, database, agent &#x505C;&#x6B62;&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x7684;&#x547D;&#x4EE4; &#x505C;&#x6B62;cloudera-manager&#x670D;&#x52A1; 1$ sudo service cloudera-scm-server stop &#x4F7F;&#x7528;&#x5185;&#x5D4C;&#x7684;PostgreSQL&#x6570;&#x636E;&#x5E93;&#x7684;&#x8BDD;&#xFF0C;&#x505C;&#x6B62;&#x6B64;&#x670D;&#x52A1; 1$ sudo service cloudera-scm-server-db stop ==Important:== If you are not running the embedded database service and you attempt to stop it, you receive a message indicating that the service cannot be found. If instead you get a message that the shutdown failed, the embedded database is still running, probably because services are connected to the Hive metastore. If the database shutdown fails due to connected services, issue the following command: RHEL-compatible 7 and higher: 12$ sudo service cloudera-scm-server-db next_stop_fast$ sudo service cloudera-scm-server-db stop All other Linux distributions: 1sudo service cloudera-scm-server-db fast_stop &#x505C;&#x6B62;cloudera-agent&#x670D;&#x52A1; 1$ sudo service cloudera-scm-agent stop &#x8BBE;&#x7F6E;repo&#x5728;&#x7EBF;&#x5347;&#x7EA7;&#xFF0C;&#x4F7F;&#x7528;cloudera&#x6E90;&#x5982;&#x679C;&#x7F51;&#x7EDC;&#x901F;&#x5EA6;&#x6BD4;&#x8F83;&#x5FEB;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x65B0;&#x5EFA;cloudera-manager.repo: 123456[cloudera-manager]# Packages for Cloudera Manager, Version 5, on RHEL or CentOS 6 x86_64name = Cloudera Managerbaseurl = https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5/gpgkey = https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/RPM-GPG-KEY-cloudera gpgcheck = 1 &#x642D;&#x5EFA;&#x672C;&#x5730;&#x6E90;&#x5982;&#x679C;&#x8BBF;&#x95EE;cloudera&#x6E90;&#x4E0D;&#x592A;&#x7A33;&#x5B9A;&#xFF0C;&#x53EF;&#x4EE5;&#x642D;&#x5EFA;&#x672C;&#x5730;&#x7684;repo&#x6E90;&#x3002; &#x5B89;&#x88C5;vsftp &#x4F7F;&#x7528;vsftp&#x4F5C;&#x4E3A;ftp&#x670D;&#x52A1;&#x5668;&#xFF0C;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x5728;/etc/vsftpd/&#x4E0B;&#xFF0C;ftp&#x8DEF;&#x5F84;&#x5728;/var/ftp/&#x4E0B;&#x3002; 12$ yum install vsftpd$ service vsftpd start &#x4E0B;&#x8F7D;rpm&#x5305;&#x548C;repodata &#x65B0;&#x5EFA;&#x76EE;&#x5F55;/var/ftp/pub/cloudera-repo&#x4F5C;&#x4E3A;repo&#x6E90;&#x76EE;&#x5F55;&#xFF0C;&#x4ECE;https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5/&#x6309;&#x4E0B;&#x8F7D;&#x6240;&#x9700;&#x7684;rpm&#x5305;&#x548C;repodata&#x76EE;&#x5F55;&#xFF0C;&#x5B8C;&#x6210;&#x540E;&#x76EE;&#x5F55;&#x7ED3;&#x6784;&#x5982;&#x4E0B;: 1234567891011121314151617$ tree /var/ftp/pub/cloudera-repo//var/ftp/pub/cloudera-repo/&#x251C;&#x2500;&#x2500; repodata&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; filelists.xml.gz&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; filelists.xml.gz.asc&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; other.xml.gz&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; other.xml.gz.asc&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; primary.xml.gz&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; primary.xml.gz.asc&#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; repomd.xml&#x2502;&#xA0;&#xA0; &#x2514;&#x2500;&#x2500; repomd.xml.asc&#x2514;&#x2500;&#x2500; RPMS &#x2514;&#x2500;&#x2500; x86_64 &#x251C;&#x2500;&#x2500; cloudera-manager-agent-5.7.0-1.cm570.p0.76.el6.x86_64.rpm &#x251C;&#x2500;&#x2500; cloudera-manager-daemons-5.7.0-1.cm570.p0.76.el6.x86_64.rpm &#x251C;&#x2500;&#x2500; cloudera-manager-server-5.7.0-1.cm570.p0.76.el6.x86_64.rpm &#x2514;&#x2500;&#x2500; cloudera-manager-server-db-2-5.7.0-1.cm570.p0.76.el6.x86_64.rpm &#x65B0;&#x5EFA;&#x672C;&#x5730;repocloudera-manager.repo&#x5982;&#x4E0B;: 1234[cloudera-manager]name = Cloudera Manager, Version 5.7.0baseurl = ftp://${local-repo-ip}/pub/cloudera-repogpgcheck = 0 &#x5982;&#x679C;&#x624B;&#x52A8;&#x5347;&#x7EA7;&#x5404;&#x673A;&#x5668;&#x7684;cloudera-manager-agent&#xFF0C;&#x9700;&#x8981;&#x5C06;cloudera-manager.repo&#x66F4;&#x65B0;&#x5230;&#x6240;&#x6709;&#x8282;&#x70B9;&#x4E0A; &#x5982;&#x679C;&#x4F7F;&#x7528;cloudera&#x5347;&#x7EA7;&#x5404;&#x673A;&#x5668;&#x7684;cloudera-manager-agent&#xFF0C;&#x5728;&#x5347;&#x7EA7;&#x65F6;&#x6CE8;&#x610F;&#x9009;&#x62E9;Custom Repository&#xFF0C;&#x586B;&#x5199;repository&#x5730;&#x5740;&#x4E3A;ftp://${local-repo-ip}/pub/cloudera-repo&#x3002; &#x8FDB;&#x884C;&#x5347;&#x7EA7;12$ sudo yum clean all$ sudo yum upgrade cloudera-manager-server cloudera-manager-daemons cloudera-manager-server-db-2 cloudera-manager-agent &#x91CD;&#x542F;cloudera manager&#x670D;&#x52A1;12$ sudo service cloudera-scm-server-db start$ sudo service cloudera-scm-server start &#x66F4;&#x65B0;cloudera manager agent ==Important:== All hosts in the cluster must have access to the Internet if you plan to use archive.cloudera.com as the source for installation files. If you do not have Internet access, create a custom repository. &#x4EE5;&#x4E0B;&#x4E24;&#x79CD;&#x5347;&#x7EA7;&#x4EFB;&#x9009;&#x4E00;&#x79CD;&#x3002; &#x4F7F;&#x7528;cloudera&#x8FDB;&#x884C;&#x5347;&#x7EA7;&#x8FDB;&#x5165;cloudera manager&#x540E;&#xFF0C;&#x4F1A;&#x81EA;&#x52A8;&#x5F39;&#x51FA;&#x5347;&#x7EA7;&#x9875;&#x9762;&#xFF0C;&#x9009;&#x62E9;Yes, I would like to upgrade the Cloudera Manager Agent packages now&#xFF0C;&#x7136;&#x540E;&#x4E00;&#x6B65;&#x6B65;&#x8FDB;&#x884C;&#x3002; &#x5728;&#x9009;&#x62E9;Cloudera Manager Agent Release&#x65F6;&#xFF0C;&#x6709;&#x4E24;&#x79CD;&#x9009;&#x62E9; &#x5982;&#x679C;&#x8FDB;&#x884C;&#x5728;&#x7EBF;&#x5347;&#x7EA7;&#xFF0C;&#x9009;&#x62E9;Matched Release for this Cloudera Manager Server&#xFF0C;&#x8FD9;&#x6837;&#x4F1A;&#x76F4;&#x63A5;&#x4ECE;https://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5/&#x8FDB;&#x884C;&#x66F4;&#x65B0;&#x3002; &#x5982;&#x679C;&#x81EA;&#x5DF1;&#x4E0B;&#x8F7D;&#x4E86;rpm&#x5305;&#xFF0C;&#x5E76;&#x5EFA;&#x7ACB;&#x4E86;&#x672C;&#x5730;repo&#x6E90;&#xFF0C;&#x9009;&#x62E9;Custom Repository&#xFF0C;&#x7136;&#x540E;&#x586B;&#x5199;&#x672C;&#x5730;repo&#x6E90;&#x5730;&#x5740;&#x3002; &#x8FD9;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#x90FD;&#x4F1A;&#x5728;&#x6BCF;&#x53F0;&#x673A;&#x5668;/etc/yum.repos.d/&#x76EE;&#x5F55;&#x4E0B;&#x751F;&#x6210;cloudera-manager.repo&#xFF0C;&#x4E0D;&#x8FC7;&#x5176;&#x4E2D;&#x7684;baseurl&#x53C2;&#x6570;&#x4E0D;&#x540C;&#x3002; &#x624B;&#x52A8;&#x8FDB;&#x884C;&#x66F4;&#x65B0; &#x5728;&#x6BCF;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x6DFB;&#x52A0;cloudera-manager.repo&#x5E76;&#x6E05;&#x7406;yum cache&#xFF0C;yum clean all&#x3002; &#x505C;&#x6B62;cloudera-scm-agent&#x670D;&#x52A1;: service cloudera-scm-agent stop&#x3002; &#x66F4;&#x65B0;cloudera-manager-agent: yum upgrade cloudera-manager-server cloudera-manager-daemons cloudera-manager-server-db-2 cloudera-manager-agent&#x3002; &#x542F;&#x52A8;cloudera-scm-agent&#x670D;&#x52A1;: service cloudera-scm-agent start&#x3002; &#x9A8C;&#x8BC1;CDH&#x5347;&#x7EA7;&#x662F;&#x5426;&#x6210;&#x529F;&#x5728;&#x9875;&#x9762;&#x4E0A;hosts&#x9875;&#x9762;&#xFF0C;&#x70B9;&#x51FB;Inspect All Hosts&#xFF0C;&#x68C0;&#x6D4B;&#x5B8C;&#x6210;&#x540E;&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF0C;&#x80FD;&#x591F;&#x6BD4;&#x8F83;&#x8BE6;&#x7EC6;&#x7684;&#x67E5;&#x770B;&#x5404;&#x673A;&#x5668;&#x60C5;&#x51B5;&#x3002; &#x670D;&#x52A1;&#x5347;&#x7EA7;CDH&#x5347;&#x7EA7;&#x540E;&#xFF0C;&#x66F4;&#x8981;&#x91CD;&#x7684;&#x662F;&#x5BF9;CDH&#x7BA1;&#x7406;&#x7684;&#x670D;&#x52A1;&#x8FDB;&#x884C;&#x5347;&#x7EA7;&#xFF0C;&#x8FD9;&#x91CC;&#x4F7F;&#x7528;parcels&#x8FDB;&#x884C;&#x5347;&#x7EA7;&#x3002; &#x521B;&#x5EFA;&#x4E34;&#x65F6;&#x8FDC;&#x7A0B;&#x4ED3;&#x5E93; &#x65B0;&#x5EFA;&#x76EE;&#x5F55;/data/cloudera-parcel-server &#x4E0B;&#x8F7D;CDH parcel&#x548C;manifest.json 12$ wget http://archive.cloudera.com/cdh5/parcels/5/CDH-5.7.0-1.cdh5.7.0.p0.45-el6.parcel$ wget http://archive.cloudera.com/cdh5/parcels/5/manifest.json &#x4E0B;&#x8F7D;kafka parcel&#x548C;manifest.json 12$ wget http://archive.cloudera.com/kafka/parcels/2/KAFKA-2.0.1-1.2.0.1.p0.5-el6.parcel$ wget http://archive.cloudera.com/kafka/parcels/2/manifest.json &#x4E0B;&#x8F7D;gplextras5&#x548C;manifest.json 12$ wget http://archive.cloudera.com/gplextras5/parcels/5/GPLEXTRAS-5.6.1-1.cdh5.6.1.p0.5-el6.parcel$ wget http://archive.cloudera.com/gplextras5/parcels/5/manifest.json &#x6574;&#x4F53;&#x76EE;&#x5F55;&#x7ED3;&#x6784;&#x5982;&#x4E0B;: 12345678910111213$ tree /data/cloudera-parcel-server/ /data/cloudera-parcel-server/ &#x251C;&#x2500;&#x2500; cdh &#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; CDH-5.7.0-1.cdh5.7.0.p0.45-el6.parcel &#x2502;&#xA0;&#xA0; &#x2514;&#x2500;&#x2500; manifest.json &#x251C;&#x2500;&#x2500; gplextras &#x2502;&#xA0;&#xA0; &#x251C;&#x2500;&#x2500; GPLEXTRAS-5.6.1-1.cdh5.6.1.p0.5-el6.parcel &#x2502;&#xA0;&#xA0; &#x2514;&#x2500;&#x2500; manifest.json &#x2514;&#x2500;&#x2500; kafka &#x251C;&#x2500;&#x2500; KAFKA-2.0.1-1.2.0.1.p0.5-el6.parcel &#x2514;&#x2500;&#x2500; manifest.json 3 directories, 6 files &#x542F;&#x52A8;&#x4E00;&#x4E2A;server 1$ python -m SimpleHTTPServer 8080 &#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x6253;&#x5F00;&#x94FE;&#x63A5;&#x67E5;&#x770B;&#x662F;&#x5426;&#x542F;&#x52A8;&#x6210;&#x529F;&#xFF0C;http://{http-server-ip}:8080&#xFF0C;&#x6210;&#x529F;&#x540E;&#x53EF;&#x4EE5;&#x5728;parcels&#x7684;&#x914D;&#x7F6E;Remote Parcel Repository URLs&#x4E2D;&#x6DFB;&#x52A0;&#x76F8;&#x5173;&#x7684;parcel&#x5730;&#x5740;: http://{http-server-ip}:8080/cdh/ http://{http-server-ip}:8080/kafka/ http://{http-server-ip}:8080/gplextras/ CDH Parcel(&#x670D;&#x52A1;)&#x5347;&#x7EA7;&#x53C2;&#x8003;Upgrading to CDH 5.7 Using Parcels &#x5728;Hosts -&gt; Parcels&#x5904;&#x8BBE;&#x7F6E;&#x4E0A;&#x4E00;&#x4E2A;&#x6B65;&#x9AA4;&#x4E2D;&#x7684;parcel&#x4E34;&#x65F6;&#x8FDC;&#x7A0B;&#x4ED3;&#x5E93; &#x5728;&#x9996;&#x9875;cluster&#x540D;&#x53F3;&#x4FA7;&#x5C0F;&#x4E09;&#x89D2;&#x5904;&#x70B9;&#x51FB;&#x300E;Upgrade Cluster&#x300F;&#xFF0C;&#x4ED4;&#x7EC6;&#x9605;&#x8BFB;&#x5347;&#x7EA7;&#x524D;&#x7684;&#x51C6;&#x5907;&#xFF0C;&#x5E76;&#x63D0;&#x524D;&#x51C6;&#x5907;&#x597D; &#x5728;&#x8282;&#x70B9;&#x68C0;&#x6D4B;&#x5B8C;&#x540E;&#xFF0C;&#x9009;&#x62E9;Let me upgrade the cluster&#xFF0C;&#x624B;&#x52A8;&#x8FDB;&#x884C;&#x91CD;&#x542F;&#x670D;&#x52A1;&#x4EE5;&#x907F;&#x514D;&#x670D;&#x52A1;&#x4E0D;&#x53EF;&#x7528;&#x3002; &#x5347;&#x7EA7;Oozie ShareLib&#xFF0C;&#x5728;Oozie&#x670D;&#x52A1;&#x9875;&#x9762;&#xFF0C;&#x70B9;&#x51FB;Actions &gt; Install Oozie ShareLib&#x3002; &#x5347;&#x7EA7;Sqoop2&#xFF0C;&#x5728;Sqoop2&#x9875;&#x9762;&#xFF0C;&#x70B9;&#x51FB;Actions &gt; Upgrade Sqoop&#x3002; &#x5347;&#x7EA7;Spark&#xFF0C;&#x5728;spark&#x9875;&#x9762;&#xFF0C;&#x70B9;&#x51FB;Actions &gt; Install Spark JAR&#x548C;Actions &gt; Create Spark History Log Dir&#x3002; &#x624B;&#x52A8;&#x5C06;&#x670D;&#x52A1;&#x4E00;&#x4E2A;&#x4E2A;&#x91CD;&#x542F;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x6BCF;&#x4E2A;&#x670D;&#x52A1;&#x7684;InstancesTab&#x9875;&#xFF0C;&#x4E00;&#x4E2A;&#x5B9E;&#x4F8B;&#x4E00;&#x4E2A;&#x5B9E;&#x4F8B;&#x7684;&#x91CD;&#x542F;&#xFF0C;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x907F;&#x514D;&#x670D;&#x52A1;&#x4E0D;&#x53EF;&#x7528;&#x3002; &#x91CD;&#x542F;&#x5B8C;&#x540E;&#xFF0C;&#x8FD0;&#x884C;Deploy Client Configuration&#x3002; &#x5728;parcels&#x9875;&#x9762;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x4E4B;&#x524D;&#x7684;parcel&#x3002; &#x53E6;&#x5916;&#x7684;&#x9014;&#x5F84;&#x53EF;&#x4EE5;&#x5728;Hosts &gt; parcels&#x9875;&#x9762;&#x624B;&#x52A8;&#x8FDB;&#x884C;Distribute&#x548C;Active&#xFF0C;&#x7136;&#x540E;&#x8FDB;&#x884C;&#x4E0A;&#x9762;&#x7684;&#x6B65;&#x9AA4;4&#x2013;&#x6B65;&#x9AA4;9&#x3002; KAFKA Parcel&#x5347;&#x7EA7;&#x5728;Hosts &gt; parcels&#x9875;&#x9762;&#x624B;&#x52A8;&#x5BF9;Kafka Parcel&#x8FDB;&#x884C;Distribute&#x548C;Active&#xFF0C;&#x7136;&#x540E;&#x5BF9;Kafka Broker&#x4E00;&#x53F0;&#x53F0;&#x8FDB;&#x884C;&#x91CD;&#x542F;&#xFF0C;&#x786E;&#x5B9A;&#x6CA1;&#x95EE;&#x9898;&#x540E;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x65E7;&#x7684;parcel&#x3002; GPLEXTRAS Parcel&#x5347;&#x7EA7;(&#x6DFB;&#x52A0;&#x5BF9;lzo&#x7684;&#x652F;&#x6301;)&#x53C2;&#x8003;Configuring Services to Use the GPL Extras Parcel &#x5728;Hosts &gt; parcels&#x9875;&#x9762;&#x624B;&#x52A8;&#x5BF9;gplextras parcel&#x8FDB;&#x884C;Distribute&#x548C;Active HDFS&#x670D;&#x52A1;&#x4E2D;&#x4FEE;&#x6539;&#x914D;&#x7F6E;Compression Codecs&#xFF0C;&#x6DFB;&#x52A0;com.hadoop.compression.lzo.LzoCodec&#x548C;com.hadoop.compression.lzo.LzopCodec&#xFF0C;&#x91CD;&#x542F;HDFS&#x3002; &#x5728;&#x6BCF;&#x53F0;Oozie Server&#x4E0A;&#x5EFA;&#x7ACB;hadoop-lzo.jar&#x7684;&#x8F6F;&#x94FE;&#x63A5;&#xFF0C;ln -sf /opt/cloudera/parcels/GPLEXTRAS/lib/hadoop/lib/hadoop-lzo.jar /var/lib/ooziehadoop-lzo.jar&#xFF0C;&#x91CD;&#x542F;Oozie&#x3002; Sqoop2&#x670D;&#x52A1;&#x4E2D;&#x4FEE;&#x6539;&#x914D;&#x7F6E;Sqoop Service Environment Advanced Configuration Snippet&#xFF0C;&#x6DFB;&#x52A0;HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/opt/cloudera/parcels/GPLEXTRAS/lib/hadoop/lib/*&#x548C;JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/opt/cloudera/parcels/GPLEXTRAS/lib/hadoop/lib/native&#xFF0C;&#x91CD;&#x542F;Sqoop2&#x3002; &#x91CD;&#x542F;&#x5176;&#x4ED6;&#x9700;&#x8981;&#x91CD;&#x542F;&#x7684;&#x670D;&#x52A1;&#x3002; &#x8FD0;&#x884C;Deploy Client Configuration&#x3002; CDH Client(Gateway)&#x5347;&#x7EA7;&#x5728;&#x5347;&#x7EA7;&#x540E;&#xFF0C;&#x53D1;&#x73B0;&#x5404;Client&#x4E2D;&#x7684;&#x547D;&#x4EE4;&#x5F15;&#x7528;&#x6CA1;&#x6709;&#x66F4;&#x65B0;&#xFF0C;&#x9700;&#x8981;&#x624B;&#x52A8;&#x5C06;/etc/alternatives/&#x76EE;&#x5F55;&#x4E0B;CDH&#x76F8;&#x5173;&#x66F4;&#x65B0;&#x4E3A;&#x6700;&#x65B0;&#x3002;&#x4EE5;spark-shell&#x4E3A;&#x4F8B;&#x3002; &#x6267;&#x884C;which spark-shell&#xFF0C;&#x53D1;&#x73B0;&#x6307;&#x5411;/usr/bin/spark-shell &#x6267;&#x884C;ls -l /usr/bin/spark-shell&#xFF0C;&#x53D1;&#x73B0;&#x662F;&#x4E2A;&#x8F6F;&#x94FE;&#x63A5;&#x5E76;&#x6307;&#x5411;&#x4E86;/etc/alternatives/spark-shell &#x6267;&#x884C;ls -l /etc/alternatives/spark-shell&#xFF0C;&#x53D1;&#x73B0;&#x662F;&#x4E2A;&#x8F6F;&#x94FE;&#x63A5;&#x5E76;&#x6307;&#x5411;&#x4E86;/opt/cloudera/parcels/CDH-5.4.8-1.cdh5.4.8.p0.4/bin/spark-shell&#xFF0C;&#x660E;&#x663E;&#x8FD8;&#x6307;&#x5411;&#x5347;&#x7EA7;&#x524D;&#x7684;&#x7248;&#x672C;&#x3002; &#x6267;&#x884C;ln -sf /opt/cloudera/parcels/CDH/bin/spark-shell /etc/alternatives/spark-shell&#x5C06;&#x5176;&#x6307;&#x5411;&#x6700;&#x65B0;&#x7684;&#x7248;&#x672C;&#x3002; &#x53EF;&#x4EE5;&#x4F7F;&#x7528;shell&#x811A;&#x672C;&#x6279;&#x91CF;&#x5C06;/etc/alternatives&#x4E0B;CDH&#x76F8;&#x5173;&#x8F6F;&#x94FE;&#x63A5;&#x6307;&#x5411;&#x6700;&#x65B0;&#x7684;&#x7248;&#x672C;&#x3002; &#x53C2;&#x8003; Upgrading Cloudera Manager 5 to the Latest Cloudera Manager: http://www.cloudera.com/documentation/enterprise/latest/topics/cm_ag_upgrade_cm5.html Upgrading CDH and Managed Services Using Cloudera Manager: http://www.cloudera.com/documentation/enterprise/latest/topics/cm_mc_upgrading_cdh.html Upgrading to CDH 5.7 Using Parcels: http://www.cloudera.com/documentation/enterprise/latest/topics/install_upgrade_to_cdh57_parcels.html Creating a Temporary Remote Repository: http://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_create_local_parcel_repo.html postgresql&#x5E38;&#x7528;&#x547D;&#x4EE4;: http://blog.chinaunix.net/uid-26642180-id-3485465.html Running Hive on Spark: http://www.cloudera.com/documentation/enterprise/latest/topics/admin_hos_oview.html Configuring Services to Use the GPL Extras Parcel: http://www.cloudera.com/documentation/enterprise/latest/topics/cm_mc_gpl_extras.html CDH 5.7.0 Properties: http://www.cloudera.com/documentation/enterprise/latest/topics/cm_props_cdh570.html","categories":[],"tags":[{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"},{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hive","slug":"hive","permalink":"http://wzktravel.github.io/tags/hive/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"}]},{"title":"elasticsearch修改mapping重建索引","slug":"elasticsearch-reindex","date":"2016-05-11T12:09:22.000Z","updated":"2016-07-14T03:16:31.000Z","comments":true,"path":"2016/05/11/elasticsearch-reindex/","link":"","permalink":"http://wzktravel.github.io/2016/05/11/elasticsearch-reindex/","excerpt":"最近需要对elasticsearch中某个index的mapping进行修改，整理一下流程。","text":"&#x6700;&#x8FD1;&#x9700;&#x8981;&#x5BF9;elasticsearch&#x4E2D;&#x67D0;&#x4E2A;index&#x7684;mapping&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#xFF0C;&#x6574;&#x7406;&#x4E00;&#x4E0B;&#x6D41;&#x7A0B;&#x3002; &#x6574;&#x4E2A;&#x6D41;&#x7A0B;&#x5305;&#x62EC;&#x4EE5;&#x4E0B;&#x51E0;&#x4E2A;&#x6B65;&#x9AA4;: &#x4FEE;&#x6539;index template &#x8FDB;&#x884C;reindex &#x5220;&#x9664;&#x65E7;index &#x521B;&#x5EFA;alias &#x4FEE;&#x6539;index template&#x4E3B;&#x8981;&#x4FEE;&#x6539;&#x4E86;dynamic templates&#x4E2D;&#x5BF9;string&#x7C7B;&#x578B;&#x7684;&#x4FEE;&#x6539;&#xFF0C;&#x4E0D;&#x8FDB;&#x884C;&#x7D22;&#x5F15;&#xFF0C;&#x8BBE;&#x7F6E;ignore_above&#x7B49;&#x3002; &#x5728;reindex&#x65F6;&#x51FA;&#x73B0;&#x9519;&#x8BEF;max_bytes_length_exceeded_exception&#xFF0C;&#x8FD9;&#x662F;&#x7531;&#x4E8E;Lucene&#x5B57;&#x8282;&#x957F;&#x5EA6;&#x9650;&#x5236;&#x5F15;&#x8D77;&#x7684;&#xFF0C;&#x6DFB;&#x52A0;ignore_above&#x5373;&#x53EF;&#x89E3;&#x51B3;&#xFF0C;&#x53C2;&#x8003;http://www.jianshu.com/p/133a0f49311a1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556{ &quot;order&quot;: 0, &quot;template&quot;: &quot;datapt-buriedtool*&quot;, &quot;settings&quot;: { &quot;index&quot;: { &quot;number_of_shards&quot;: &quot;6&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &quot;mapper&quot;: { &quot;dynamic&quot;: &quot;true&quot; } } }, &quot;mappings&quot;: { &quot;_default_&quot;: { &quot;_ttl&quot;: { &quot;default&quot;: &quot;3d&quot;, &quot;enabled&quot;: true }, &quot;_source&quot;: { &quot;enabled&quot;: true }, &quot;dynamic_templates&quot;: [ { &quot;str&quot;: { &quot;mapping&quot;: { &quot;ignore_above&quot;: 10922, &quot;index&quot;: &quot;not_analyzed&quot;, &quot;type&quot;: &quot;string&quot;, &quot;doc_values&quot;: true }, &quot;match_mapping_type&quot;: &quot;string&quot; } }, { &quot;num&quot;: { &quot;mapping&quot;: { &quot;type&quot;: &quot;long&quot;, &quot;doc_values&quot;: true }, &quot;match_mapping_type&quot;: &quot;long&quot; } }, { &quot;date&quot;: { &quot;mapping&quot;: { &quot;type&quot;: &quot;date&quot;, &quot;doc_values&quot;: true }, &quot;match&quot;: &quot;stamp*&quot; } } ] } }, &quot;aliases&quot;: {}} &#x8FDB;&#x884C;reindex&#x5728;reindex&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x8FC7;&#x6EE4;&#xFF0C;&#x4E5F;&#x6709;&#x8BB8;&#x591A;&#x5176;&#x4ED6;&#x64CD;&#x4F5C;&#xFF0C;&#x5177;&#x4F53;&#x53C2;&#x8003;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html &#x6CE8;&#x610F;curl&#x8D85;&#x65F6;&#x65F6;&#x95F4; 12345678910111213141516171819curl -m 10000000 -XPOST &apos;http://elasticsearch_ip:9200/_reindex&apos; -d &apos;{ &quot;source&quot; : { &quot;index&quot; : &quot;datapt-buriedtool&quot;, &quot;query&quot; : { &quot;bool&quot; : { &quot;filter&quot; : { &quot;range&quot; : { &quot;stamp&quot;: { &quot;gte&quot; : &quot;2016-05-11&quot; } } } } } }, &quot;dest&quot; : { &quot;index&quot; : &quot;datapt-buriedtool_v1&quot; }}&apos; &#x521B;&#x5EFA;alias&#x5728;&#x521B;&#x5EFA;alias&#x4E4B;&#x524D;&#x5148;&#x5C06;&#x65E7;&#x7684;index&#x5220;&#x9664;&#x3002;alias&#x64CD;&#x4F5C;&#x53C2;&#x8003;https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html 123456curl -XPOST &apos;http://elasticsearch_ip:9200/_aliases&apos; -d &apos;{ &quot;actions&quot; : [ { &quot;add&quot; : { &quot;index&quot; : &quot;datapt-buriedtool_v1&quot;, &quot;alias&quot; : &quot;datapt-buriedtool&quot; } } ]}&apos; &#x81F3;&#x6B64;&#x5B8C;&#x6210;&#x3002;","categories":[],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://wzktravel.github.io/tags/elasticsearch/"}]},{"title":"hadoop集群管理","slug":"hadoop-management","date":"2016-05-10T01:33:37.000Z","updated":"2016-08-24T07:25:01.000Z","comments":true,"path":"2016/05/10/hadoop-management/","link":"","permalink":"http://wzktravel.github.io/2016/05/10/hadoop-management/","excerpt":"hadoop集群管理","text":"hadoop&#x96C6;&#x7FA4;&#x7BA1;&#x7406; yarn&#x65E5;&#x5FD7;&#x548C;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x5730;&#x5740;&#x8BBE;&#x7F6E;&#x6700;&#x8FD1;&#x9047;&#x5230;&#x8DD1;&#x4EFB;&#x52A1;&#x65F6;&#x5C06;&#x7CFB;&#x7EDF;&#x78C1;&#x76D8;&#x6253;&#x6EE1;&#x7684;&#x60C5;&#x51B5;&#xFF0C;&#x5B9A;&#x4F4D;&#x53D1;&#x73B0;&#x662F;yarn.nodemanager.log-dirs&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x914D;&#x7F6E;&#xFF0C;&#x5BFC;&#x81F4;&#x8FD0;&#x884C;&#x4EFB;&#x52A1;&#x7684;&#x65E5;&#x5FD7;&#x8FC7;&#x591A;&#x9020;&#x6210;&#x7684;&#x3002; yarn.nodemanager.local-dirs &#x53C2;&#x6570;&#x89E3;&#x91CA;&#xFF1A;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x5B58;&#x653E;&#x4F4D;&#x7F6E;&#xFF0C;&#x7C7B;&#x4F3C;&#x4E8E;1.0&#x4E2D;&#x7684;mapred.local.dir&#x3002;&#x6CE8;&#x610F;&#xFF0C;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x901A;&#x5E38;&#x4F1A;&#x914D;&#x7F6E;&#x591A;&#x4E2A;&#x76EE;&#x5F55;&#xFF0C;&#x4EE5;&#x5206;&#x644A;&#x78C1;&#x76D8;IO&#x8D1F;&#x8F7D;&#x3002; &#x9ED8;&#x8BA4;&#x503C;&#xFF1A;${hadoop.tmp.dir}/nm-local-dir yarn.nodemanager.log-dirs &#x53C2;&#x6570;&#x89E3;&#x91CA;&#xFF1A;&#x65E5;&#x5FD7;&#x5B58;&#x653E;&#x5730;&#x5740;&#xFF08;&#x53EF;&#x914D;&#x7F6E;&#x591A;&#x4E2A;&#x76EE;&#x5F55;&#xFF09;&#x3002; &#x9ED8;&#x8BA4;&#x503C;&#xFF1A;${yarn.log.dir}/userlogs &#x8FD9;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#x5728;yarn-site.xml&#x4E2D;&#xFF0C;&#x5C3D;&#x91CF;&#x8FDB;&#x884C;&#x5355;&#x72EC;&#x914D;&#x7F6E;&#xFF0C;&#x5C06;&#x5176;&#x653E;&#x7F6E;&#x5230;&#x6570;&#x636E;&#x78C1;&#x76D8;&#x4E0A;&#x3002; ResouceManager&#x548C;NodeManager&#x7684;&#x4E00;&#x4E9B;&#x53C2;&#x6570;&#x8BF4;&#x660E;&#x53EF;&#x4EE5;&#x53C2;&#x8003;http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/ hdfs&#x5F00;&#x542F;ACLHDFS&#x672C;&#x8EAB;&#x6CA1;&#x6709;&#x63D0;&#x4F9B;&#x7528;&#x6237;&#x540D;&#x3001;&#x7528;&#x6237;&#x7EC4;&#x7684;&#x521B;&#x5EFA;&#xFF0C;&#x5728;&#x5BA2;&#x6237;&#x7AEF;&#x8C03;&#x7528;hadoop &#x7684;&#x6587;&#x4EF6;&#x64CD;&#x4F5C;&#x547D;&#x4EE4;&#x65F6;&#xFF0C;hadoop &#x8BC6;&#x522B;&#x51FA;&#x6267;&#x884C;&#x547D;&#x4EE4;&#x6240;&#x5728;&#x8FDB;&#x7A0B;&#x7684;&#x7528;&#x6237;&#x540D;&#x548C;&#x7528;&#x6237;&#x7EC4;&#xFF0C;&#x7136;&#x540E;&#x4F7F;&#x7528;&#x8FD9;&#x4E2A;&#x7528;&#x6237;&#x540D;&#x548C;&#x7EC4;&#x6765;&#x68C0;&#x67E5;&#x6587;&#x4EF6;&#x6743;&#x9650;&#x3002; 12345678&lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.acls.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; For HDFS, the mapping of users to groups is performed on the NameNode. Thus, the host system configuration of the NameNode determines the group mappings for the users. &#x53C2;&#x8003;: http://debugo.com/hdfs-acl/?utm_source=tuicool&amp;utm_medium=referral &#x57FA;&#x4E8E;Hadoop SLA&#x8BA4;&#x8BC1;&#x673A;&#x5236;&#x5B9E;&#x73B0;&#x6743;&#x9650;&#x63A7;&#x5236;: http://shiyanjun.cn/archives/994.html hive&#x67E5;&#x8BE2;&#x51FA;&#x9519; &#x6216; yarn&#x6267;&#x884C;&#x62A5;&#x9519;&#x5728;hue&#x4E2D;&#x4F7F;&#x7528;hive&#x67E5;&#x8BE2;&#x65F6;&#x6709;&#x65F6;&#x4F1A;&#x62A5;&#x9519;: Return Code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask&#xFF0C;&#x663E;&#x7136;&#x5177;&#x4F53;&#x539F;&#x56E0;&#x8FD8;&#x5F97;&#x53BB;yarn&#x4E2D;&#x67E5;&#x770B;&#xFF0C;&#x5177;&#x4F53;&#x539F;&#x56E0;&#x662F;Diagnostics: Rename cannot overwrite non empty destination directory /data/yarn/nm/usercache/xxxx/filecache/100&#x3002; &#x539F;&#x56E0;: This is a bug in Hadoop 2.6.0. It&#x2019;s been marked as fixed but it still happens occasionally (see: https://issues.apache.org/jira/browse/YARN-2624). &#x89E3;&#x51B3;: &#x624B;&#x52A8;&#x5C06;&#x6240;&#x6709;NodeManager&#x4E0A;&#x76EE;&#x5F55;/data/yarn/nm/usercache/&#x4E0B;&#x5185;&#x5BB9;&#x5220;&#x9664;&#x3002; &#x53C2;&#x8003;: http://stackoverflow.com/questions/30857413/hadoop-complains-about-attempting-to-overwrite-nonempty-destination-directory yarn unhealthy nodes&#x5728;yarn resourcemanager web ui&#x754C;&#x9762;&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x6709;&#x4E00;&#x9879;&#x662F;Unhealthy Nodes&#xFF0C;&#x70B9;&#x8FDB;&#x53BB;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x5177;&#x4F53;&#x4FE1;&#x606F;&#xFF0C;health-report&#x663E;&#x793A;&#x5177;&#x4F53;&#x539F;&#x56E0;&#x3002; &#x67E5;&#x770B;&#x6B64;node manager&#x4E0A;&#x78C1;&#x76D8;&#x5DF2;&#x7ECF;&#x5230;90%&#xFF0C;&#x8003;&#x8651;&#x5230;&#x78C1;&#x76D8;&#x5269;&#x4F59;&#x7A7A;&#x95F4;&#x8FD8;&#x5F88;&#x5145;&#x8DB3;&#xFF0C;&#x51B3;&#x5B9A;&#x8C03;&#x8282;yarn&#x53C2;&#x6570;&#x3002; yarn.nodemanager.disk-health-checker.min-healthy-disks: &#x5F53;&#x78C1;&#x76D8;&#x5269;&#x4F59;&#x7A7A;&#x95F4;&#x5C0F;&#x4E8E;&#x6B64;&#x9600;&#x503C;&#x65F6;&#xFF0C;yarn&#x4E0D;&#x4F1A;&#x521B;&#x5EFA;&#x65B0;&#x7684;container&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;0.25&#x3002; yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage: &#x5F53;&#x78C1;&#x76D8;&#x5360;&#x7528;&#x7A7A;&#x95F4;&#x5C0F;&#x4E8E;&#x6B64;&#x9600;&#x503C;&#x65F6;&#xFF0C;yarn&#x4F1A;&#x89C6;&#x4E3A;&#x6B64;&#x8282;&#x70B9;&#x4E3A;unhealthy&#x7684;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;90.0&#x3002; &#x589E;&#x52A0;&#x8FD9;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#x5982;&#x4E0B;:12345678&lt;property&gt; &lt;name&gt;yarn.nodemanager.disk-health-checker.min-healthy-disks&lt;/name&gt; &lt;value&gt;0.05&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage&lt;/name&gt; &lt;value&gt;95.0&lt;/value&gt;&lt;/property&gt; &#x4FEE;&#x6539;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x9700;&#x8981;&#x5148;&#x5C06;nodemanager&#x91CD;&#x542F;&#xFF0C;&#x7136;&#x540E;&#x518D;&#x91CD;&#x542F;resourcemanager&#xFF0C;&#x5426;&#x5219;&#x4F1A;&#x5BFC;&#x81F4;&#x4FEE;&#x6539;&#x7684;&#x8282;&#x70B9;&#x72B6;&#x6001;&#x9519;&#x4E71;&#x3002; &#x53C2;&#x8003;: YARN UNHEALTHY nodes yarn&#x9ED8;&#x8BA4;&#x914D;&#x7F6E;(yarn-default.xml)","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"http://wzktravel.github.io/tags/hdfs/"},{"name":"yarn","slug":"yarn","permalink":"http://wzktravel.github.io/tags/yarn/"}]},{"title":"azkaban的安装和使用","slug":"azkaban-how-to-install-and-use","date":"2016-05-04T02:00:07.000Z","updated":"2016-08-24T07:25:08.000Z","comments":true,"path":"2016/05/04/azkaban-how-to-install-and-use/","link":"","permalink":"http://wzktravel.github.io/2016/05/04/azkaban-how-to-install-and-use/","excerpt":"azkaban的使用。","text":"azkaban&#x7684;&#x4F7F;&#x7528;&#x3002;&#x5B98;&#x7F51;: http://azkaban.github.io/ &#x95EE;&#x9898; java.sql.SQLException: Unknown column &apos;ex.executor_id&apos; in &apos;on clause&apos;&#x8FD9;&#x662F;&#x7531;&#x4E8E;3.0.0&#x7248;&#x672C;&#x4E2D;create-all-sql-3.0.0.sql&#x5EFA;&#x8868;&#x65F6;&#x8868;executors&#x5C11;&#x4E86;executor_id&#x5217;&#x3002;&#x5728;github&#x4E0A;&#x67E5;&#x770B;&#x6E90;&#x7801;&#x6709;&#x4E0B;&#x9762;4&#x884C;sql&#x8BED;&#x53E5;&#x4FEE;&#x6539;&#x3002; 12345ALTER TABLE active_executing_flows DROP COLUMN host;ALTER TABLE active_executing_flows DROP COLUMN port;ALTER TABLE execution_flows ADD COLUMN executor_id INT DEFAULT NULL;CREATE INDEX executor_id ON execution_flows(executor_id); &#x53C2;&#x8003; https://github.com/azkaban/azkaban/issues/582 &#x548C; https://github.com/azkaban/azkaban/pull/591 &#x52A0;&#x5165;hdfsviewer&#x4E4B;&#x540E;&#xFF0C;&#x542F;&#x52A8;web&#x65F6;&#x51FA;&#x73B0;&#x5F02;&#x5E38;java.lang.ClassNotFoundException: org.json.JSONException&#xFF0C;&#x8FD9;&#x662F;&#x7531;&#x4E8E;json&#x5305;&#x7F3A;&#x5931;&#x5F15;&#x8D77;&#x7684;&#xFF0C;&#x76F4;&#x63A5;&#x53BB;http://mvnrepository.com/artifact/org.json/json/20160212&#x4E0B;&#x8F7D;&#x6B64;json&#x5305;&#x653E;&#x5728;azkaban-web-server-3.0.0/lib/&#x4E0B;&#x5373;&#x53EF;&#x3002;","categories":[],"tags":[{"name":"schedule","slug":"schedule","permalink":"http://wzktravel.github.io/tags/schedule/"},{"name":"azkaban","slug":"azkaban","permalink":"http://wzktravel.github.io/tags/azkaban/"}]},{"title":"quartz in practice","slug":"quartz-in-practice","date":"2016-04-14T03:26:50.000Z","updated":"2016-08-24T07:25:09.000Z","comments":true,"path":"2016/04/14/quartz-in-practice/","link":"","permalink":"http://wzktravel.github.io/2016/04/14/quartz-in-practice/","excerpt":"基于quartz 2.2.1版本，quartz使用数据库(mysql)作为持久化策略。","text":"&#x57FA;&#x4E8E;quartz 2.2.1&#x7248;&#x672C;&#xFF0C;quartz&#x4F7F;&#x7528;&#x6570;&#x636E;&#x5E93;(mysql)&#x4F5C;&#x4E3A;&#x6301;&#x4E45;&#x5316;&#x7B56;&#x7565;&#x3002; &#x914D;&#x7F6E;quartz.properties1234567891011121314151617181920212223# quartz&#x914D;&#x7F6E; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/configuration/index.html# &#x4E3B;&#x8981;&#x914D;&#x7F6E; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigMain.htmlorg.quartz.scheduler.instanceName = DataptQuartzScheduler# &#x7EBF;&#x7A0B;&#x6C60;&#x914D;&#x7F6E; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigThreadPool.htmlorg.quartz.threadPool.class = org.quartz.simpl.SimpleThreadPoolorg.quartz.threadPool.threadCount = 10org.quartz.threadPool.threadPriority = 5org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread = true# &#x6301;&#x4E45;&#x5316;&#x914D;&#x7F6E; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigJobStoreTX.htmlorg.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTXorg.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegateorg.quartz.jobStore.tablePrefix = QRTZ_org.quartz.jobStore.dataSource = dataptDS# &#x6570;&#x636E;&#x5E93;&#x8FDE;&#x63A5;&#x8BBE;&#x7F6E; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/configuration/ConfigDataSources.htmlorg.quartz.dataSource.dataptDS.driver = com.mysql.jdbc.Driverorg.quartz.dataSource.dataptDS.URL = jdbc:mysql://ip:port/quartz?useUnicode=true&amp;characterEncoding=utf-8org.quartz.dataSource.dataptDS.user = usernameorg.quartz.dataSource.dataptDS.password = passwordorg.quartz.dataSource.dataptDS.maxConnections = 30 &#x521D;&#x59CB;&#x5316;mysql&#x53EF;&#x4EE5;&#x9002;&#x7528;&#x591A;&#x79CD;&#x6570;&#x636E;&#x5E93;&#xFF0C;&#x521D;&#x59CB;&#x5316;sql&#x6587;&#x4EF6;&#x5728;docs/dbTables/&#x4E0B;&#xFF0C;mysql&#x53EF;&#x4EE5;&#x4F7F;&#x7528;tables_mysql_innodb.sql&#xFF0C;&#x5B98;&#x65B9;&#x5EFA;&#x8BAE;&#x4F7F;&#x7528;innodb&#x5F15;&#x64CE;&#x3002;&#x6211;&#x8FD9;&#x8FB9;&#x6570;&#x636E;&#x5E93;&#x540D;&#x4F7F;&#x7528;quartz. ListenerJobListener&#x548C;TriggerListener&#x6267;&#x884C;&#x987A;&#x5E8F;: trigger fired job to be executed job&#x6267;&#x884C; job was executed trigger complete JobListener&#x53C2;&#x8003; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/cookbook/JobListeners.html TriggerListener&#x53C2;&#x8003; http://www.quartz-scheduler.org/documentation/quartz-2.2.x/cookbook/TriggerListeners.html &#x53C2;&#x8003; quartz cookbook: http://www.quartz-scheduler.org/documentation/quartz-2.2.x/cookbook/","categories":[],"tags":[{"name":"quartz","slug":"quartz","permalink":"http://wzktravel.github.io/tags/quartz/"},{"name":"schedule","slug":"schedule","permalink":"http://wzktravel.github.io/tags/schedule/"}]},{"title":"查看修复HDFS中丢失的块","slug":"Fix-Corrupt-Blocks-on-HDFS","date":"2016-03-31T05:53:20.000Z","updated":"2016-12-28T03:19:14.000Z","comments":true,"path":"2016/03/31/Fix-Corrupt-Blocks-on-HDFS/","link":"","permalink":"http://wzktravel.github.io/2016/03/31/Fix-Corrupt-Blocks-on-HDFS/","excerpt":"","text":"&#x68C0;&#x6D4B;&#x7F3A;&#x5931;&#x5757;12hdfs fsck -list-corruptfileblockshdfs fsck / | egrep -v &apos;^\\.+$&apos; | grep -v eplica &#x67E5;&#x770B;&#x4E0A;&#x9762;&#x67D0;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x7684;&#x60C5;&#x51B5;1hdfs fsck /path/to/corrupt/file -locations -blocks -files &#x89E3;&#x51B3;&#x65B9;&#x6CD5; &#x5982;&#x679C;&#x6587;&#x4EF6;&#x4E0D;&#x91CD;&#x8981;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x5220;&#x9664;&#x6B64;&#x6587;&#x4EF6;&#xFF1B;&#x6216;&#x5220;&#x9664;&#x540E;&#x91CD;&#x65B0;&#x590D;&#x5236;&#x4E00;&#x4EFD;&#x5230;&#x96C6;&#x7FA4;&#x4E2D; 1hdfs fs -rm /path/to/file/with/permanently/missing/blocks &#x6216;&#x76F4;&#x63A5;&#x5168;&#x90E8;&#x5220;&#x9664; 1hdfs fsck / -delete &#x5982;&#x679C;&#x4E0D;&#x80FD;&#x5220;&#x9664;&#xFF0C;&#x9700;&#x8981;&#x4ECE;&#x4E0A;&#x9762;&#x547D;&#x4EE4;&#x4E2D;&#x627E;&#x5230;&#x53D1;&#x751F;&#x5728;&#x54EA;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#xFF0C;&#x7136;&#x540E;&#x5230;&#x6B64;&#x673A;&#x5668;&#x4E0A;&#x67E5;&#x770B;&#x65E5;&#x5FD7;&#x3002; &#x53C2;&#x8003; http://centoshowtos.org/hadoop/fix-corrupt-blocks-on-hdfs/ http://stackoverflow.com/questions/19205057/how-to-fix-corrupt-hadoop-hdfs","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"http://wzktravel.github.io/tags/hdfs/"}]},{"title":"CDH禁用kerberos","slug":"Disable-kerberos-in-CDH","date":"2016-03-05T02:23:51.000Z","updated":"2016-08-17T11:25:39.000Z","comments":true,"path":"2016/03/05/Disable-kerberos-in-CDH/","link":"","permalink":"http://wzktravel.github.io/2016/03/05/Disable-kerberos-in-CDH/","excerpt":"在CDH中如何禁用kerberos，以及在这个过程中遇到的一些问题和具体解决方法。","text":"&#x5728;CDH&#x4E2D;&#x5982;&#x4F55;&#x7981;&#x7528;kerberos&#xFF0C;&#x4EE5;&#x53CA;&#x5728;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x4E2D;&#x9047;&#x5230;&#x7684;&#x4E00;&#x4E9B;&#x95EE;&#x9898;&#x548C;&#x5177;&#x4F53;&#x89E3;&#x51B3;&#x65B9;&#x6CD5;&#x3002; &#x64CD;&#x4F5C; Hbase&#x4FEE;&#x6539;hbase.security.authentication&#x4E3A;simple&#xFF0C;&#x53D6;&#x6D88;&#x52FE;&#x9009;hbase.security.authorization HDFS&#x4FEE;&#x6539;hadoop.security.authentication&#x4E3A;simple&#xFF0C;&#x53D6;&#x6D88;&#x52FE;&#x9009;hadoop.security.authorization&#xFF0C;&#x5C06;datanode&#x7684;dfs.datanode.address&#x6062;&#x590D;&#x4E3A;50010&#xFF0C;dfs.datanode.http.address&#x6062;&#x590D;&#x4E3A;50075 Zookeeper&#x53D6;&#x6D88;&#x52FE;&#x9009;enableSecurity Hue&#x5B9E;&#x4F8B;&#x4E2D;&#x5220;&#x9664;Kerberos Ticket Renewer &#x91CD;&#x542F;&#x96C6;&#x7FA4;&#x524D;&#xFF0C;&#x624B;&#x52A8;&#x5C06;zookeeper /hbase&#x4E0B;&#x6240;&#x6709;znode&#x6743;&#x9650;&#x8BBE;&#x7F6E;&#x4E3A;world:anyone:cdrwa&#x3002;&#x4F7F;&#x7528;hbase&#x8D26;&#x53F7;&#xFF0C;&#x7136;&#x540E;&#x5728;hbase zkcli&#x4E2D;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x3002;&#x5982;&#x679C;&#x542F;&#x52A8;zkcli&#x65F6;&#x62A5;jline&#x76F8;&#x5173;&#x9519;&#x8BEF;&#xFF0C;&#x53EA;&#x9700;&#x5C06;zookeeper/lib&#x76EE;&#x5F55;&#x4E0B;0.9&#x7248;&#x672C;&#x5220;&#x9664;&#xFF0C;&#x7136;&#x540E;&#x62F7;&#x8D1D;1.1.2&#x7248;&#x672C;&#x5230;&#x6B64;&#x76EE;&#x5F55;&#x5373;&#x53EF;&#x89E3;&#x51B3;&#x3002; &#x5F02;&#x5E38;&#x4FE1;&#x606F;1. datanodes&#x65E0;&#x6CD5;&#x542F;&#x52A8;&#x5F02;&#x5E38;&#x4FE1;&#x606F;: java.io.IOException: Failed on local exception: java.net.SocketException: Permission denied; Host Details : local host is: &quot;xxxxx&quot;; destination host is: (unknown) &#x89E3;&#x51B3;&#x65B9;&#x6CD5;: &#x5C06;datanode&#x7684;dfs.datanode.address&#x6062;&#x590D;&#x4E3A;50010&#xFF0C;dfs.datanode.http.address&#x6062;&#x590D;&#x4E3A;50075&#x3002; 2. &#x7981;&#x7528;kerberos&#x540E;, hbase&#x65E0;&#x6CD5;&#x542F;&#x52A8;&#x5F02;&#x5E38;&#x4FE1;&#x606F;: &#x7981;&#x7528;kerberos&#x540E;&#xFF0C;&#x91CD;&#x542F;hbase&#x65F6;&#x62A5;Authentication is not valid : /hbase&#x9519;&#x8BEF; &#x539F;&#x56E0;: zookeeper&#x548C;hbase&#x542F;&#x7528;kerberos&#x540E;&#xFF0C;/hbase&#x76EE;&#x5F55;&#x6743;&#x9650;&#x5C5E;&#x4E8E;hbase&#x3002;12345[zk: vlnx103124:2181(CONNECTED) 0] getAcl /hbase/table/tsdb&apos;world,&apos;anyone: r&apos;sasl,&apos;hbase: cdrwa &#x89E3;&#x51B3;&#x65B9;&#x6848;: &#x91CD;&#x65B0;&#x542F;&#x7528;kerberos&#xFF0C;&#x7136;&#x540E;&#x624B;&#x52A8;&#x5C06;zookeeper&#x4E2D;/hbase&#x4E0B;&#x6240;&#x6709;znode&#x6743;&#x9650;&#x8BBE;&#x7F6E;&#x4E3A;world:anyone:cdrwa&#x3002;&#x4F7F;&#x7528;hbase&#x8D26;&#x53F7;&#xFF0C;&#x7136;&#x540E;&#x5728;hbase zkcli&#x4E2D;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x3002;&#x5982;&#x679C;&#x542F;&#x52A8;zkcli&#x65F6;&#x62A5;jline&#x76F8;&#x5173;&#x9519;&#x8BEF;&#xFF0C;&#x53EA;&#x9700;&#x5C06;zookeeper/lib&#x76EE;&#x5F55;&#x4E0B;0.9&#x7248;&#x672C;&#x5220;&#x9664;&#xFF0C;&#x7136;&#x540E;&#x62F7;&#x8D1D;1.1.2&#x7248;&#x672C;&#x5230;&#x6B64;&#x76EE;&#x5F55;&#x5373;&#x53EF;&#x89E3;&#x51B3;&#x3002; backing out kerberos is not an automatic process currently as there can be many services using Zookeeper and it retains those ACLs which were set while kerberos was enabled. We have developed a little java program for our customers that backs out the ACLs from ZK, but all it really does is iterate over all the znodes in /hbase and set their acls to world:anyone. So, you can just manually do this as well. This is an example:setAcl /hbase world:anyone:cdrwaYou would need to do that on every znode under /hbase and the master will start. &#x53C2;&#x8003;: HBase fails to start with an error &#x201C;NoAuth for /hbase/ Disabling Kerberos for CDH how to remove a node in zookeeper, forcibly ? 3. &#x7981;&#x7528;kerberos&#x540E;&#xFF0C;HA&#x60C5;&#x51B5;&#x4E0B;yarn&#x4E24;&#x4E2A;ResourceManager&#x90FD;&#x5904;&#x4E8E;standby&#x72B6;&#x6001;&#x5728;&#x4E0D;&#x6253;patch&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x8FD8;&#x672A;&#x89E3;&#x51B3;&#xFF0C;&#x4F46;&#x662F;&#x53EF;&#x4EE5;&#x7981;&#x7528;HA&#xFF0C;&#x53EA;&#x542F;&#x7528;&#x5355;&#x4E2A;&#x8282;&#x70B9;&#x3002;&#x53C2;&#x8003;https://issues.apache.org/jira/browse/YARN-2588","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"},{"name":"kerberos","slug":"kerberos","permalink":"http://wzktravel.github.io/tags/kerberos/"}]},{"title":"kerberos使用手册","slug":"how-to-use-kerberos-in-CDH","date":"2016-03-01T09:56:45.000Z","updated":"2016-08-24T07:25:09.000Z","comments":true,"path":"2016/03/01/how-to-use-kerberos-in-CDH/","link":"","permalink":"http://wzktravel.github.io/2016/03/01/how-to-use-kerberos-in-CDH/","excerpt":"kerberos使用手册，包括管理员和普通用户。","text":"kerberos&#x4F7F;&#x7528;&#x624B;&#x518C;&#xFF0C;&#x5305;&#x62EC;&#x7BA1;&#x7406;&#x5458;&#x548C;&#x666E;&#x901A;&#x7528;&#x6237;&#x3002; &#x7B80;&#x4ECB;kerberos&#x662F;&#x4EC0;&#x4E48;&#xFF1F; Kerberos&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x5355;&#x70B9;&#x767B;&#x5F55;(SSO)&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x8003;&#x8651;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x573A;&#x666F;&#xFF0C;&#x5728;&#x4E00;&#x4E2A;&#x7F51;&#x7EDC;&#x4E2D;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x670D;&#x52A1;&#x5668;&#xFF0C;&#x6BD4;&#x5982;&#xFF0C;&#x6253;&#x5370;&#x670D;&#x52A1;&#x5668;&#x3001;&#x90AE;&#x4EF6;&#x670D;&#x52A1;&#x5668;&#x548C;&#x6587;&#x4EF6;&#x670D;&#x52A1;&#x5668;&#x3002;&#x8FD9;&#x4E9B;&#x670D;&#x52A1;&#x5668;&#x90FD;&#x6709;&#x8BA4;&#x8BC1;&#x7684;&#x9700;&#x6C42;&#x3002;&#x5F88;&#x81EA;&#x7136;&#x7684;&#xFF0C;&#x4E0D;&#x53EF;&#x80FD;&#x8BA9;&#x6BCF;&#x4E2A;&#x670D;&#x52A1;&#x5668;&#x81EA;&#x5DF1;&#x5B9E;&#x73B0;&#x4E00;&#x5957;&#x8BA4;&#x8BC1;&#x7CFB;&#x7EDF;&#xFF0C;&#x800C;&#x662F;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;&#x4E2D;&#x5FC3;&#x8BA4;&#x8BC1;&#x670D;&#x52A1;&#x5668;&#xFF08;AS-Authentication Server&#xFF09;&#x4F9B;&#x8FD9;&#x4E9B;&#x670D;&#x52A1;&#x5668;&#x4F7F;&#x7528;&#x3002;&#x8FD9;&#x6837;&#x4EFB;&#x4F55;&#x5BA2;&#x6237;&#x7AEF;&#x5C31;&#x53EA;&#x9700;&#x7EF4;&#x62A4;&#x4E00;&#x4E2A;&#x5BC6;&#x7801;&#x5C31;&#x80FD;&#x767B;&#x5F55;&#x6240;&#x6709;&#x670D;&#x52A1;&#x5668;&#x3002; &#x56E0;&#x6B64;&#xFF0C;&#x5728;Kerberos&#x7CFB;&#x7EDF;&#x4E2D;&#x81F3;&#x5C11;&#x6709;&#x4E09;&#x4E2A;&#x89D2;&#x8272;&#xFF1A;&#x8BA4;&#x8BC1;&#x670D;&#x52A1;&#x5668;&#xFF08;AS&#xFF09;&#xFF0C;&#x5BA2;&#x6237;&#x7AEF;&#xFF08;Client&#xFF09;&#x548C;&#x666E;&#x901A;&#x670D;&#x52A1;&#x5668;&#xFF08;Server&#xFF09;&#x3002;&#x5BA2;&#x6237;&#x7AEF;&#x548C;&#x670D;&#x52A1;&#x5668;&#x5C06;&#x5728;AS&#x7684;&#x5E2E;&#x52A9;&#x4E0B;&#x5B8C;&#x6210;&#x76F8;&#x4E92;&#x8BA4;&#x8BC1;&#x3002;&#x5728;Kerberos&#x7CFB;&#x7EDF;&#x4E2D;&#xFF0C;&#x5BA2;&#x6237;&#x7AEF;&#x548C;&#x670D;&#x52A1;&#x5668;&#x90FD;&#x6709;&#x4E00;&#x4E2A;&#x552F;&#x4E00;&#x7684;&#x540D;&#x5B57;&#xFF0C;&#x53EB;&#x505A;Principal&#x3002;&#x540C;&#x65F6;&#xFF0C;&#x5BA2;&#x6237;&#x7AEF;&#x548C;&#x670D;&#x52A1;&#x5668;&#x90FD;&#x6709;&#x81EA;&#x5DF1;&#x7684;&#x5BC6;&#x7801;&#xFF0C;&#x5E76;&#x4E14;&#x5B83;&#x4EEC;&#x7684;&#x5BC6;&#x7801;&#x53EA;&#x6709;&#x81EA;&#x5DF1;&#x548C;&#x8BA4;&#x8BC1;&#x670D;&#x52A1;&#x5668;AS&#x77E5;&#x9053;&#x3002; kerberos&#x5728;CDH&#x4E2D;&#x7684;&#x4F7F;&#x7528; &#x5728;&#x5404;&#x670D;&#x52A1;&#x4E4B;&#x95F4;&#x901A;&#x4FE1;&#x4F7F;&#x7528;kerberos&#xFF0C;&#x5982;&#x5404;&#x670D;&#x52A1;&#x8FDE;&#x63A5;zookeeper&#xFF0C;opentsdb&#x8FDE;&#x63A5;hbase&#x3002; &#x4F7F;&#x7528;&#x5404;&#x670D;&#x52A1;&#x5BA2;&#x6237;&#x7AEF;&#x65F6;&#xFF0C;&#x5FC5;&#x987B;&#x9996;&#x5148;&#x5207;&#x6362;&#x5230;&#x81EA;&#x5DF1;&#x7684;kerberos&#x8D26;&#x6237;&#xFF0C;&#x624D;&#x80FD;&#x591F;&#x8FDE;&#x63A5;&#x5230;&#x5404;&#x670D;&#x52A1;&#xFF0C;&#x5426;&#x5219;&#x4F1A;&#x62A5;&#x9519;&#x3002; &#x542F;&#x7528;kerberos&#x540E;&#xFF0C;&#x8FDE;&#x63A5;hive&#x53EA;&#x80FD;&#x4F7F;&#x7528;beeline&#xFF0C;hive&#x4E0D;&#x518D;&#x652F;&#x6301;&#x3002; &#x666E;&#x901A;&#x7528;&#x6237;&#x53C2;&#x8003;http://web.mit.edu/kerberos/krb5-latest/doc/user/index.html&#x6BCF;&#x4EBA;&#x5C3D;&#x91CF;&#x4F7F;&#x7528;&#x81EA;&#x5DF1;&#x7684;&#x8D26;&#x53F7;&#x767B;&#x9646;&#x96C6;&#x7FA4;&#x4E2D;&#x673A;&#x5668;&#xFF0C;&#x5426;&#x5219;&#x53EF;&#x80FD;&#x5728;&#x5207;&#x6362;kerberos&#x8D26;&#x6237;&#x65F6;&#x8986;&#x76D6;&#x5176;&#x4ED6;&#x4EBA;&#x8D26;&#x53F7;&#x6216;&#x88AB;&#x8986;&#x76D6;&#x3002; &#x4F7F;&#x7528;&#x5BC6;&#x7801;&#x5207;&#x6362;&#x7528;&#x6237; 1kinit username &#x6B64;&#x547D;&#x4EE4;&#x9700;&#x8981;&#x8F93;&#x5165;&#x4F60;&#x5728;kerberos&#x4E2D;&#x7684;&#x5BC6;&#x7801; &#x4FEE;&#x6539;&#x5BC6;&#x7801; 1kpassword &#x66F4;&#x65B0;credentials 1kinit -R &#x9500;&#x6BC1;credentials 1kdestroy &#x4F7F;&#x7528;keytab 1kinit -k -t user.keytab username &#x514D;&#x5BC6;&#x7801;&#x5207;&#x6362;&#x7528;&#x6237;&#xFF0C;&#x4F46;&#x662F;&#x9700;&#x8981;&#x63D0;&#x524D;&#x751F;&#x6210;&#x597D;keytab&#xFF0C;&#x5E76;&#x4FDD;&#x8BC1;&#x53EA;&#x6709;&#x81EA;&#x5DF1;&#x6709;&#x8BFB;&#x5199;&#x6743;&#x9650;&#x3002; 1klist -k user.keytab &#x67E5;&#x770B;&#x6B64;keytab&#x4E2D;&#x6240;&#x6709;principal &#x7BA1;&#x7406;&#x5458;&#x53C2;&#x8003;http://web.mit.edu/kerberos/krb5-latest/doc/admin/database.html &#x8FDB;&#x5165;kerberos&#x7BA1;&#x7406;&#x9875;&#x9762;&#xFF0C;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#xFF1A;&#x5728;Krb5 server&#x6240;&#x5728;&#x673A;&#x5668;&#x5E76;&#x4E14;&#x5F53;&#x524D;&#x7528;&#x6237;&#x662F;root&#x7684;&#x8BDD;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;kadmin.local&#x514D;&#x5BC6;&#x7801;&#x8FDB;&#x5165;&#xFF1B;&#x5F53;&#x524D;&#x7528;&#x6237;&#x662F;&#x975E;root&#x7528;&#x6237;&#x6216;&#x5728;&#x5176;&#x4ED6;&#x673A;&#x5668;&#x4E0A;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;kadmin $admin_user&#x8FDB;&#x5165;&#xFF0C;&#x9700;&#x8981;&#x8F93;&#x5165;&#x6B64;admin&#x7528;&#x6237;&#x7684;&#x5BC6;&#x7801;&#x3002;&#x5982;&#x679C;&#x9700;&#x8981;&#x76F4;&#x63A5;&#x6267;&#x884C;&#x547D;&#x4EE4;&#xFF0C;&#x4F7F;&#x7528;-q&#x53C2;&#x6570; 1kadmin.local -q &quot;listprincs&quot; &#x5217;&#x51FA;&#x6240;&#x6709;principal: list_principals, listprincs listprincs [expression] 1listprincs *test* &#x67E5;&#x770B;principal&#x4FE1;&#x606F;: get_principal, getprinc getprinc [-terse] principal -terse&#x8F93;&#x51FA;&#x66F4;&#x52A0;&#x7B80;&#x6D01;&#xFF0C;&#x5404;&#x4FE1;&#x606F;&#x4E4B;&#x95F4;&#x4EE5;tab&#x4F5C;&#x4E3A;&#x5206;&#x9694;&#x7B26;&#x3002; &#x6DFB;&#x52A0;principal: add_principal, addprinc addprinc [options] principal -randkey&#x968F;&#x673A;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x503C;&#x4F5C;&#x4E3A;principal&#x7684;key -pw&#x8BBE;&#x7F6E;&#x5BC6;&#x7801;&#xFF0C;&#x6B64;&#x9009;&#x9879;&#x4E00;&#x822C;&#x7528;&#x5728;&#x811A;&#x672C;&#x4E2D;&#x3002; &#x793A;&#x4F8B; 12addprinc -pw password user@DOMAIN.COMaddprinc -randkey user@DOMAIN.COM &#x53E6;&#x5916;&#x53EF;&#x4EE5;&#x5BF9;principal&#x8BBE;&#x7F6E;&#x8FC7;&#x671F;&#x65F6;&#x95F4;&#x7B49;&#xFF0C;&#x5177;&#x4F53;&#x53C2;&#x8003;&#x4E0A;&#x65B9;&#x94FE;&#x63A5;&#x3002; &#x4FEE;&#x6539;principal: modify_principal, modprinc&#x4E0E;addprinc&#x547D;&#x4EE4;&#x9009;&#x9879;&#x57FA;&#x672C;&#x4E00;&#x81F4;, modprinc [options] principal &#x5220;&#x9664;principal: delete_principal, delprinc delprinc [-force] principal &#x4FEE;&#x6539;&#x5BC6;&#x7801;: change_password, cpw change_password [options] principal -randkey&#x968F;&#x673A;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x503C;&#x4F5C;&#x4E3A;principal&#x7684;key -pw&#x8BBE;&#x7F6E;&#x5BC6;&#x7801;&#xFF0C;&#x6B64;&#x9009;&#x9879;&#x4E00;&#x822C;&#x7528;&#x5728;&#x811A;&#x672C;&#x4E2D;&#x3002; &#x793A;&#x4F8B; 12cpw usercpw -pw password user &#x751F;&#x6210;keytab &#x751F;&#x6210;&#x5355;&#x4E00;&#x7684;keytab: xst -k ${USERNAME}.keytab ${USERNAME}@DOMAIN.COM &#x5408;&#x5E76;&#x591A;&#x4E2A;keytab 12345$ ktutilktutil: rkt a.keytabktutil: rkt b.keytabktutil: wkt merge.keytabktutil: exit","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"},{"name":"kerberos","slug":"kerberos","permalink":"http://wzktravel.github.io/tags/kerberos/"}]},{"title":"CDH启用sentry","slug":"Enabling-sentry-in-CDH","date":"2016-02-25T06:22:59.000Z","updated":"2016-08-24T07:25:14.000Z","comments":true,"path":"2016/02/25/Enabling-sentry-in-CDH/","link":"","permalink":"http://wzktravel.github.io/2016/02/25/Enabling-sentry-in-CDH/","excerpt":"CDH集群启用sentry步骤和测试。","text":"CDH&#x96C6;&#x7FA4;&#x542F;&#x7528;sentry&#x6B65;&#x9AA4;&#x548C;&#x6D4B;&#x8BD5;&#x3002; CDH&#x542F;&#x7528;sentryCDH&#x4E2D;&#x6DFB;&#x52A0;sentry&#x670D;&#x52A1;&#x540E;&#xFF0C;&#x6309;&#x7167;Configuring the Sentry Service&#x4E00;&#x6B65;&#x6B65;&#x8FDB;&#x884C;&#x6765;&#x914D;&#x7F6E;sentry&#x670D;&#x52A1;&#x3002; Before Enabling the Sentry Service &#x8BBE;&#x7F6E;hive.metastore.warehouse.dir&#x914D;&#x7F6E;&#x9879;(&#x9ED8;&#x8BA4;&#x8DEF;&#x5F84;&#x662F;/user/hive/warehouse)&#x7684;&#x6743;&#x9650;&#x548C;owner&#x3002;12$ hdfs dfs -chmod -R 771 /user/hive/warehouse$ hdfs dfs -chown -R hive:hive /user/hive/warehouse &#x5982;&#x679C;&#x5DF2;&#x7ECF;&#x542F;&#x7528;&#x4E86;kerberos&#xFF0C;&#x9700;&#x8981;kinit -k -t hdfs.keytab hdfs&#x3002; Disable impersonation for HiveServer2&#x914D;&#x7F6E;&#x9879;: hive &#x2013; HiveServer2 Enable Impersonation Enable the Hive user to submit YARN jobsEnsure the Allowed System Users property includes the hive user. If not, add hive.&#x914D;&#x7F6E;&#x9879;: yarn &#x2013; allowed.system.users Important: Ensure you have unchecked the Enable Sentry Authorization using Policy Files configuration property for both Hive and Impala under the Policy File Based Sentry category before you proceed. Enabling the Sentry Service for Hive &#x4FEE;&#x6539;hive&#x914D;&#x7F6E;&#x9879;Sentry Service&#xFF0C;&#x9009;&#x62E9;&#x201D;Sentry&#x201D; &#x53D6;&#x6D88;&#x9009;&#x4E2D;hive.server2.enable.impersonation Enabling the Sentry Service for Impala&#x4FEE;&#x6539;impala&#x914D;&#x7F6E;&#x9879;Sentry Service&#xFF0C;&#x9009;&#x62E9;&#x201D;Sentry&#x201D; Enabling the Sentry Service for Hue&#x4FEE;&#x6539;hue&#x914D;&#x7F6E;&#x9879;Sentry Service&#xFF0C;&#x9009;&#x62E9;&#x201D;Sentry&#x201D; Important: When Sentry is enabled, you must use Beeline to execute Hive queries. Hive CLI is not supported with Sentry and must be disabled as described here. When Sentry is enabled, a user with no privileges on a database will not be allowed to connect to HiveServer2. This is because the use command is now executed as part of the connection to HiveServer2, which is why the connection fails. See HIVE-4256. &#x914D;&#x7F6E;hive with sentryhttp://www.cloudera.com/documentation/enterprise/5-4-x/topics/sg_hive_sql.html &#x5982;&#x679C;&#x542F;&#x7528;&#x4E86;kerbreos&#x542F;&#x7528;kerberos&#x540E;&#xFF0C;&#x4F7F;&#x7528;&#x4E0B;&#x9762;&#x547D;&#x4EE4;&#x8FDB;&#x5165;beeline&#x8FDB;&#x884C;&#x8BBE;&#x7F6E;12$ kinit -k -t hive.keytab hive$ beeline -u &quot;jdbc:hive2://vlnx107011:10000/default;principal=hive/vlnx107011@HADOOP.COM&quot; &#x5982;&#x679C;&#x672A;&#x542F;&#x7528;kerberos&#x5728;hive&#x914D;&#x7F6E;sentry-site.xml &#x7684; Hive &#x670D;&#x52A1;&#x9AD8;&#x7EA7;&#x914D;&#x7F6E;&#x4EE3;&#x7801;&#x6BB5;&#xFF08;&#x5B89;&#x5168;&#x9600;&#xFF09;&#x4E2D;&#x6DFB;&#x52A0; 1234&lt;property&gt; &lt;name&gt;sentry.hive.testing.mode&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; &#x53EF;&#x4EE5;&#x4F7F;&#x7528;beeline -u &quot;jdbc:hive2://vlnx107011:10000/&quot; -n &lt;admin_user&gt;&#x8FDB;&#x884C;&#x8BBE;&#x7F6E;&#xFF0C;&#x5176;&#x4E2D;admin&#x7528;&#x6237;&#x5728;sentry&#x7684;sentry.service.admin.group&#x4E2D;&#x914D;&#x7F6E;&#x3002; Important: &#x7528;&#x6237;&#x548C;&#x7EC4;&#x4F7F;&#x7528;&#x7684;&#x662F;Linux&#x673A;&#x5668;&#x4E0A;&#x7684;&#x7528;&#x6237;&#x548C;&#x7EC4;&#xFF0C;&#x800C;&#x89D2;&#x8272;&#x5FC5;&#x987B;&#x81EA;&#x5DF1;&#x521B;&#x5EFA;&#x3002; &#x914D;&#x7F6E;HDFS with sentry&#x53C2;&#x8003;http://www.cloudera.com/documentation/enterprise/5-4-x/topics/sg_hdfs_sentry_sync.html &#x5173;&#x4E8E;hdfs acl&#xFF0C;&#x53C2;&#x8003;http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cdh_sg_hdfs_ext_acls.html hdfs acl &#x542F;&#x7528;Sentry&#x540C;&#x6B65; &#x68C0;&#x67E5;HDFS&#x6743;&#x9650;&#xFF0C;dfs.permissions&#x3002; &#x8BBE;&#x7F6E;Sentry&#x540C;&#x6B65;&#x8DEF;&#x5F84;&#x524D;&#x7F00;, sentry.hdfs.integration.path.prefixes&#xFF0C;&#x53EF;&#x4EE5;&#x591A;&#x4E2A;&#x3002; Sentry-HDFS authorization is focused on Hive warehouse data - that is, any data that is part of a table in Hive or Impala. The real objective of this integration is to expand the same authorization checks to Hive warehouse data being accessed from any other components such as Pig, MapReduce or Spark. At this point, this feature does not replace HDFS ACLs. Tables that are not associated with Sentry will retain their old ACLs. &#x5B58;&#x5728;&#x54EA;&#x4E9B;&#x95EE;&#x9898;: sentry.hdfs.integration.path.prefixes&#x66F4;&#x6539;&#x9700;&#x8981;&#x91CD;&#x542F;hdfs &#x542F;&#x7528;&#x540E;hdfs acl&#x5931;&#x6548; hdfs uri&#x4E0D;&#x80FD;&#x81EA;&#x52A8;&#x7EDF;&#x4E00;&#x6210;&#x6807;&#x51C6;&#x683C;&#x5F0F;&#x3002;/facishare-data/, hdfs:///facishare-data/, hdfs://nameservice1/facishare-data/, hdfs://nameservice1:8020/facishare-data/&#x5728;sentry&#x7684;&#x7406;&#x89E3;&#x4E2D;&#x662F;&#x4E0D;&#x540C;&#x7684;&#x8DEF;&#x5F84;&#x3002; hue&#x4E2D;&#x8FDB;&#x884C;sentry&#x914D;&#x7F6E;http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/#howto&#x5728;ldap&#x4E2D;&#x65B0;&#x5EFA;&#x4E86;&#x670D;&#x52A1;&#x8D26;&#x53F7;&#xFF0C;&#x7528;&#x4E8E;&#x5728;hue&#x4E2D;&#x5BF9;sentry&#x8FDB;&#x884C;&#x8BBE;&#x7F6E; &#x5728;&#x6240;&#x6709;&#x673A;&#x5668;&#x4E0A;&#x540C;&#x6B65;&#x6B64;&#x8D26;&#x53F7;&#x548C;&#x7EC4; &#x5728;sentry&#x4E2D;&#x5C06;&#x6B64;&#x8D26;&#x53F7;&#x7EC4;&#x52A0;&#x5165;&#x5230;&#x7BA1;&#x7406;&#x5458;&#x7EC4;sentry.service.admin.group&#x4E2D; hue&#x4E2D;&#x65B0;&#x5EFA;hive&#x7EC4;&#xFF0C;&#x5E76;&#x5C06;&#x6B64;&#x8D26;&#x53F7;&#x52A0;&#x5165;&#x5230;hive&#x7EC4; &#x9644;&#x5F55;: hive&#x6743;&#x9650; &#x64CD;&#x4F5C; &#x89E3;&#x91CA; ALL &#x6240;&#x6709;&#x6743;&#x9650; ALTER &#x5141;&#x8BB8;&#x4FEE;&#x6539;&#x5143;&#x6570;&#x636E;&#xFF08;modify metadata data of object&#xFF09;&#x2014;&#x8868;&#x4FE1;&#x606F;&#x6570;&#x636E; UPDATE &#x5141;&#x8BB8;&#x4FEE;&#x6539;&#x7269;&#x7406;&#x6570;&#x636E;&#xFF08;modify physical data of object&#xFF09;&#x2014;&#x5B9E;&#x9645;&#x6570;&#x636E; CREATE &#x5141;&#x8BB8;&#x8FDB;&#x884C;Create&#x64CD;&#x4F5C; DROP &#x5141;&#x8BB8;&#x8FDB;&#x884C;DROP&#x64CD;&#x4F5C; INDEX &#x5141;&#x8BB8;&#x5EFA;&#x7D22;&#x5F15;&#xFF08;&#x76EE;&#x524D;&#x8FD8;&#x6CA1;&#x6709;&#x5B9E;&#x73B0;&#xFF09; LOCK &#x5F53;&#x51FA;&#x73B0;&#x5E76;&#x53D1;&#x7684;&#x4F7F;&#x7528;&#x5141;&#x8BB8;&#x7528;&#x6237;&#x8FDB;&#x884C;LOCK&#x548C;UNLOCK&#x64CD;&#x4F5C; SELECT &#x5141;&#x8BB8;&#x7528;&#x6237;&#x8FDB;&#x884C;SELECT&#x64CD;&#x4F5C; SHOW_DATABASE &#x5141;&#x8BB8;&#x7528;&#x6237;&#x67E5;&#x770B;&#x53EF;&#x7528;&#x7684;&#x6570;&#x636E;&#x5E93; Hive SQL Syntax for Use with Sentry&#x521B;&#x5EFA;&#x548C;&#x5220;&#x9664;&#x89D2;&#x8272; &#x521B;&#x5EFA;&#x89D2;&#x8272;: create role ROLE_NAME &#x5220;&#x9664;&#x89D2;&#x8272;: droop role ROLE_NAME &#x89D2;&#x8272;&#x7684;&#x6388;&#x6743;&#x548C;&#x64A4;&#x9500;&#x89D2;&#x8272;&#x7684;&#x6388;&#x6743;(GRANT)&#x5C31;&#x662F;&#x7ED9;&#x89D2;&#x8272;&#x6388;&#x4E88;&#x521B;&#x5EFA;&#x8868;&#x3001;&#x67E5;&#x8BE2;&#x8868;&#x7B49;&#x64CD;&#x4F5C;&#xFF0C;&#x64A4;&#x9500;(REVOKE)&#x53CD;&#x4E4B;&#x3002;&#x8BED;&#x6CD5;&#x5982;&#x4E0B;&#xFF1A; 12GRANT ROLE role_name [, role_name] TO GROUP &lt;groupName&gt; [,GROUP &lt;groupName&gt;]REVOKE ROLE role_name [, role_name] FROM GROUP &lt;groupName&gt; [,GROUP &lt;groupName&gt;] &#x6743;&#x9650;&#x7684;&#x6388;&#x4E88;&#x548C;&#x64A4;&#x9500;12GRANT &lt;PRIVILEGE&gt; [, &lt;PRIVILEGE&gt; ] ON &lt;OBJECT&gt; &lt;object_name&gt; TO ROLE &lt;roleName&gt; [,ROLE &lt;roleName&gt;]REVOKE &lt;PRIVILEGE&gt; [, &lt;PRIVILEGE&gt; ] ON &lt;OBJECT&gt; &lt;object_name&gt; FROM ROLE &lt;roleName&gt; [,ROLE &lt;roleName&gt;] &#x67E5;&#x770B;&#x89D2;&#x8272;/&#x7EC4;&#x6743;&#x9650;12345SHOW ROLES;SHOW CURRENT ROLES;SHOW ROLE GRANT GROUP &lt;groupName&gt;;SHOW GRANT ROLE &lt;roleName&gt;;SHOW GRANT ROLE &lt;roleName&gt; on OBJECT &lt;objectName&gt;; &#x793A;&#x4F8B;&#xFF1A; &#x628A;role_test1&#x89D2;&#x8272;&#x6388;&#x6743;&#x7ED9;test&#x7EC4;: grant role role_test1 to group test &#x67E5;&#x770B;test&#x7EC4;&#x88AB;&#x6388;&#x6743;&#x7684;&#x89D2;&#x8272;: show role grant group test &#x53D6;&#x6D88;test&#x7EC4;&#x7684;role_test1&#x89D2;&#x8272;: revoke role role_test1 from group test Grant privileges to analyst_role: 1234CREATE ROLE analyst_role;GRANT ALL ON DATABASE analyst1 TO ROLE analyst_role;GRANT SELECT ON DATABASE jranalyst1 TO ROLE analyst_role;GRANT ALL ON URI &apos;hdfs://ha-nn-uri/landing/analyst1&apos; TO ROLE analyst_role; Grant privileges to junior_analyst_role: 1234CREATE ROLE junior_analyst_role;GRANT ALL ON DATABASE jranalyst1 TO ROLE junior_analyst_role;GRANT ALL ON URI &apos;hdfs://ha-nn-uri/landing/jranalyst1&apos; TO ROLE junior_analyst_role;grant all on database test to role admin_role with grant option; Grant privileges to admin_role: 12CREATE ROLE admin_roleGRANT ALL ON SERVER server TO ROLE admin_role; Grant roles to groups: 123GRANT ROLE admin_role TO GROUP admin;GRANT ROLE analyst_role TO GROUP analyst;GRANT ROLE jranalyst_role TO GROUP jranalyst; &#x53C2;&#x8003;: Authorization Privilege Model for Hive and Impala: http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_sg_sentry_service.html#concept_cx4_sw2_q4_unique_1 The Sentry Service: http://www.cloudera.com/documentation/enterprise/5-4-x/topics/cm_sg_sentry_service.html Apache Sentry made easy with the new Hue Security App: http://gethue.com/apache-sentry-made-easy-with-the-new-hue-security-app/#howto What is missing in Apache Sentry (incubating)?: http://getindata.com/blog/post/what-is-missing-in-apache-sentry-incubating/ Apache Sentry Tutorial: https://cwiki.apache.org/confluence/display/SENTRY/Sentry+Tutorial","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"},{"name":"sentry","slug":"sentry","permalink":"http://wzktravel.github.io/tags/sentry/"}]},{"title":"Flume SpoolDirectorySource遇到emoj截断问题","slug":"flume-hdfs-ucs-4","date":"2016-01-29T05:09:59.000Z","updated":"2016-08-24T07:24:59.000Z","comments":true,"path":"2016/01/29/flume-hdfs-ucs-4/","link":"","permalink":"http://wzktravel.github.io/2016/01/29/flume-hdfs-ucs-4/","excerpt":"最近在flume上报hdfs过程中遇到一些文件在中间被截断的问题，经过排查发现遇到emoj表情时会出现这种情况，如”上海👃”。下面介绍问题是如何定位并修复的。以下代码都基于org.apache.flume:flume-ng-core:1.6.0。","text":"&#x6700;&#x8FD1;&#x5728;flume&#x4E0A;&#x62A5;hdfs&#x8FC7;&#x7A0B;&#x4E2D;&#x9047;&#x5230;&#x4E00;&#x4E9B;&#x6587;&#x4EF6;&#x5728;&#x4E2D;&#x95F4;&#x88AB;&#x622A;&#x65AD;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x7ECF;&#x8FC7;&#x6392;&#x67E5;&#x53D1;&#x73B0;&#x9047;&#x5230;emoj&#x8868;&#x60C5;&#x65F6;&#x4F1A;&#x51FA;&#x73B0;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;&#x5982;&#x201D;&#x4E0A;&#x6D77;&#x1F443;&#x201D;&#x3002;&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;&#x95EE;&#x9898;&#x662F;&#x5982;&#x4F55;&#x5B9A;&#x4F4D;&#x5E76;&#x4FEE;&#x590D;&#x7684;&#x3002;&#x4EE5;&#x4E0B;&#x4EE3;&#x7801;&#x90FD;&#x57FA;&#x4E8E;org.apache.flume:flume-ng-core:1.6.0&#x3002; &#x9996;&#x5148;&#x770B;SpoolDirectorySource.java&#xFF0C;&#x8FD9;&#x662F;&#x6574;&#x4E2A;Spooling Directory Source&#x7684;&#x5165;&#x53E3;&#x3002;SpoolDirectorySource.start&#x7247;&#x6BB5;:12345678910111213141516171819202122232425@Overridepublic synchronized void start() { ... try { reader = new ReliableSpoolingFileEventReader.Builder() .spoolDirectory(directory) .completedSuffix(completedSuffix) .ignorePattern(ignorePattern) .trackerDirPath(trackerDirPath) .annotateFileName(fileHeader) .fileNameHeader(fileHeaderKey) .annotateBaseName(basenameHeader) .baseNameHeader(basenameHeaderKey) .deserializerType(deserializerType) .deserializerContext(deserializerContext) .deletePolicy(deletePolicy) .inputCharset(inputCharset) .decodeErrorPolicy(decodeErrorPolicy) .consumeOrder(consumeOrder) .build(); } catch (IOException ioe) { throw new FlumeException(&quot;Error instantiating spooling event parser&quot;, ioe); } ...} &#x548C;SpoolDirectorySource&#x5185;&#x90E8;&#x7C7B;SpoolDirectoryRunnable.run&#x7247;&#x6BB5;12345678910111213@Overridepublic void run() { ... while (!Thread.interrupted()) { List&lt;Event&gt; events = reader.readEvents(batchSize); if (events.isEmpty()) { break; } sourceCounter.addToEventReceivedCount(events.size()); sourceCounter.incrementAppendBatchReceivedCount(); ... }} &#x53EF;&#x4EE5;&#x770B;&#x5230;&#x8C03;&#x7528;&#x4E86;ReliableSpoolingFileEventReader&#x4E2D;&#x7684;readEvents&#x65B9;&#x6CD5;&#x8BFB;&#x53D6;&#x6587;&#x4EF6;&#x4E2D;&#x6570;&#x636E;&#xFF0C;&#x7136;&#x540E;&#x53BB;&#x770B;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x7684;&#x5B9E;&#x73B0;&#x3002; ReliableSpoolingFileEventReader.readEvents&#x7247;&#x6BB5;:12345678910111213public List&lt;Event&gt; readEvents(int numEvents) throws IOException { ... while (events.isEmpty()) { logger.info(&quot;Last read took us just up to a file boundary. Rolling to the next file, if there is one.&quot;); retireCurrentFile(); currentFile = getNextFile(); if (!currentFile.isPresent()) { return Collections.emptyList(); } events = currentFile.get().getDeserializer().readEvents(numEvents); } ...} &#x6B64;&#x6BB5;&#x4EE3;&#x7801;&#x4E0A;&#x4E0B;&#x90E8;&#x5206;&#x4E3B;&#x8981;&#x662F;&#x5BF9;&#x72B6;&#x6001;&#x548C;&#x6761;&#x4EF6;&#x7684;&#x4E00;&#x4E9B;&#x5224;&#x65AD;&#xFF0C;&#x83B7;&#x53D6;&#x6570;&#x636E;&#x7684;&#x4E3B;&#x8981;&#x90E8;&#x5206;&#x5728;currentFile.get().getDeserializer().readEvents(numEvents);&#xFF0C;&#x5982;&#x6B64;&#x5F97;&#x786E;&#x5B9A;&#x4F7F;&#x7528;&#x7684;&#x54EA;&#x4E00;&#x4E2A;EventDeserializer&#x3002; ReliableSpoolingFileEventReader.openFile&#x7247;&#x6BB5;:12345678910111213141516171819202122232425262728293031323334353637383940/** * Opens a file for consuming * @param file * @return {@link #FileInfo} for the file to consume or absent option if the * file does not exists or readable. */ private Optional&lt;FileInfo&gt; openFile(File file) { try { // roll the meta file, if needed String nextPath = file.getPath(); PositionTracker tracker = DurablePositionTracker.getInstance(metaFile, nextPath); if (!tracker.getTarget().equals(nextPath)) { tracker.close(); deleteMetaFile(); tracker = DurablePositionTracker.getInstance(metaFile, nextPath); } // sanity check Preconditions.checkState(tracker.getTarget().equals(nextPath), &quot;Tracker target %s does not equal expected filename %s&quot;, tracker.getTarget(), nextPath); ResettableInputStream in = new ResettableFileInputStream(file, tracker, ResettableFileInputStream.DEFAULT_BUF_SIZE, inputCharset, decodeErrorPolicy); EventDeserializer deserializer = EventDeserializerFactory.getInstance (deserializerType, deserializerContext, in); return Optional.of(new FileInfo(file, deserializer)); } catch (FileNotFoundException e) { // File could have been deleted in the interim logger.warn(&quot;Could not find file: &quot; + file, e); return Optional.absent(); } catch (IOException e) { logger.error(&quot;Exception opening file: &quot; + file, e); return Optional.absent(); } } &#x6B64;&#x65B9;&#x6CD5;&#x5B9A;&#x4E49;&#x4E86;&#x83B7;&#x53D6;&#x6587;&#x4EF6;&#x6570;&#x636E;&#x65F6;&#x4F7F;&#x7528;&#x7684;EventDeserializer&#xFF0C;&#x5728;SpoolDirectorySourceConfigurationConstants&#x4E2D;&#x770B;&#x5230;deserializerType&#x7684;&#x9ED8;&#x8BA4;&#x503C;&#x662F;LINE&#xFF0C;EventDeserializerFactory&#x4F1A;&#x6839;&#x636E;&#x6B64;&#x5B57;&#x6BB5;&#x6620;&#x5C04;&#x5230;LineDeserializer&#x3002; &#x53E6;&#x5916;&#x6B64;&#x65B9;&#x6CD5;&#x8FD8;&#x5B9A;&#x4E49;&#x4E86;ResettableInputStream&#xFF0C;&#x8FD9;&#x4E2A;&#x7C7B;&#x662F;&#x540E;&#x9762;&#x4E0E;&#x6587;&#x4EF6;&#x6253;&#x4EA4;&#x9053;&#x7684;&#xFF0C;&#x95EE;&#x9898;&#x4E5F;&#x662F;&#x51FA;&#x6765;&#x8FD9;&#x4E2A;&#x7C7B;&#x4E2D;&#x3002;&#x6CE8;&#x610F;inputCharset&#x548C;decodeErrorPolicy&#x4E24;&#x4E2A;&#x5B57;&#x6BB5;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x5206;&#x522B;&#x4E3A;UTF-8&#x548C;FAIL&#x3002;decodeErrorPolicy&#x5B57;&#x6BB5;&#x5B9A;&#x4E49;&#x4E86;&#x5982;&#x679C;&#x9047;&#x5230;&#x89E3;&#x6790;&#x5931;&#x8D25;&#x7684;&#x5B57;&#x7B26;&#x65F6;&#x5E94;&#x8BE5;&#x5982;&#x679C;&#x5904;&#x7406;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;FAIL&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x9009;&#x62E9;IGNORE&#x548C;REPLACE&#x3002;FAIL&#x65F6;&#x4F1A;&#x629B;&#x51FA;Exception&#xFF0C;flume&#x6574;&#x4E2A;&#x8FDB;&#x7A0B;&#x4F1A;&#x963B;&#x585E;&#x5728;&#x8FD9;&#xFF0C;IGNORE&#x4F1A;&#x5FFD;&#x7565;&#x6B64;&#x5B57;&#x7B26;&#xFF0C;REPLACE&#x4F1A;&#x7528;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x66FF;&#x4EE3;&#x3002; SpoolDirectorySourceConfigurationConstants&#x4E2D;&#x7247;&#x6BB5;:1234567891011/** Deserializer to use to parse the file data into Flume Events */public static final String DESERIALIZER = &quot;deserializer&quot;;public static final String DEFAULT_DESERIALIZER = &quot;LINE&quot;;/** Character set used when reading the input. */public static final String INPUT_CHARSET = &quot;inputCharset&quot;;public static final String DEFAULT_INPUT_CHARSET = &quot;UTF-8&quot;;/** What to do when there is a character set decoding error. */public static final String DECODE_ERROR_POLICY = &quot;decodeErrorPolicy&quot;;public static final String DEFAULT_DECODE_ERROR_POLICY = DecodeErrorPolicy.FAIL.name(); &#x518D;&#x56DE;&#x5230;readEvents&#x65B9;&#x6CD5;&#x4E0A;&#xFF0C;&#x53EA;&#x770B;&#x9ED8;&#x8BA4;&#x7684;LineDeserializer&#x4E2D;&#x5B9E;&#x73B0;&#x3002; LineDeserializer.readEvents&#x548C;LineDeserializer.readEvent&#x548C;LineDeserializer.readLine&#x7247;&#x6BB5;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Overridepublic List&lt;Event&gt; readEvents(int numEvents) throws IOException { ensureOpen(); List&lt;Event&gt; events = Lists.newLinkedList(); for (int i = 0; i &lt; numEvents; i++) { Event event = readEvent(); if (event != null) { events.add(event); } else { break; } } return events;}@Overridepublic Event readEvent() throws IOException { ensureOpen(); String line = readLine(); if (line == null) { return null; } else { return EventBuilder.withBody(line, outputCharset); }}// TODO: consider not returning a final character that is a high surrogate// when truncatingprivate String readLine() throws IOException { StringBuilder sb = new StringBuilder(); int c; int readChars = 0; while ((c = in.readChar()) != -1) { readChars++; // FIXME: support \\r\\n if (c == &apos;\\n&apos;) { break; } sb.append((char)c); if (readChars &gt;= maxLineLength) { logger.warn(&quot;Line length exceeds max ({}), truncating line!&quot;, maxLineLength); break; } } if (readChars &gt; 0) { return sb.toString(); } else { return null; }} &#x4E0A;&#x9762;&#x7684;readEvents&#x548C;readEvent&#x90FD;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#xFF0C;&#x6700;&#x7EC8;&#x662F;&#x8C03;&#x7528;&#x4E86;readLine&#x65B9;&#x6CD5;&#x3002;readline&#x65B9;&#x6CD5;&#x4E2D;&#x7684;in&#x5BF9;&#x8C61;&#x5C31;&#x662F;&#x524D;&#x9762;&#x8BF4;&#x7684;ResettableInputStream&#xFF0C;&#x5F53;in.readChar()&#x8FD4;&#x56DE;&#x7684;&#x662F;-1&#x6216;\\n&#x5C31;&#x8BA4;&#x4E3A;&#x6B64;&#x884C;&#x8BFB;&#x53D6;&#x5B8C;&#x6BD5;&#x3002;&#x53EA;&#x80FD;&#x518D;&#x770B;ResettableInputStream.readChar&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;&#x3002; ResettableInputStream.readChar&#x7247;&#x6BB5;:1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic synchronized int readChar() throws IOException { // The decoder can have issues with multi-byte characters. // This check ensures that there are at least maxCharWidth bytes in the buffer // before reaching EOF. if (buf.remaining() &lt; maxCharWidth) { buf.clear(); buf.flip(); refillBuf(); } int start = buf.position(); charBuf.clear(); boolean isEndOfInput = false; if (position &gt;= fileSize) { isEndOfInput = true; } CoderResult res = decoder.decode(buf, charBuf, isEndOfInput); // ------- 1 if (res.isMalformed() || res.isUnmappable()) { // ------- 2 res.throwException(); } int delta = buf.position() - start; charBuf.flip(); // ------- 3 if (charBuf.hasRemaining()) { // ------- 4 char c = charBuf.get(); // don&apos;t increment the persisted location if we are in between a // surrogate pair, otherwise we may never recover if we seek() to this // location! incrPosition(delta, !Character.isHighSurrogate(c)); return c; // there may be a partial character in the decoder buffer } else { incrPosition(delta, false); return -1; } } &#x770B;&#x6B64;&#x65B9;&#x6CD5;&#x7B2C;&#x4E00;&#x884C;&#x6CE8;&#x91CA;&#xFF0C;The decoder can have issues with multi-byte characters.&#xFF0C;&#x8BF4;&#x660E;&#x6B64;&#x65B9;&#x6CD5;&#x7684;&#x5F00;&#x53D1;&#x4EBA;&#x5458;&#x4E5F;&#x77E5;&#x9053;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x7684;&#x95EE;&#x9898;&#x6240;&#x5728;&#x3002;&#x5F53;&#x5B57;&#x7B26;&#x662F;&#x591A;&#x4E2A;&#x5B57;&#x7B26;&#x5BBD;&#x5EA6;&#x65F6;&#xFF0C;decoder&#x89E3;&#x6790;&#x4F1A;&#x51FA;&#x95EE;&#x9898;&#x3002;&#x524D;&#x9762;&#x8BF4;&#x7684;&#x5728;new ResettableInputStream&#x65F6;&#x4F1A;&#x6307;&#x5B9A;inputCharset&#x53C2;&#x6570;&#xFF0C;&#x6B64;&#x53C2;&#x6570;&#x5C31;&#x51B3;&#x5B9A;&#x4E86;&#x4F7F;&#x7528;&#x54EA;&#x4E00;&#x4E2A;decoder&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;UTF_8&#xFF0C;&#x6B64;&#x5904;&#x6307;&#x7684;&#x662F;UTF_8 class&#x3002; &#x5148;&#x6574;&#x4F53;&#x8BF4;&#x4E00;&#x4E0B;&#xFF0C;&#x5177;&#x4F53;&#x7684;decode&#x8FC7;&#x7A0B;&#x53EF;&#x4EE5;&#x81EA;&#x884C;&#x7814;&#x7A76;&#x3002;&#x5047;&#x5B9A;&#x6B64;&#x884C;&#x4E2D;&#x5B58;&#x5728;&#x4E0A;&#x6D77;&#x1F443;&#x4F60;&#x597D;&#xFF0C;&#x5F53;&#x8BFB;&#x5B8C;&#x6D77;&#x8BFB;&#x53D6;&#x4E0B;&#x4E00;&#x4E2A;char&#x65F6;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x4E0A;&#x9762;1&#x6240;&#x5728;&#x4F4D;&#x7F6E;&#x65F6;&#xFF0C;&#x4F1A;&#x53D1;&#x751F;overflow&#xFF0C;&#x5373;res.isOverflow&#x662F;true&#xFF0C;&#x4F46;&#x5728;2&#x7684;&#x4F4D;&#x7F6E;&#x6CA1;&#x6709;&#x5BF9;overflow&#x8FDB;&#x884C;&#x5224;&#x65AD;&#xFF0C;&#x7EE7;&#x7EED;&#x5F80;&#x4E0B;&#x8D70;&#xFF0C;&#x7ECF;&#x8FC7;3&#x5904;&#x7684;flip&#x4E4B;&#x540E;&#xFF0C;charBuf&#x53D8;&#x6210;&#x7A7A;&#xFF0C;4&#x65F6;&#x8D70;else&#x903B;&#x8F91;&#xFF0C;&#x8FD4;&#x56DE;-1&#xFF0C;&#x4E0A;&#x5C42;class&#x4F1A;&#x8BA4;&#x4E3A;&#x6B64;&#x6587;&#x4EF6;&#x5DF2;&#x7ECF;&#x8BFB;&#x53D6;&#x5B8C;&#x6BD5;&#xFF0C;&#x5BFC;&#x81F4;&#x6587;&#x4EF6;&#x540E;&#x9762;&#x6570;&#x636E;&#x4E22;&#x5931;&#xFF0C;&#x5E76;&#x4E14;&#x4E0D;&#x62A5;Exception&#x3002; &#x5176;&#x5B9E;&#x5728;flume-1.7.0&#x4E2D;&#x6B64;&#x95EE;&#x9898;&#x5C31;&#x5DF2;&#x7ECF;&#x89E3;&#x51B3;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;https://github.com/apache/flume/commit/344e0accae5675fd3d14b8414531528607865aae#diff-2abdc3f807bae84ca2b41578c4e66ca7 &#x4E3B;&#x8981;&#x6539;&#x8FDB;&#x5730;&#x65B9;&#xFF1A; &#x4FEE;&#x6539;&#x524D;&#x7684;maxCharWidth = (int)Math.ceil(charset.newEncoder().maxBytesPerChar());&#xFF0C;charset&#x4E3A;&#x201D;utf8&#x201D;&#x65F6;&#x503C;&#x4E3A;&#x201D;3&#x201D;,&#x4FEE;&#x6539;&#x540E;&#x4F1A;&#x5BF9;&#x201D;UTF-8&#x201D;,&#x201D;UTF-16&#x201D;,&#x201D;UTF-32&#x201D;&#x8FDB;&#x884C;&#x4E0D;&#x540C;&#x8BBE;&#x7F6E;&#x3002; charbuf&#x5927;&#x5C0F;&#x4E5F;&#x7531;&#x4E4B;&#x524D;single char&#x6539;&#x4E3A;two chars&#x3002; &#x4FEE;&#x6539;&#x540E;&#xFF0C;&#x4E0D;&#x4EC5;&#x5BF9;charbuf&#x5224;&#x65AD;&#xFF0C;&#x8FD8;&#x4F1A;&#x5BF9;buf&#x8FDB;&#x884C;&#x5224;&#x65AD;&#x3002;&#x5F53;charBuf.hasRemaining&#x4E3A;true&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x65AD;&#x5B9A;&#x662F;&#x4E2A;single char&#xFF0C;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;&#xFF1B;&#x5F53;&#x4E3A;false&#x65F6;&#xFF0C;&#x5224;&#x65AD;buf.hasRemaining()&#x4E3A;true&#x65F6;&#xFF0C;&#x5C06;&#x8FD9;&#x4E24;&#x4E2A;char&#x5206;&#x522B;&#x653E;&#x5728;highSurrogate&#x548C;lowSurrogate&#x4E2D;&#xFF0C;&#x6B64;&#x6B21;&#x8FD4;&#x56DE;highSurrogate&#xFF0C;&#x5E76;&#x8BBE;&#x7F6E;hasLowSurrogate&#x4E3A;true&#x3002;&#x5F53;&#x4E0B;&#x6B21;&#x8C03;&#x7528;&#x6B64;&#x65B9;&#x6CD5;&#x65F6;&#xFF0C;&#x5148;&#x5224;&#x65AD;hasLowSurrogat&#xFF0C;&#x5982;&#x679C;&#x4E3A;true&#xFF0C;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;lowSurrogate&#xFF0C;&#x5E76;&#x5C06;hasLowSurrogat&#x6062;&#x590D;&#x4E3A;false&#x3002;&#x5982;&#x6B64;&#x4E00;&#x6765;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;char&#x5168;&#x90FD;&#x8BFB;&#x53D6;&#x5B8C;&#x6BD5;&#x3002;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"flume","slug":"flume","permalink":"http://wzktravel.github.io/tags/flume/"}]},{"title":"HDFS修改备份系数和动态增删节点","slug":"hdfs-add-nodes-dynamically","date":"2016-01-19T06:59:01.000Z","updated":"2016-08-24T07:25:10.000Z","comments":true,"path":"2016/01/19/hdfs-add-nodes-dynamically/","link":"","permalink":"http://wzktravel.github.io/2016/01/19/hdfs-add-nodes-dynamically/","excerpt":"hadoop集群会经常遇到增删节点的情况，这里整理一下修改hdfs备份系数和增删datanode时的一些工作。","text":"hadoop&#x96C6;&#x7FA4;&#x4F1A;&#x7ECF;&#x5E38;&#x9047;&#x5230;&#x589E;&#x5220;&#x8282;&#x70B9;&#x7684;&#x60C5;&#x51B5;&#xFF0C;&#x8FD9;&#x91CC;&#x6574;&#x7406;&#x4E00;&#x4E0B;&#x4FEE;&#x6539;hdfs&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x548C;&#x589E;&#x5220;datanode&#x65F6;&#x7684;&#x4E00;&#x4E9B;&#x5DE5;&#x4F5C;&#x3002; &#x68C0;&#x67E5;&#x4FEE;&#x6539;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x67E5;&#x770B;&#x6587;&#x4EF6;&#x5907;&#x4EFD;&#x6570;1234[root@VLNX107011 hue]# hdfs dfs -ls /facishare-data/flume/testFound 2 itemsdrwxr-xr-x - fsdevops fsdevops 0 2015-11-18 11:09 /facishare-data/flume/test/2015-rw-r--r-- 2 fsdevops fsdevops 33 2015-11-30 17:49 /facishare-data/flume/test/nohup.out &#x7ED3;&#x679C;&#x884C;&#x4E2D;&#x7684;&#x7B2C;2&#x5217;&#x662F;&#x5907;&#x4EFD;&#x7CFB;&#x6570;(&#x6CE8;&#xFF1A;&#x6587;&#x4EF6;&#x5939;&#x4FE1;&#x606F;&#x5B58;&#x50A8;&#x5728;namenode&#x8282;&#x70B9;&#x4E0A;&#xFF0C;&#x6CA1;&#x6709;&#x5907;&#x4EFD;&#xFF0C;&#x6545;&#x6587;&#x4EF6;&#x5939;&#x7684;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x662F;&#x6A2A;&#x6760;) &#x67E5;&#x770B;&#x96C6;&#x7FA4;&#x5E73;&#x5747;&#x5907;&#x4EFD;&#x6570;&#x901A;&#x8FC7;hadoop fsck /&#x53EF;&#x4EE5;&#x65B9;&#x4FBF;&#x7684;&#x770B;&#x5230;Average block replication&#x7684;&#x503C;&#xFF0C;&#x8FD9;&#x4E2A;&#x503C;&#x4E0D;&#x4E00;&#x5B9A;&#x4F1A;&#x4E0E;Default replication factor&#x76F8;&#x7B49;&#x3002; 12345678910111213141516171819202122[root@VLNX107011 hue]# hdfs fsck /Connecting to namenode via http://VLNX107011:50070FSCK started by root (auth:SIMPLE) from /VLNX107011 for path / at Fri Dec 04 19:08:09 CST 2015................... Total size: 11837043630 B (Total open files size: 166 B) Total dirs: 3980 Total files: 3254 Total symlinks: 0 (Files currently being written: 2) Total blocks (validated): 2627 (avg. block size 4505916 B) (Total open file blocks (not validated): 2) Minimally replicated blocks: 2627 (100.0 %) Over-replicated blocks: 2253 (85.76323 %) Under-replicated blocks: 0 (0.0 %) Mis-replicated blocks: 0 (0.0 %) Default replication factor: 3 Average block replication: 2.9798248 Corrupt blocks: 0 Missing replicas: 0 (0.0 %) Number of data-nodes: 10 Number of racks: 1FSCK ended at Fri Dec 04 19:08:09 CST 2015 in 100 millisecondsThe filesystem under path &apos;/&apos; is HEALTHY &#x53EF;&#x4EE5;&#x770B;&#x5230;Average block replication, Corrupt blocks, Missing replicas&#x7B49;&#x4FE1;&#x606F;&#x3002; &#x4FEE;&#x6539;&#x5907;&#x4EFD;&#x7CFB;&#x6570;12345678[root@VLNX107011 hue]# hdfs dfs -setrep -w 3 -R /Replication 3 set: /user/oozie/share/lib/lib_20151103160704/hive/jetty-all-7.6.0.v20120127.jarReplication 3 set: /user/oozie/share/lib/lib_20151103160704/hive/jline-2.11.jar......Waiting for /backup/gitlab/1447133001_gitlab_backup.tar ........... doneWaiting for /backup/gitlab/1447133732_gitlab_backup.tar ... doneWaiting for /backup/gitlab/1447180217_gitlab_backup.tar ... done...... &#x53EF;&#x4EE5;&#x770B;&#x5230;HDFS&#x5BF9;&#x6240;&#x6709;&#x6587;&#x4EF6;&#x7684;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x8FDB;&#x884C;&#x4E86;&#x5237;&#x65B0;&#x3002; &#x518D;&#x6B21;&#x68C0;&#x67E5;&#x521A;&#x624D;&#x6587;&#x4EF6;&#x7684;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x4ECE;2&#x53D8;&#x4E3A;3&#x3002; 1234[root@VLNX107011 hue]# hdfs dfs -ls /facishare-data/flume/testFound 2 itemsdrwxr-xr-x - fsdevops fsdevops 0 2015-11-18 11:09 /facishare-data/flume/test/2015-rw-r--r-- 3 fsdevops fsdevops 33 2015-11-30 17:49 /facishare-data/flume/test/nohup.out WARNING &#x5C06;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x4ECE;&#x4F4E;&#x5230;&#x9AD8;&#x6BD4;&#x8F83;&#x5BB9;&#x6613;&#xFF0C;&#x4F46;&#x4ECE;&#x9AD8;&#x5230;&#x4F4E;&#x4F1A;&#x7279;&#x522B;&#x6162;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x96C6;&#x7FA4;&#x642D;&#x5EFA;&#x521D;&#x59CB;&#x5C31;&#x8981;&#x89C4;&#x5212;&#x597D;Default replication factor&#x3002;&#x901A;&#x5E38;&#x5907;&#x4EFD;&#x7CFB;&#x6570;&#x4E0D;&#x9700;&#x8981;&#x592A;&#x9AD8;&#xFF0C;&#x53EF;&#x4EE5;&#x662F;&#x670D;&#x52A1;&#x5668;&#x603B;&#x91CF;&#x7684;1/3&#x5DE6;&#x53F3;&#x5373;&#x53EF;&#xFF0C;Hadoop&#x9ED8;&#x8BA4;&#x7684;&#x6570;&#x503C;&#x662F;3&#x3002; &#x589E;&#x52A0;DataNode&#x6DFB;&#x52A0;&#x8FC7;&#x7A0B;&#x7565;&#x8FC7;&#x3002;&#x589E;&#x52A0;&#x5B8C;&#x673A;&#x5668;&#x540E;&#xFF0C;&#x5982;&#x679C;&#x9700;&#x8981;&#x53EF;&#x4EE5;&#x5BF9;HDFS&#x4E2D;&#x6587;&#x4EF6;&#x8FDB;&#x884C;&#x8D1F;&#x8F7D;&#x5747;&#x8861;&#x3002; 123[root@VLNX107011 hue]# hdfs balancer.....2015-12-4 19:38:46 Balancing took 18.637816666666666 minutes &#x5220;&#x9664;DataNode &#x5728;&#x914D;&#x7F6E;&#x4E2D;&#x5C06;&#x6B64;datanode&#x6DFB;&#x52A0;&#x5230;exclude&#x4E2D;&#x6CE8;&#xFF1A;cloudera&#x4E2D;&#x914D;&#x7F6E;dfs_hosts_exclude.txt &#x7684; NameNode &#x9AD8;&#x7EA7;&#x914D;&#x7F6E;&#x4EE3;&#x7801;&#x6BB5;&#xFF08;&#x5B89;&#x5168;&#x9600;&#xFF09;&#x9009;&#x9879;&#x3002;&#x975E;cloudera&#x65F6;&#xFF0C;&#x624B;&#x52A8;&#x8FDB;&#x884C;&#x914D;&#x7F6E;&#x3002; &#x4FEE;&#x6539;core-site.xml 12345678&lt;property&gt; &lt;name&gt;dfs.hosts.exclude&lt;/name&gt; &lt;value&gt;/etc/hadoop/conf/exclude&lt;/value&gt; &lt;description&gt;Names a file that contains a list of hosts that are not permitted to connect to the namenode. The full pathname of the file must be specified. If the value is empty, no hosts are excluded.&lt;/description&gt;&lt;/property&gt; &#x4FEE;&#x6539;hdfs-site.xml 12345678&lt;property&gt; &lt;name&gt;dfs.hosts.exclude&lt;/name&gt; &lt;value&gt;/etc/hadoop/conf/exclude&lt;/value&gt; &lt;description&gt;Names a file that contains a list of hosts that are not permitted to connect to the namenode. The full pathname of the file must be specified. If the value is empty, no hosts are excluded.&lt;/description&gt;&lt;/property&gt; &#x521B;&#x5EFA;/etc/hadoop/conf/exclude&#xFF0C;&#x5728;&#x6587;&#x4EF6;&#x4E2D;&#x589E;&#x52A0;&#x9700;&#x8981;&#x5220;&#x9664;&#x7684;&#x8282;&#x70B9;&#xFF0C;&#x4E00;&#x884C;&#x4E00;&#x4E2A; 12vlnx103122vlnx103123 &#x52A8;&#x6001;&#x5237;&#x65B0;&#x914D;&#x7F6E; 123[root@VLNX107011 hue]# hdfs dfsadmin -refreshNodesRefresh nodes successful for VLNX107010/172.31.107.10:8020Refresh nodes successful for VLNX107011/172.31.107.11:8020 &#x901A;&#x8FC7;web&#x9875;&#x9762;&#x67E5;&#x770B;datanode&#x60C5;&#x51B5;&#x3002;http://vlnx107010:50070/dfshealth.html#tab-datanode&#x5F00;&#x59CB;&#x5904;&#x4E8E;Decommissioning(&#x9000;&#x5F79;&#x4E2D;)&#x72B6;&#x6001;&#xFF0C;&#x6700;&#x540E;&#x5904;&#x4E8E;Dead(&#x5DF2;&#x4E0B;&#x7EBF;)&#x72B6;&#x6001;&#x3002; &#x6CE8;&#x610F;&#x5728;&#x5220;&#x9664;&#x8282;&#x70B9;&#x65F6;&#x4E00;&#x5B9A;&#x8981;&#x505C;&#x6B62;&#x6240;&#x6709;Hadoop&#x7684;Job&#xFF0C;&#x5426;&#x5219;&#x7A0B;&#x5E8F;&#x8FD8;&#x4F1A;&#x5411;&#x8981;&#x5220;&#x9664;&#x7684;&#x8282;&#x70B9;&#x540C;&#x6B65;&#x6570;&#x636E;&#xFF0C;&#x8FD9;&#x6837;&#x4E5F;&#x4F1A;&#x5BFC;&#x81F4;Decommission&#x7684;&#x8FC7;&#x7A0B;&#x4E00;&#x76F4;&#x65E0;&#x6CD5;&#x5B8C;&#x6210;&#x3002;&#x6211;&#x81EA;&#x5DF1;&#x6CA1;&#x6709;&#x8BD5;&#x8FC7;&#xFF0C;&#x4F46;&#x5E94;&#x8BE5;&#x5C06;yarn&#x7684;nodemanager&#x505C;&#x6389;&#x5C31;&#x597D;&#x3002; &#x68C0;&#x67E5;datanode&#x548C;tasktracker&#x72B6;&#x6001;&#xFF0C;&#x7406;&#x8BBA;&#x4E0A;datanode&#x5DF2;&#x7ECF;&#x505C;&#x6389;&#xFF0C;&#x7136;&#x540E;&#x624B;&#x52A8;&#x505C;&#x6389;tasktracker&#x3002; &#x589E;&#x52A0;datanode&#x78C1;&#x76D8;&#x96C6;&#x7FA4;&#x78C1;&#x76D8;&#x8FDB;&#x884C;&#x6269;&#x5BB9;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x91C7;&#x7528;&#x6DFB;&#x52A0;&#x8282;&#x70B9;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x4E5F;&#x53EF;&#x80FD;&#x4F1A;&#x91C7;&#x7528;&#x589E;&#x52A0;datanode&#x78C1;&#x76D8;&#x6302;&#x8F7D;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x5BF9;&#x4E8E;&#x7B2C;&#x4E8C;&#x79CD;&#x65B9;&#x5F0F;&#xFF0C;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x4EE5;&#x4E0B;&#x51E0;&#x70B9;&#xFF1A; &#x65B0;&#x6302;&#x8F7D;&#x7684;&#x78C1;&#x76D8;&#x9700;&#x8981;&#x6709;&#x8BFB;&#x5199;&#x6743;&#x9650; &#x4FEE;&#x6539;datanode&#x6570;&#x636E;&#x526F;&#x672C;&#x5B58;&#x653E;&#x78C1;&#x76D8;&#x9009;&#x62E9;&#x7B56;&#x7565; &#x914D;&#x7F6E;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x9700;&#x8981;&#x91CD;&#x542F;&#x96C6;&#x7FA4;&#x3002; datanode&#x6570;&#x636E;&#x526F;&#x672C;&#x5B58;&#x653E;&#x78C1;&#x76D8;&#x9009;&#x62E9;&#x7B56;&#x7565;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;:&#x7B2C;&#x4E00;&#x79CD;&#x662F;&#x6CBF;&#x7528;hadoop1.0&#x7684;&#x78C1;&#x76D8;&#x76EE;&#x5F55;&#x8F6E;&#x8BE2;&#x65B9;&#x5F0F;&#xFF0C;&#x5B9E;&#x73B0;&#x7C7B;&#xFF1A;RoundRobinVolumeChoosingPolicy.java&#x7B2C;&#x4E8C;&#x79CD;&#x662F;&#x9009;&#x62E9;&#x53EF;&#x7528;&#x7A7A;&#x95F4;&#x8DB3;&#x591F;&#x591A;&#x7684;&#x78C1;&#x76D8;&#x65B9;&#x5F0F;&#x5B58;&#x50A8;&#xFF0C;&#x5B9E;&#x73B0;&#x7C7B;&#xFF1A;AvailableSpaceVolumeChoosingPolicy.java &#x5177;&#x4F53;&#x914D;&#x7F6E;&#x5728;hdfs-site.xml&#x4E2D;&#xFF1A; 12345&lt;property&gt; &lt;name&gt;dfs.datanode.fsdataset.volume.choosing.policy&lt;/name&gt; &lt;!-- &lt;value&gt;org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy&lt;/value&gt; --&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy&lt;/value&gt;&lt;/property&gt; &#x5982;&#x679C;&#x4E0D;&#x914D;&#x7F6E;&#xFF0C;&#x9ED8;&#x8BA4;&#x4F7F;&#x7528;&#x7B2C;&#x4E00;&#x79CD;&#x65B9;&#x5F0F;&#xFF0C;&#x65E2;&#x8F6E;&#x8BE2;&#x9009;&#x62E9;&#x78C1;&#x76D8;&#x6765;&#x5B58;&#x50A8;&#x6570;&#x636E;&#x526F;&#x672C;&#xFF0C;&#x4F46;&#x662F;&#x8F6E;&#x8BE2;&#x7684;&#x65B9;&#x5F0F;&#x867D;&#x7136;&#x80FD;&#x591F;&#x4FDD;&#x8BC1;&#x6240;&#x6709;&#x78C1;&#x76D8;&#x90FD;&#x80FD;&#x591F;&#x88AB;&#x4F7F;&#x7528;&#xFF0C;&#x4F46;&#x662F;&#x7ECF;&#x5E38;&#x4F1A;&#x51FA;&#x73B0;&#x5404;&#x4E2A;&#x78C1;&#x76D8;&#x76F4;&#x63A5;&#x6570;&#x636E;&#x5B58;&#x50A8;&#x4E0D;&#x5747;&#x8861;&#x95EE;&#x9898;&#xFF0C;&#x6709;&#x7684;&#x78C1;&#x76D8;&#x5B58;&#x50A8;&#x5F97;&#x5F88;&#x6EE1;&#x4E86;&#xFF0C;&#x800C;&#x6709;&#x7684;&#x78C1;&#x76D8;&#x53EF;&#x80FD;&#x8FD8;&#x6709;&#x5F88;&#x591A;&#x5B58;&#x50A8;&#x7A7A;&#x95F4;&#x6CA1;&#x6709;&#x5F97;&#x5230;&#x5229;&#x7528;&#xFF0C;&#x6240;&#x6709;&#x5728;hadoop2.0&#x96C6;&#x7FA4;&#x4E2D;&#xFF0C;&#x6700;&#x597D;&#x5C06;&#x78C1;&#x76D8;&#x9009;&#x62E9;&#x7B56;&#x7565;&#x914D;&#x7F6E;&#x6210;&#x7B2C;&#x4E8C;&#x79CD;&#xFF0C;&#x6839;&#x636E;&#x78C1;&#x76D8;&#x7A7A;&#x95F4;&#x5269;&#x4F59;&#x91CF;&#x6765;&#x9009;&#x62E9;&#x78C1;&#x76D8;&#x5B58;&#x50A8;&#x6570;&#x636E;&#x526F;&#x672C;&#xFF0C;&#x8FD9;&#x6837;&#x4E00;&#x6837;&#x80FD;&#x4FDD;&#x8BC1;&#x6240;&#x6709;&#x78C1;&#x76D8;&#x90FD;&#x80FD;&#x5F97;&#x5230;&#x5229;&#x7528;&#xFF0C;&#x8FD8;&#x80FD;&#x4FDD;&#x8BC1;&#x6240;&#x6709;&#x78C1;&#x76D8;&#x90FD;&#x88AB;&#x5229;&#x7528;&#x5747;&#x8861;&#x3002; &#x4F7F;&#x7528;&#x7B2C;&#x4E8C;&#x79CD;&#x65B9;&#x5F0F;&#x65F6;&#xFF0C;&#x540C;&#x65F6;&#x9700;&#x8981;&#x914D;&#x7F6E;&#x53E6;&#x5916;&#x4E24;&#x4E2A;&#x53C2;&#x6570;: dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold, &#x9ED8;&#x8BA4;&#x503C;&#x662F;10737418240&#xFF0C;&#x65E2;10G&#xFF0C;&#x4E00;&#x822C;&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x503C;&#x5C31;&#x884C;&#x3002;&#x9996;&#x5148;&#x8BA1;&#x7B97;&#x51FA;&#x4E24;&#x4E2A;&#x503C;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x6240;&#x6709;&#x78C1;&#x76D8;&#x4E2D;&#x6700;&#x5927;&#x53EF;&#x7528;&#x7A7A;&#x95F4;&#xFF0C;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x503C;&#x662F;&#x6240;&#x6709;&#x78C1;&#x76D8;&#x4E2D;&#x6700;&#x5C0F;&#x53EF;&#x7528;&#x7A7A;&#x95F4;&#xFF0C;&#x5982;&#x679C;&#x8FD9;&#x4E24;&#x4E2A;&#x503C;&#x76F8;&#x5DEE;&#x5C0F;&#x4E8E;&#x8BE5;&#x914D;&#x7F6E;&#x9879;&#x6307;&#x5B9A;&#x7684;&#x9600;&#x503C;&#x65F6;&#xFF0C;&#x5219;&#x5C31;&#x7528;&#x8F6E;&#x8BE2;&#x65B9;&#x5F0F;&#x7684;&#x78C1;&#x76D8;&#x9009;&#x62E9;&#x7B56;&#x7565;&#x9009;&#x62E9;&#x78C1;&#x76D8;&#x5B58;&#x50A8;&#x6570;&#x636E;&#x526F;&#x672C;&#x3002; dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction, &#x9ED8;&#x8BA4;&#x503C;&#x662F;0.75f&#xFF0C;&#x4E00;&#x822C;&#x4F7F;&#x7528;&#x9ED8;&#x8BA4;&#x503C;&#x5C31;&#x884C;&#x3002;&#x6709;&#x591A;&#x5C11;&#x6BD4;&#x4F8B;&#x7684;&#x6570;&#x636E;&#x526F;&#x672C;&#x5E94;&#x8BE5;&#x5B58;&#x50A8;&#x5230;&#x5269;&#x4F59;&#x7A7A;&#x95F4;&#x8DB3;&#x591F;&#x591A;&#x7684;&#x78C1;&#x76D8;&#x4E0A;&#x3002;&#x8BE5;&#x914D;&#x7F6E;&#x9879;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x662F;0.0-1.0&#xFF0C;&#x4E00;&#x822C;&#x53D6;0.5-1.0&#xFF0C;&#x5982;&#x679C;&#x914D;&#x7F6E;&#x592A;&#x5C0F;&#xFF0C;&#x4F1A;&#x5BFC;&#x81F4;&#x5269;&#x4F59;&#x7A7A;&#x95F4;&#x8DB3;&#x591F;&#x7684;&#x78C1;&#x76D8;&#x5B9E;&#x9645;&#x4E0A;&#x6CA1;&#x5206;&#x914D;&#x8DB3;&#x591F;&#x7684;&#x6570;&#x636E;&#x526F;&#x672C;&#xFF0C;&#x800C;&#x5269;&#x4F59;&#x7A7A;&#x95F4;&#x4E0D;&#x8DB3;&#x7684;&#x78C1;&#x76D8;&#x53D6;&#x9700;&#x8981;&#x5B58;&#x50A8;&#x66F4;&#x591A;&#x7684;&#x6570;&#x636E;&#x526F;&#x672C;&#xFF0C;&#x5BFC;&#x81F4;&#x78C1;&#x76D8;&#x6570;&#x636E;&#x5B58;&#x50A8;&#x4E0D;&#x5747;&#x8861;&#x3002;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"hdfs","slug":"hdfs","permalink":"http://wzktravel.github.io/tags/hdfs/"}]},{"title":"Cloudera启用kerberos","slug":"Enabling-Kerberos-In-CDH","date":"2016-01-19T03:11:47.000Z","updated":"2016-08-24T07:25:12.000Z","comments":true,"path":"2016/01/19/Enabling-Kerberos-In-CDH/","link":"","permalink":"http://wzktravel.github.io/2016/01/19/Enabling-Kerberos-In-CDH/","excerpt":"CDH中想使用sentry进行安全管理，但需要首先集成kerberos，下面介绍CDH启用kerberos的步骤以及遇到的问题。基本按照Cloudera官网: Enabling Kerberos Authentication Using the Wizard进行操作。 如果需要禁用kerberos，参考CDH禁用kerberos WARNING!!! 操作需谨慎，坑很多，最好先在测试环境预演。","text":"CDH&#x4E2D;&#x60F3;&#x4F7F;&#x7528;sentry&#x8FDB;&#x884C;&#x5B89;&#x5168;&#x7BA1;&#x7406;&#xFF0C;&#x4F46;&#x9700;&#x8981;&#x9996;&#x5148;&#x96C6;&#x6210;kerberos&#xFF0C;&#x4E0B;&#x9762;&#x4ECB;&#x7ECD;CDH&#x542F;&#x7528;kerberos&#x7684;&#x6B65;&#x9AA4;&#x4EE5;&#x53CA;&#x9047;&#x5230;&#x7684;&#x95EE;&#x9898;&#x3002;&#x57FA;&#x672C;&#x6309;&#x7167;Cloudera&#x5B98;&#x7F51;: Enabling Kerberos Authentication Using the Wizard&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x3002; &#x5982;&#x679C;&#x9700;&#x8981;&#x7981;&#x7528;kerberos&#xFF0C;&#x53C2;&#x8003;CDH&#x7981;&#x7528;kerberos WARNING!!! &#x64CD;&#x4F5C;&#x9700;&#x8C28;&#x614E;&#xFF0C;&#x5751;&#x5F88;&#x591A;&#xFF0C;&#x6700;&#x597D;&#x5148;&#x5728;&#x6D4B;&#x8BD5;&#x73AF;&#x5883;&#x9884;&#x6F14;&#x3002; &#x6574;&#x4F53;&#x6D41;&#x7A0B;&#x6982;&#x8FF0;&#x603B;&#x7ED3;&#x4E00;&#x4E0B;&#x6574;&#x4E2A;&#x6D41;&#x7A0B;&#x4E0B;&#x6765;&#x9700;&#x8981;&#x505A;&#x7684;&#x4E8B;&#x60C5;&#xFF1A; &#x642D;&#x5EFA;MIT kerberos&#xFF0C;&#x6CE8;&#x610F;&#x4FDD;&#x5B58;cloudera-scm/admin&#x5BC6;&#x7801;&#x3002; &#x96C6;&#x7FA4;&#x542F;&#x7528;kerberos &#x5220;&#x9664;&#x6240;&#x6709;node manager&#x4E0A;yarn cache&#xFF0C;/yarn/nm/usercache/ &#x5BA2;&#x6237;&#x7AEF;&#x914D;&#x7F6E; &#x5468;&#x8FB9;&#x670D;&#x52A1;&#x914D;&#x7F6E;: opentsdb&#x5347;&#x7EA7;&#x5230;2.2&#xFF0C;&#x52A0;&#x5165;jaas, flume&#x914D;&#x7F6E;&#x5347;&#x7EA7; &#x9A8C;&#x8BC1;MapReduce, spark, hive, impala, sqoop, oozie, shell&#x811A;&#x672C;&#x7684;&#x6B63;&#x786E;&#x6027; &#x542F;&#x7528;&#x548C;&#x7981;&#x7528;kerberos&#x8FC7;&#x7A0B;&#x4E2D;&#x7684;&#x95EE;&#x9898; &#x5982;&#x679C;&#x6709;&#x8DE8;&#x96C6;&#x7FA4;&#x64CD;&#x4F5C;&#xFF0C;&#x6700;&#x597D;&#x4E0D;&#x8981;&#x542F;&#x7528;kerberos&#xFF0C;distcp&#x547D;&#x4EE4;&#x65F6;&#x4F1A;&#x62A5;&#x9519;&#x3002;&#x53C2;&#x8003;https://issues.apache.org/jira/browse/HDFS-7037 &#x96C6;&#x7FA4;&#x9700;&#x8981;&#x505C;&#x673A;&#x4E00;&#x6BB5;&#x65F6;&#x95F4; &#x7981;&#x7528;kerberos&#x540E;&#x6062;&#x590D;hbase&#x9700;&#x8981;&#x4E00;&#x6BB5;&#x65F6;&#x95F4; HA&#x4E0B;yarn&#x4E24;&#x4E2A;resource manager&#x90FD;&#x5904;&#x4E8E;standby&#x72B6;&#x6001;&#xFF0C;&#x53EA;&#x80FD;&#x7981;&#x7528;HA MIT kerberos&#x642D;&#x5EFA;&#x516C;&#x53F8;&#x5185;&#x90E8;&#x4F7F;&#x7528;&#x7684;&#x662F;Microsoft Active Directory&#xFF0C;&#x4F46;&#x7531;&#x4E8E;&#x4E0D;&#x7ED9;&#x521B;&#x5EFA;&#x7528;&#x6237;&#x6743;&#x9650;&#xFF0C;&#x800C;&#x4E14;&#x7528;&#x6237;&#x540D;&#x5FC5;&#x987B;&#x7B26;&#x5408;&#x4E00;&#x5B9A;&#x683C;&#x5F0F;&#xFF0C;&#x4FEE;&#x6539;&#x73B0;&#x5B58;&#x96C6;&#x7FA4;&#x7684;&#x8D26;&#x53F7;&#x592A;&#x8FC7;&#x9EBB;&#x70E6;&#xFF0C;&#x6240;&#x4EE5;&#x81EA;&#x5DF1;&#x642D;&#x5EFA;&#x4E86;MIT kerberos&#x3002;&#x53C2;&#x8003;http://blog.javachen.com/2014/11/04/config-kerberos-in-cdh-hdfs &#x5728;&#x8FD9;&#x7EAA;&#x5F55;&#x4E00;&#x4E0B;&#x7528;&#x5230;&#x7684;&#x4E00;&#x4E9B;&#x547D;&#x4EE4;&#xFF0C;&#x5177;&#x4F53;&#x914D;&#x7F6E;&#x548C;&#x6B65;&#x9AA4;&#x53C2;&#x8003;&#x4E0A;&#x6587;&#x3002;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# &#x5B89;&#x88C5;kerberos serveryum install krb5-server -yyum install krb5-libs krb5-workstation -y# &#x505C;&#x6B62;&#x670D;&#x52A1;service krb5kdc stopservice kadmin stop# &#x5220;&#x9664;&#x6570;&#x636E;&#x5E93;&#x6587;&#x4EF6;&#x548C;&#x4E00;&#x4E9B;&#x914D;&#x7F6E;rm -f /var/kerberos/krb5kdc/principal*rm -f /var/kerberos/krb5kdc/.k5.*rm -f /etc/krb5.keytab# &#x4FEE;&#x6539;&#x914D;&#x7F6E;## &#x6CE8;&#x610F;&#x6700;&#x540E;&#x7684;*&#x4E4B;&#x95F4;&#x6709;&#x4E00;&#x4E2A;&#x7A7A;&#x683C;vim /var/kerberos/krb5kdc/kadm5.aclvim /var/kerberos/krb5kdc/kdc.conf# &#x6B64;&#x914D;&#x7F6E;&#x9700;&#x8981;&#x540C;&#x6B65;&#x5230;&#x5176;&#x4ED6;&#x673A;&#x5668;&#x4E0A;&#xFF0C;&#x5982;&#x679C;&#x4F7F;&#x7528;cloudera&#xFF0C;&#x53EF;&#x4EE5;&#x8BA9;cloudera&#x63A5;&#x7BA1;vim /etc/krb5.conf# &#x521B;&#x5EFA;&#x6570;&#x636E;&#x5E93;kdb5_util create -r HADOOP.COM -s# &#x542F;&#x52A8;&#x670D;&#x52A1;service krb5kdc startservice kadmin start# &#x6DFB;&#x52A0;root&#x7528;&#x6237;echo -e &quot;root\\nroot&quot; | kadmin.local -q &quot;addprinc root/admin&quot;# &#x62BD;&#x53D6;&#x5BC6;&#x94A5;&#x5E76;&#x5C06;&#x5176;&#x50A8;&#x5B58;&#x5728;&#x672C;&#x5730; keytab &#x6587;&#x4EF6; /etc/krb5.keytab &#x4E2D;&#x3002;&#x8FD9;&#x4E2A;&#x6587;&#x4EF6;&#x7531;&#x8D85;&#x7EA7;&#x7528;&#x6237;&#x62E5;&#x6709;&#xFF0C;&#x6240;&#x4EE5;&#x60A8;&#x5FC5;&#x987B;&#x662F; root &#x7528;&#x6237;&#x624D;&#x80FD;&#x5728; kadmin shell &#x4E2D;&#x6267;&#x884C;&#x4EE5;&#x4E0B;&#x547D;&#x4EE4;kadmin.local -q &quot;ktadd kadmin/admin&quot;klist -k /etc/krb5.keytab# &#x751F;&#x6210;cloudera&#x4E2D;&#x4F7F;&#x7528;&#x7684;admin&#x8D26;&#x53F7;kadmin.local -q &quot;addprinc -pw cloudera cloudera-scm/admin@HADOOP.COM&quot;# &#x751F;&#x6210;&#x7528;&#x6237;&#x8D26;&#x53F7;keytabkadmin.local -q &quot;xst -k ${USERNAME}.keytab ${USERNAME}@HADOOP.COM&quot;# &#x5408;&#x5E76;keytab$ ktutilktutil: rkt hdfs-unmerged.keytabktutil: rkt HTTP.keytabktutil: wkt hdfs.keytabktutil: exit# &#x4F7F;&#x7528;keytab&#x5207;&#x6362;&#x7528;&#x6237;kinit -k -t hdfs.keytab hdfs@HADOOP.COM kinit -k -t hdfs.keytab hdfs# &#x5220;&#x9664;principal&#xFF0C;&#x4E0D;&#x4EA4;&#x4E92;&#x7684;&#x8BDD;&#x53EF;&#x4EE5;&#x52A0;&apos;-force&apos;&#x53C2;&#x6570;kadmin.local -q &quot;delprinc $princ&quot; What&#x2019;s a keytab file? What&#x2019;s a keytab file? It&#x2019;s basically a file that contains a table of user accounts, with an encrypted hash of the user&#x2019;s password. Why have a keytab file? Well, when you want a server process to automatically logon to Active Directory on startup, you have two options: type the password (in clear text) into a config file somewhere, or store an encrypted hash of the password in a keytab file. CDH&#x542F;&#x7528;kerberos&#x53C2;&#x8003;Cloudera&#x5B98;&#x7F51;: Enabling Kerberos Authentication Using the Wizard &#x524D;&#x671F;&#x51C6;&#x5907;CDH Manager Server&#x4E0A;&#x5B89;&#x88C5;openldap-clients1sudo yum install openldap-clients &#x96C6;&#x7FA4;&#x6240;&#x6709;&#x673A;&#x5668;&#x4E0A;&#x5B89;&#x88C5;krb5-workstation, krb5-libscloudera manager server&#x53EF;&#x4EE5;ssh&#x65E0;&#x5BC6;&#x7801;&#x767B;&#x9646;&#x5230;&#x5176;&#x4ED6;&#x673A;&#x5668;&#x4E0A;123for `cat /etc/hosts | fgrep 172 | awk &apos;{print $1}&apos;`; do sudo yum install krb5-workstation krb5-libs -y done &#x751F;&#x6210;cloudera&#x4E2D;&#x4F7F;&#x7528;&#x7684;admin&#x8D26;&#x53F7;&#x5BC6;&#x7801;&#x8981;&#x8BB0;&#x7262;&#xFF0C;&#x6B64;&#x8D26;&#x53F7;&#x9700;&#x8981;&#x6709;&#x6743;&#x9650;&#x521B;&#x5EFA;&#x5176;&#x4ED6;&#x8D26;&#x53F7; Specifically, the Cloudera Manager Server must have a Kerberos principal that has privileges to create other accounts. 1kadmin.local -q &quot;addprinc -pw &lt;Password&gt; cloudera-scm/admin@YOUR-LOCAL-REALM.COM&quot; CDH&#x542F;&#x7528;kerberos&#x5728;CDH&#x7BA1;&#x7406;&#x9875;&#x9762;&#xFF0C;&#x96C6;&#x7FA4;&#x540D;&#x79F0;&#x53F3;&#x4FA7;&#x7684;&#x5C0F;&#x4E09;&#x89D2;&#x4E0B;&#x62C9;&#x83DC;&#x5355;&#x4E2D;&#xFF0C;&#x9009;&#x62E9;&#x300C;&#x542F;&#x7528;Kerberos&#x300D;&#xFF0C;&#x7136;&#x540E;&#x6309;Enabling Kerberos Using the Wizard&#x4E00;&#x6B65;&#x6B65;&#x64CD;&#x4F5C;&#x5373;&#x53EF;&#x3002; &#x9488;&#x5BF9;yarn&#x914D;&#x7F6E;&#xFF0C;&#x9700;&#x8981;&#x505A;&#x4E0B;&#x9762;&#x7684;&#x4FEE;&#x6539;&#xFF1A;&#x914D;&#x7F6E;&#x6587;&#x4EF6;container-executor.cfg min.user.id: &#x5141;&#x8BB8;&#x7684;&#x6700;&#x5C0F; Linux &#x7528;&#x6237; ID, &#x7528;&#x4E8E;&#x963B;&#x6B62;&#x5176;&#x4ED6;&#x8D85;&#x7EA7;&#x7528;&#x6237;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;1000&#x3002; allowed.system.users: &#x660E;&#x786E;&#x5217;&#x5165;&#x767D;&#x540D;&#x5355;&#x4EE5;&#x5141;&#x8BB8;&#x8FD0;&#x884C;&#x5BB9;&#x5668;&#x7684;&#x7528;&#x6237;&#x5217;&#x8868;&#x3002;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x8BE5;&#x8BBE;&#x7F6E;&#x5C06; ID &#x4F4E;&#x4E8E;&#x201C;&#x6700;&#x5C0F;&#x7528;&#x6237; ID&#x201D;&#x8BBE;&#x7F6E;&#x7684;&#x7528;&#x6237;&#x5217;&#x5165;&#x767D;&#x540D;&#x5355;&#x3002; banned.users: &#x7981;&#x6B62;&#x8FD0;&#x884C;&#x5BB9;&#x5668;&#x7684;&#x7528;&#x6237;&#x5217;&#x8868;&#x3002; &#x683C;&#x5F0F;&#x5316;resourcemanager state store Important:If you have enabled YARN Resource Manager HA in your non-secure cluster, you should clear the StateStore znode in ZooKeeper before enabling Kerberos. To do this: Go to the Cloudera Manager Admin Console home page, click to the right of the YARN service and select Stop. When you see a Finished status, the service has stopped. Go to the YARN service and select Actions &gt; Format State Store. When the command completes, click Close. &#x5BA2;&#x6237;&#x7AEF;&#x914D;&#x7F6E;&#x521B;&#x5EFA;hdfs&#x8D85;&#x7EA7;&#x7528;&#x6237;1kadmin.local -q &quot;addprinc hdfs@HADOOP.COM&quot; &#x5BC6;&#x7801;&#x5F3A;&#x5EA6;&#x5927;&#x4E00;&#x70B9;&#xFF0C;&#x6B64;&#x7528;&#x6237;&#x62E5;&#x6709;hdfs&#x4E0A;&#x6240;&#x6709;&#x6743;&#x9650;&#x3002; 1kinit hdfs@HADOOP.COM &#x5207;&#x6362;&#x5230;&#x6B64;&#x7528;&#x6237;&#x3002; &#x6307;&#x5B9A;hdfs&#x8D85;&#x7EA7;&#x7528;&#x6237;&#x7EC4; To designate a group of superusers instead of using the default hdfs account, follow these steps: Navigate to the HDFS Service &gt; Configuration tab. In the Search field, type Superuser to display the Superuser Group property. Change the value from the default supergroup to the appropriate group name for your environment. Click Save Changes.For this change to take effect, you must restart the cluster. &#x4E3A;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x521B;&#x5EFA;principal1kadmin.local -q &quot;addprinc user@HADOOP.COM&quot; Prepare the Cluster for Each User Each account must have a user ID that is greater than or equal to 1000. In the /etc/hadoop/conf/taskcontroller.cfg file, the default setting for the banned.users property is mapred, hdfs, and bin to prevent jobs from being submitted via those user accounts. The default setting for the min.user.id property is 1000 to prevent jobs from being submitted with a user ID less than 1000, which are conventionally Unix super users. &#x5468;&#x8FB9;&#x670D;&#x52A1;opentsdb&#x8FDE;&#x63A5;&#x96C6;&#x6210;&#x4E86;kerberos&#x7684;hbase&#x4E0B;&#x8F7D;&#x4F7F;&#x7528;&#x6700;&#x65B0;&#x7684;opentsdb 2.2&#x7248;&#x672C;&#xFF0C;&#x6B64;&#x524D;&#x7248;&#x672C;&#x4E2D;&#x96C6;&#x6210;&#x7684;AsyncHBase&#x65E0;kerberos&#x9A8C;&#x8BC1;&#x529F;&#x80FD;&#x3002; &#x5728;/etc/opentsdb/opentsdb.conf&#x4E2D;&#x6DFB;&#x52A0;&#x5982;&#x4E0B;&#x914D;&#x7F6E;: 1234hbase.security.auth.enable=truehbase.security.authentication=kerberoshbase.kerberos.regionserver.principal=hbase/_HOST@HADOOP.COMhbase.sasl.clientconfig=Client &#x65B0;&#x5EFA;/etc/opentsdb/jaas.conf&#xFF0C;&#x5185;&#x5BB9;&#x5982;&#x4E0B;: 12345Client { com.sun.security.auth.module.Krb5LoginModule required useKeyTab=false useTicketCache=true;}; &#x5728;opentsdb&#x542F;&#x52A8;&#x9879;&#x4E2D;&#x6DFB;&#x52A0;-Djava.security.auth.login.config=/etc/opentsdb/jaas.conf&#x3002; &#x8FD0;&#x884C;kinit&#x547D;&#x4EE4;&#xFF1A;kinit -k -t hbase.keytab hbase &#x91CD;&#x542F;opentsdb &#x5982;&#x679C;&#x4F7F;&#x7528;keytab&#x65B9;&#x5F0F;&#x4F1A;&#x62A5;&#x65E0;&#x6CD5;&#x8FDE;&#x63A5;hbase&#x7684;&#x9519;&#x8BEF;&#xFF0C;&#x6240;&#x4EE5;&#x4F7F;&#x7528;useTicketCache&#xFF0C;&#x5E76;&#x624B;&#x52A8;kinit&#x3002; KerberosClientAuthProvider: Could not login: the client is being asked for a password, but the client code does not currently support obtaining a password from the user. Make sure that the client is configured to use a ticket cache (using the JAAS configuration setting &#x2018;useTicketCache=true)&#x2019; and restart the client. If you still get this message after that, the TGT in the ticket cache has expired and must be manually refreshed. To do so, first determine if you are using a password or a keytab. If the former, run kinit in a Unix shell in the environment of the user who is running this asynchbase client using the command &#x2018;kinit &#x2018; (where is the name of the client&#x2019;s Kerberos principal). If the latter, do &#x2018;kinit -k -t &#x2018; (where is the name of the Kerberos principal, and is the location of the keytab file). After manually refreshing your cache, restart this client. If you continue to see this message after manually refreshing your cache, ensure that your KDC host&#x2019;s clock is in sync with this host&#x2019;s clock. flume&#x8FDE;&#x63A5;&#x96C6;&#x6210;&#x4E86;kerberos&#x7684;hdfs&#x5C06;hdfs.keytab&#x590D;&#x5236;&#x5230;flume conf&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x5E76;&#x5728;flume.hdfs.conf&#x4E2D;&#x914D;&#x7F6E;hdfs-sink&#xFF0C;&#x6DFB;&#x52A0;12a1.sinks.hdfs-sink.hdfs.kerberosPrincipal = hdfs@HADOOP.COMa1.sinks.hdfs-sink.hdfs.kerberosKeytab = ./conf/hdfs.keytab &#x6CE8;&#x610F;keytab&#x4F4D;&#x7F6E;&#x3002; &#x5F02;&#x5E38;&#x4FE1;&#x606F;&#x548C;&#x89E3;&#x51B3;&#x65B9;&#x6CD5;1. kinit: Cannot find KDC for requested realm while getting initial credentialskrb5.conf&#x914D;&#x7F6E;&#x4E0D;&#x6B63;&#x786E;&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;cloudera&#x63A5;&#x7BA1;krb5.conf 2. kinit: KDC reply did not match expectations while getting initial credentialskerberos&#x914D;&#x7F6E;&#x65F6;&#x57DF;&#x540D;&#x8981;&#x5927;&#x5199; 3. &#x673A;&#x5668;hostname&#x5F15;&#x8D77;&#x7684;&#x6700;&#x5927;&#x7684;&#x5751;&#xFF01;&#x75C7;&#x72B6;: &#x96C6;&#x7FA4;&#x4E2D;hdfs&#x7B49;&#x670D;&#x52A1;&#x65E0;&#x6CD5;&#x542F;&#x52A8;,&#x62A5;&#x9519; 12345678910111213141516171819202122232425262728293031323334353637java.io.IOException: Login failure for hdfs/vlnx107010@HADOOP.COM from keytab hdfs.keytab: javax.security.auth.login.LoginException: Client not found in Kerberos database (6) - CLIENT_NOT_FOUND at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:976) at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:243) at org.apache.hadoop.hdfs.server.namenode.NameNode.loginAsNameNodeUser(NameNode.java:613) at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:632) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:810) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:794) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1487) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1555)Caused by: javax.security.auth.login.LoginException: Client not found in Kerberos database (6) - CLIENT_NOT_FOUND at com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:804) at com.sun.security.auth.module.Krb5LoginModule.login(Krb5LoginModule.java:617) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at javax.security.auth.login.LoginContext.invoke(LoginContext.java:755) at javax.security.auth.login.LoginContext.access$000(LoginContext.java:195) at javax.security.auth.login.LoginContext$4.run(LoginContext.java:682) at javax.security.auth.login.LoginContext$4.run(LoginContext.java:680) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:680) at javax.security.auth.login.LoginContext.login(LoginContext.java:587) at org.apache.hadoop.security.UserGroupInformation.loginUserFromKeytab(UserGroupInformation.java:967) ... 7 moreCaused by: KrbException: Client not found in Kerberos database (6) - CLIENT_NOT_FOUND at sun.security.krb5.KrbAsRep.&lt;init&gt;(KrbAsRep.java:82) at sun.security.krb5.KrbAsReqBuilder.send(KrbAsReqBuilder.java:316) at sun.security.krb5.KrbAsReqBuilder.action(KrbAsReqBuilder.java:361) at com.sun.security.auth.module.Krb5LoginModule.attemptAuthentication(Krb5LoginModule.java:776) ... 20 moreCaused by: KrbException: Identifier doesn&apos;t match expected value (906) at sun.security.krb5.internal.KDCRep.init(KDCRep.java:140) at sun.security.krb5.internal.ASRep.init(ASRep.java:64) at sun.security.krb5.internal.ASRep.&lt;init&gt;(ASRep.java:59) at sun.security.krb5.KrbAsRep.&lt;init&gt;(KrbAsRep.java:60) ... 23 more 123456789101112klist -k hdfs.keytabKeytab name: FILE:hdfs.keytabKVNO Principal---- -------------------------------------------------------------------------- 2 HTTP/VLNX107010@HADOOP.COM 2 HTTP/VLNX107010@HADOOP.COM 2 HTTP/VLNX107010@HADOOP.COM 2 HTTP/VLNX107010@HADOOP.COM 2 hdfs/VLNX107010@HADOOP.COM 2 hdfs/VLNX107010@HADOOP.COM 2 hdfs/VLNX107010@HADOOP.COM 2 hdfs/VLNX107010@HADOOP.COM &#x6CE8;&#x610F;hdfs&#x65E5;&#x5FD7;&#x4E2D;principal&#x4E3A;hdfs/vlnx107010@HADOOP.COM&#xFF0C;&#x4F46;&#x5728;&#x751F;&#x6210;&#x7684;hdfs.keytab&#x4E2D;&#x4E3A;hdfs/VLNX107010@HADOOP.COM&#xFF0C;&#x533A;&#x522B;&#x5C31;&#x662F;&#x57DF;&#x540D;&#x7684;&#x5927;&#x5C0F;&#x5199;&#xFF0C;&#x5728;kerberos&#x4E2D;&#x662F;&#x533A;&#x5206;&#x5927;&#x5C0F;&#x5199;&#x7684;&#xFF0C;&#x6240;&#x4EE5;&#x8BA4;&#x8BC1;&#x5931;&#x8D25;&#x3002; &#x6B64;&#x96C6;&#x7FA4;&#x7684;hostname&#x548C;/etc/hosts&#x4E2D;&#x90FD;&#x662F;&#x5927;&#x5199;&#x7684;&#xFF0C;&#x6240;&#x4EE5;&#x7B2C;&#x4E00;&#x60F3;&#x6CD5;&#x662F;&#x60F3;&#x529E;&#x6CD5;&#x5C06;hdfs&#x7684;principal&#x6539;&#x4E3A;&#x5C0F;&#x5199;&#x7684;&#xFF0C;&#x7ECF;&#x8FC7;&#x5404;&#x79CD;&#x5C1D;&#x8BD5;&#x548C;&#x67E5;&#x9605;&#x8D44;&#x6599;&#x540E;&#xFF0C;&#x53D1;&#x73B0;&#x4E0D;&#x53EF;&#x884C;&#xFF0C;&#x53C2;&#x8003;https://community.cloudera.com/t5/Cloudera-Manager-Installation/javax-security-auth-login-LoginException-Client-not-found-in/td-p/30475 Hadoop in general expects that your hostnames and domain names are all lowercase. When Kerberos is introduced, this becomes important. While it is possible to override this behavior (of expecting lowercase) by doing manual configuration, I recommend ensuring via /etc/hosts or DNS that your host and domain are lower case. After that is corrected, regenerate credentials and that should correct the problem. &#x8FDB;&#x884C;&#x4E86;&#x66F4;&#x4E3A;&#x82E6;&#x903C;&#x7684;&#x4E09;&#x6B65;&#xFF1A;1&#x3002;&#x4FEE;&#x6539;&#x96C6;&#x7FA4;&#x7684;hostname&#x548C;/etc/hosts&#x4E86;&#xFF0C;&#x4FEE;&#x6539;&#x4E00;&#x53F0;&#x673A;&#x5668;&#x7684;/etc/hosts&#x540E;&#xFF0C;&#x6279;&#x91CF;&#x5904;&#x7406;1234for HOST in `cat /etc/hosts | fgrep 172 | awk &apos;{print $2}&apos;`; do scp /etc/hosts ${HOST}:/etc/hosts ssh ${HOST} &quot;hostname ${HOST} &amp;&amp; sed -i &apos;s/VLNX/vlnx/g&apos; /etc/sysconfig/network&quot;done &#x5728;cloudera&#x4E2D;&#x6309;&#x7167;&#x4E0A;&#x9762;&#x6B65;&#x9AA4;disable kerberos&#xFF0C;&#x7136;&#x540E;&#x91CD;&#x65B0;&#x914D;&#x7F6E;&#x4E00;&#x6B21;&#x3002;&#x53D1;&#x73B0;&#x8FD8;&#x662F;&#x4E0D;&#x884C;&#xFF0C;&#x5728;kerberos&#x4E2D;&#x751F;&#x6210;&#x7684;&#x7528;&#x6237;&#x8FD8;&#x662F;&#x5927;&#x5199;&#x7684;&#x3002; 2&#x3002;&#x4E8E;&#x662F;&#x4FEE;&#x6539;kerberos&#x4E2D;&#x8D26;&#x53F7;&#x540D;&#xFF0C;&#x5C06;VLNX&#x4FEE;&#x6539;&#x4E3A;vlnx&#x3002;1234for P in `kadmin.local -q &quot;listprincs&quot; | fgrep VLNX` ; do UP=`echo $P | sed &apos;s/VLNX/vlnx/g&apos; ` kadmin.local -q &quot;renprinc -force ${P} ${UP}&quot;done &#x8FD8;&#x662F;&#x4E0D;&#x884C;&#xFF0C;&#x8FD9;&#x662F;&#x5728;&#x6211;&#x9884;&#x6599;&#x4E2D;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x5728;&#x751F;&#x6210;&#x7684;keytab&#x4E2D;&#x8D26;&#x53F7;&#x540D;&#x8FD8;&#x662F;&#x5927;&#x5199;&#x7684;&#x3002;&#x53C2;&#x8003;&#x4E0A;&#x9762;&#x7684;klist -k hdfs.keytab&#x547D;&#x4EE4;&#x7ED3;&#x679C;&#x3002; 3&#x3002;&#x7EC8;&#x6781;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x6765;&#x4E86;&#x3002;cloudera&#x4E2D;kerberos&#x751F;&#x6210;&#x51ED;&#x8BC1;&#x53D6;&#x7684;&#x662F;&#x5728;cloudera&#x6570;&#x636E;&#x5E93;&#x4E2D;&#x4FDD;&#x5B58;&#x7684;&#x4E3B;&#x673A;&#x540D;&#xFF0C;&#x6240;&#x4EE5;&#x9700;&#x8981;&#x4FEE;&#x6539;cloudera&#x4E3B;&#x673A;&#x540D;&#xFF0C;&#x5728;&#x9875;&#x9762;&#x4E2D;&#x6CA1;&#x6709;&#x627E;&#x5230;&#x53EF;&#x4EE5;&#x4FEE;&#x6539;&#x4E3B;&#x673A;&#x540D;&#x7684;&#x5730;&#x65B9;&#xFF0C;&#x53EA;&#x80FD;&#x901A;&#x8FC7;&#x6570;&#x636E;&#x5E93;&#x4FEE;&#x6539;&#x3002; cloudera&#x81EA;&#x8EAB;&#x4F7F;&#x7528;&#x7684;&#x6570;&#x636E;&#x5E93;&#x662F;postgres&#xFF0C;database&#x4E3A;scm&#xFF0C;&#x5BC6;&#x7801;&#x5728;/etc/cloudera-scm-server/db.properties&#x4E2D;&#x3002;&#x901A;&#x8FC7;psql -h localhost -p 7432 -U scm&#x8FDB;&#x5165;postgres cli&#x3002; &#x67E5;&#x770B;hosts&#xFF0C;&#x5E76;&#x4FEE;&#x6539;name123456789101112131415scm=&gt; select host_id,host_identifier,name,ip_address from hosts; host_id | host_identifier | name | ip_address---------+--------------------------------------+------------+---------------- 1 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX107009 | 192.1.107.9 2 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX107010 | 192.1.107.10 9 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103122 | 192.1.103.122 7 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103124 | 192.1.103.124 8 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103125 | 192.1.103.125 6 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103126 | 192.1.103.126 5 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103127 | 192.1.103.127 4 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103128 | 192.1.103.128 12 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX103129 | 192.1.103.129 3 | xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx | VLNX107011 | 192.1.107.11scm=&gt; update hosts set name = &apos;vlnx107011&apos; where host_id = 3; &#x5168;&#x90E8;&#x66F4;&#x65B0;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x91CD;&#x542F;cloudera-scm-server&#x548C;&#x6240;&#x6709;&#x673A;&#x5668;&#x7684;cloudera-scm-agent&#xFF0C;&#x7136;&#x540E;&#x518D;&#x91CD;&#x65B0;&#x6765;&#x4E00;&#x904D;&#x3002; 4. &#x8DE8;&#x96C6;&#x7FA4;distcp&#x5F02;&#x5E38;&#x4ECE;&#x4E00;&#x4E2A;&#x975E;&#x5B89;&#x5168;&#x96C6;&#x7FA4;&#x62F7;&#x8D1D;&#x6570;&#x636E;&#x5230;&#x5B89;&#x5168;&#x96C6;&#x7FA4;&#x5B58;&#x5728;&#x95EE;&#x9898;&#xFF0C;&#x53C2;&#x8003;https://issues.apache.org/jira/browse/HDFS-7037&#x6B64;&#x95EE;&#x9898;&#x8FD8;&#x672A;&#x5F97;&#x5230;&#x89E3;&#x51B3;&#xFF0C;&#x7531;&#x4E8E;&#x6211;&#x4EEC;&#x6709;&#x4E24;&#x4E2A;&#x96C6;&#x7FA4;&#xFF0C;&#x5E76;&#x4E14;&#x4F1A;&#x8FDB;&#x884C;&#x96C6;&#x7FA4;&#x95F4;&#x6570;&#x636E;&#x4EA4;&#x4E92;&#xFF0C;&#x6240;&#x4EE5;&#x6700;&#x540E;&#x672A;&#x542F;&#x7528;kerberos&#x3002; 5. yarn&#x4E2D;&#x4EFB;&#x52A1;&#x62A5;&#x9519;&#x201D;&#x7528;&#x6237;id&#x5C0F;&#x4E8E;1000&#x201D;Diagnostics: Application application_1453449921629_0005 initialization failed (exitCode=255) with output: Requested user hdfs is not whitelisted and has id 496, which is below the minimum allowed 1000 &#x7528;&#x6237;&#x5728;client&#x4E0A;id&#x4E0D;&#x80FD;&#x5C0F;&#x4E8E;1000&#xFF0C;&#x53EF;&#x4EE5;&#x5728;container-executor.cfg&#x914D;&#x7F6E;min.user.id&#xFF0C;&#x6216;&#x8005;&#x4FEE;&#x6539;linux&#x7684;/etc/login.defs&#x4E2D;UID_MIN&#x5927;&#x5C0F;&#x3002; 6. yarn&#x4E2D;&#x8DD1;&#x4EFB;&#x52A1;&#x65F6;&#x62A5;&#x9519;User &lt;user&gt; not found&#x5F02;&#x5E38;&#x4FE1;&#x606F;: Diagnostics: Application application_1453449921629_0004 initialization failed (exitCode=255) with output: User usertest not found &#x89E3;&#x51B3;&#x65B9;&#x6848;&#xFF1A;&#x9700;&#x8981;&#x6240;&#x6709;nodemanager&#x4E0A;&#x6709;&#x76F8;&#x5E94;&#x7684;&#x7528;&#x6237;1useradd -m usertest &amp;&amp; echo &lt;password&gt; | passwd --stdin usertest 7. yarn&#x62A5;&#x9519;Can&apos;t create directory /yarn/nm/usercache/... Permission denied&#x5F02;&#x5E38;&#x4FE1;&#x606F;&#xFF1A; Can&apos;t create directory /yarn/nm/usercache/usertest/appcache/application_1453549225084_0001 - Permission denied. Did not create any app directories &#x89E3;&#x51B3;&#x65B9;&#x6CD5;&#xFF1A;&#x624B;&#x52A8;&#x5220;&#x9664;&#x6240;&#x6709;nodemanager&#x7684;/yarn/nm/usercache/&#x4E0B;&#x5185;&#x5BB9;&#x3002; &#x6CE8;&#x610F;&#x4E0D;&#x80FD;&#x5220;&#x9664;&#x6574;&#x4E2A;usercache&#x76EE;&#x5F55;&#xFF0C;&#x5426;&#x5219;&#x4F1A;&#x62A5;Failed to create directory /yarn/nm/usercache/usertest - No such file or directory&#x3002;&#x62A5;&#x8FD9;&#x4E2A;&#x9519;&#x65F6;&#xFF0C;&#x53EA;&#x8981;&#x518D;&#x65B0;&#x5EFA;&#x8FD9;&#x4E2A;&#x76EE;&#x5F55;&#xFF0C;&#x5E76;chown&#x7ED9;yarn&#x3002; &#x53C2;&#x8003;&#xFF1A;http://community.cloudera.com/t5/Batch-Processing-and-Workflow/Can-t-create-directory-yarn-nm-usercache-urika-appcache/td-p/24891 Fix was to remove or move the urika cache directory from all the nodes with (computes in my case). Seems that these directories will get re-created during a run.Bug when you go from simlpe AUTH to kerberos AUTH; the cache directories will not work if created under simple AUTH. &#x53C2;&#x8003; Cloudera&#x5B98;&#x7F51;: Enabling Kerberos Authentication Using the Wizard HDFS&#x914D;&#x7F6E;Kerberos&#x8BA4;&#x8BC1; CDH&#x914D;&#x7F6E;Kerberos&#x540E;&#x7684;&#x95EE;&#x9898; Linux&#x52A0;&#x5165;&#x57DF;kinit&#x547D;&#x4EE4;&#x9A8C;&#x8BC1;&#x9519;&#x8BEF;&#x89E3;&#x7B54; Creating Kerberos Keytab Files Compatible with Active Directory cloudera kerberos hostname&#x5927;&#x5C0F;&#x5199;&#x95EE;&#x9898; Using kerberos5 for single sign on authentication","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"},{"name":"kerberos","slug":"kerberos","permalink":"http://wzktravel.github.io/tags/kerberos/"}]},{"title":"ntp server搭建","slug":"ntp-server","date":"2016-01-15T10:25:41.000Z","updated":"2016-08-24T07:25:17.000Z","comments":true,"path":"2016/01/15/ntp-server/","link":"","permalink":"http://wzktravel.github.io/2016/01/15/ntp-server/","excerpt":"NTP（Network Time Protocol）是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源做同步化，它可以提供高精准度的时间校正。在CDH集群中，要求服务器之间时钟尽量保持同步，本例讲解如何在CentOS6.5上配置NTP服务器和NTP客户端，可使多台客户机的时间与指定的NTP服务器的时间保持一致。从而保证多台服务器的时间同步。","text":"NTP&#xFF08;Network Time Protocol&#xFF09;&#x662F;&#x7528;&#x6765;&#x4F7F;&#x8BA1;&#x7B97;&#x673A;&#x65F6;&#x95F4;&#x540C;&#x6B65;&#x5316;&#x7684;&#x4E00;&#x79CD;&#x534F;&#x8BAE;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x4F7F;&#x8BA1;&#x7B97;&#x673A;&#x5BF9;&#x5176;&#x670D;&#x52A1;&#x5668;&#x6216;&#x65F6;&#x949F;&#x6E90;&#x505A;&#x540C;&#x6B65;&#x5316;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x63D0;&#x4F9B;&#x9AD8;&#x7CBE;&#x51C6;&#x5EA6;&#x7684;&#x65F6;&#x95F4;&#x6821;&#x6B63;&#x3002;&#x5728;CDH&#x96C6;&#x7FA4;&#x4E2D;&#xFF0C;&#x8981;&#x6C42;&#x670D;&#x52A1;&#x5668;&#x4E4B;&#x95F4;&#x65F6;&#x949F;&#x5C3D;&#x91CF;&#x4FDD;&#x6301;&#x540C;&#x6B65;&#xFF0C;&#x672C;&#x4F8B;&#x8BB2;&#x89E3;&#x5982;&#x4F55;&#x5728;CentOS6.5&#x4E0A;&#x914D;&#x7F6E;NTP&#x670D;&#x52A1;&#x5668;&#x548C;NTP&#x5BA2;&#x6237;&#x7AEF;&#xFF0C;&#x53EF;&#x4F7F;&#x591A;&#x53F0;&#x5BA2;&#x6237;&#x673A;&#x7684;&#x65F6;&#x95F4;&#x4E0E;&#x6307;&#x5B9A;&#x7684;NTP&#x670D;&#x52A1;&#x5668;&#x7684;&#x65F6;&#x95F4;&#x4FDD;&#x6301;&#x4E00;&#x81F4;&#x3002;&#x4ECE;&#x800C;&#x4FDD;&#x8BC1;&#x591A;&#x53F0;&#x670D;&#x52A1;&#x5668;&#x7684;&#x65F6;&#x95F4;&#x540C;&#x6B65;&#x3002; NTP server&#x4FEE;&#x6539;/etc/ntp.conf &#x8BF4;&#x660E;&#xFF1A; server 1.cn.pool.ntp.org &#x662F;&#x8FDC;&#x7A0B;&#x65F6;&#x95F4;&#x670D;&#x52A1;&#x5668;&#x7684;&#x5730;&#x5740;&#x3002;CentOS&#x5728;&#x6B64;&#x5904;&#x7684;&#x914D;&#x7F6E;&#x9879;&#x662F; 0.centos.pool.ntp.org, 1.centos.pool.ntp.org, 2.centos.pool.ntp.org, &#x6D4B;&#x8BD5;&#x4E2D;&#x53D1;&#x73B0;&#x8FD9;&#x51E0;&#x4E2A;&#x65F6;&#x95F4;&#x670D;&#x52A1;&#x5668;&#x90FD;&#x4E0D;&#x80FD;&#x6B63;&#x786E;&#x7684;&#x540C;&#x6B65;&#xFF0C;&#x6240;&#x4EE5;&#x628A;&#x5B83;&#x4EEC;&#x7ED9;&#x6CE8;&#x91CA;&#x6389;&#x3002; server 127.127.1.0 &#x548C; fudge 127.127.1.0 stratum 10 &#x5982;&#x679C;&#x914D;&#x7F6E;&#x7684;&#x8FDC;&#x7A0B;server&#x65E0;&#x6548;&#x65F6;&#xFF0C;&#x5219;NTP&#x670D;&#x52A1;&#x5668;&#x4F1A;&#x6839;&#x636E;&#x8FD9;&#x91CC;&#x7684;&#x914D;&#x7F6E;&#xFF0C;&#x628A;&#x81EA;&#x5DF1;&#x7684;&#x65F6;&#x95F4;&#x505A;&#x4E3A;NTP&#x670D;&#x52A1;&#x5668;&#x7684;&#x65F6;&#x95F4;&#xFF0C;&#x5373;&#x548C;&#x81EA;&#x5DF1;&#x540C;&#x6B65;&#x3002;&#x8003;&#x8651;&#x5230;&#x6709;&#x7684;&#x5C40;&#x57DF;&#x7F51;&#x91CC;&#x4E0D;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x5916;&#x7F51;&#xFF0C;&#x6240;&#x6709;&#x8FD9;&#x91CC;&#x9700;&#x8981;&#x628A;&#x8FD9;&#x4E2A;&#x914D;&#x7F6E;&#x9879;&#x7528;&#x4E0A;&#x3002; NTP&#x670D;&#x52A1;&#x9ED8;&#x8BA4;&#x8D70;UPD&#x534F;&#x8BAE;&#xFF0C;&#x4F7F;&#x7528;123&#x7AEF;&#x53E3;&#xFF0C;&#x5982;&#x679C;&#x542F;&#x52A8;&#x9632;&#x706B;&#x5899;&#x7684;&#x8BDD;&#xFF0C;&#x9700;&#x8981;&#x914D;&#x7F6E;&#x4E00;&#x4E0B;&#x9632;&#x706B;&#x5899;&#x3002; ntp server&#x914D;&#x7F6E;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x6267;&#x884C;service ntpd restart&#x5373;&#x53EF;&#x3002; NTP&#x670D;&#x52A1;&#x542F;&#x52A8;&#x540E;&#x5927;&#x7EA6;&#x9700;&#x8981;3&#xFF5E;5&#x5206;&#x949F;&#x7684;&#x65F6;&#x95F4;&#x624D;&#x4F1A;&#x8FDB;&#x884C;&#x4E00;&#x6B21;&#x65F6;&#x95F4;&#x540C;&#x6B65;&#x3002;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x547D;&#x4EE4;ntpstat&#x67E5;&#x770B;&#x540C;&#x6B65;&#x60C5;&#x51B5;&#x3002;&#x53EA;&#x6709;NTP&#x670D;&#x52A1;&#x5668;&#x540C;&#x6B65;&#x6210;&#x529F;&#x540E;&#xFF0C;NTP&#x5BA2;&#x6237;&#x7AEF;&#x624D;&#x53EF;&#x4EE5;&#x540C;&#x6765;&#x540C;&#x6B65;&#x65F6;&#x95F4;&#x3002;&#x5982;&#x679C;&#x9700;&#x8981;&#x7ACB;&#x523B;&#x4ECE;&#x6307;&#x5B9A;&#x7684;&#x65F6;&#x95F4;&#x670D;&#x52A1;&#x5668;&#x540C;&#x6B65;&#x65F6;&#x95F4;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;ntpdate &#x547D;&#x4EE4;&#x3002;&#x4F7F;&#x7528;ntpdate&#x547D;&#x4EE4;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x5148;&#x5173;&#x95ED;ntp&#x670D;&#x52A1;service ntpd stop&#x3002;&#x7136;&#x540E;&#x6267;&#x884C;ntpdate 1.cn.pool.ntp.org &#x5373;&#x53EF;&#x7ACB;&#x5373;&#x5B8C;&#x6210;&#x65F6;&#x95F4;&#x7684;&#x540C;&#x6B65;&#xFF0C;&#x7136;&#x540E;&#x542F;&#x52A8;ntp&#x670D;&#x52A1;service ntpd start&#x3002; NTP client&#x540C;&#x6837;&#x4FEE;&#x6539;/etc/ntp.conf &#x8BF4;&#x660E;:&#x5BA2;&#x6237;&#x7AEF;&#x7684;&#x914D;&#x7F6E;&#x6BD4;&#x670D;&#x52A1;&#x5668;&#x7684;&#x914D;&#x7F6E;&#x8981;&#x7B80;&#x5355;&#x4E00;&#x4E0B;&#xFF0C;&#x53EA;&#x9700;&#x52A0;&#x5165; server 172.31.107.9 &#x5373;&#x53EF;&#xFF0C;&#x8868;&#x660E;&#x672C;&#x673A;&#x7684;&#x65F6;&#x95F4;&#x670D;&#x52A1;&#x5668;&#x3002;&#x5176;&#x4ED6;&#x64CD;&#x4F5C;&#x4E0E;&#x670D;&#x52A1;&#x5668;&#x4E00;&#x81F4;&#x3002; &#x6279;&#x91CF;&#x4FEE;&#x6539;ntp client&#x914D;&#x7F6E;12345678910NTPSERVER=172.31.107.9for IP in `cat /etc/hosts | fgrep 103 | awk &apos;{print $1}&apos;`; do ssh ${IP} &quot; sed -i &apos;22,25s/^/#/g&apos; /etc/ntp.conf &amp;&amp; \\ sed -i &apos;25a server &quot;${NTPSERVER}&quot; iburst&apos; /etc/ntp.conf &amp;&amp; \\ service ntpd stop &amp;&amp; \\ ntpdate &quot;${NTPSERVER}&quot; &amp;&amp; \\ service ntpd start &quot;done &#x8BF4;&#x660E;: &#x4ECE;hosts&#x4E2D;&#x627E;&#x5230;CDH&#x96C6;&#x7FA4;host &#x9700;&#x8981;&#x914D;&#x7F6E;root&#x514D;&#x767B;&#x9646; CDH&#x96C6;&#x7FA4;&#x673A;&#x5668;&#x4E2D;&#x7684;/etc/hosts&#x914D;&#x7F6E;&#x4E00;&#x81F4;&#xFF0C;&#x6240;&#x4EE5;&#x53EF;&#x4EE5;&#x6279;&#x91CF;&#x5904;&#x7406;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"}]},{"title":"kafka重新分配partition","slug":"kafka-reassign","date":"2015-12-31T09:29:51.000Z","updated":"2016-10-26T12:16:06.000Z","comments":true,"path":"2015/12/31/kafka-reassign/","link":"","permalink":"http://wzktravel.github.io/2015/12/31/kafka-reassign/","excerpt":"今天kafka测试环境中机器磁盘告警，占用率超过了80%，原来是某一个topic的partition为1，只往一台机器上写数据，造成kafka集群空间使用不均。下面主要使用kafka-topics.sh和kafka-reassign-partitions.sh来解决问题。推荐使用kafka manager来管理kafka集群。","text":"&#x4ECA;&#x5929;kafka&#x6D4B;&#x8BD5;&#x73AF;&#x5883;&#x4E2D;&#x673A;&#x5668;&#x78C1;&#x76D8;&#x544A;&#x8B66;&#xFF0C;&#x5360;&#x7528;&#x7387;&#x8D85;&#x8FC7;&#x4E86;80%&#xFF0C;&#x539F;&#x6765;&#x662F;&#x67D0;&#x4E00;&#x4E2A;topic&#x7684;partition&#x4E3A;1&#xFF0C;&#x53EA;&#x5F80;&#x4E00;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x5199;&#x6570;&#x636E;&#xFF0C;&#x9020;&#x6210;kafka&#x96C6;&#x7FA4;&#x7A7A;&#x95F4;&#x4F7F;&#x7528;&#x4E0D;&#x5747;&#x3002;&#x4E0B;&#x9762;&#x4E3B;&#x8981;&#x4F7F;&#x7528;kafka-topics.sh&#x548C;kafka-reassign-partitions.sh&#x6765;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#x3002;&#x63A8;&#x8350;&#x4F7F;&#x7528;kafka manager&#x6765;&#x7BA1;&#x7406;kafka&#x96C6;&#x7FA4;&#x3002; &#x4FEE;&#x6539;topic&#x7684;partitions1./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --alter --topic test --partitions 6 &#x6B64;&#x547D;&#x4EE4;&#x6267;&#x884C;&#x5B8C;&#x4E4B;&#x540E;&#x5373;&#x53EF;&#x518D;kafka&#x96C6;&#x7FA4;&#x5176;&#x4ED6;&#x673A;&#x5668;&#x4E2D;&#x627E;&#x5230;&#x6B64;topic&#x7684;&#x76EE;&#x5F55; &#x6269;&#x5BB9;&#x3001;&#x5220;&#x9664;&#x673A;&#x5668;&#x53EA;&#x8981;&#x914D;&#x7F6E;zookeeper.connect&#x4E3A;&#x8981;&#x52A0;&#x5165;&#x7684;&#x96C6;&#x7FA4;&#xFF0C;&#x518D;&#x542F;&#x52A8;Kafka&#x8FDB;&#x7A0B;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x8BA9;&#x65B0;&#x7684;&#x673A;&#x5668;&#x52A0;&#x5165;&#x5230;Kafka&#x96C6;&#x7FA4;&#x3002;&#x4F46;&#x662F;&#x65B0;&#x7684;&#x673A;&#x5668;&#x53EA;&#x9488;&#x5BF9;&#x65B0;&#x7684;Topic&#x624D;&#x4F1A;&#x8D77;&#x4F5C;&#x7528;&#xFF0C;&#x5728;&#x4E4B;&#x524D;&#x5C31;&#x5DF2;&#x7ECF;&#x5B58;&#x5728;&#x7684;Topic&#x7684;&#x5206;&#x533A;&#xFF0C;&#x4E0D;&#x4F1A;&#x81EA;&#x52A8;&#x7684;&#x5206;&#x914D;&#x5230;&#x65B0;&#x589E;&#x52A0;&#x7684;&#x7269;&#x7406;&#x673A;&#x4E2D;&#x3002;&#x4E3A;&#x4E86;&#x4F7F;&#x65B0;&#x589E;&#x52A0;&#x7684;&#x673A;&#x5668;&#x53EF;&#x4EE5;&#x5206;&#x62C5;&#x7CFB;&#x7EDF;&#x538B;&#x529B;&#xFF0C;&#x5FC5;&#x987B;&#x8FDB;&#x884C;&#x6D88;&#x606F;&#x6570;&#x636E;&#x8FC1;&#x79FB;&#x3002;Kafka&#x63D0;&#x4F9B;&#x4E86;kafka-reassign-partitions.sh&#x8FDB;&#x884C;&#x6570;&#x636E;&#x8FC1;&#x79FB;&#x3002; &#x8FD9;&#x4E2A;&#x811A;&#x672C;&#x63D0;&#x4F9B;3&#x4E2A;&#x547D;&#x4EE4;&#xFF1A; --generate: &#x6839;&#x636E;&#x7ED9;&#x4E88;&#x7684;Topic&#x5217;&#x8868;&#x548C;Broker&#x5217;&#x8868;&#x751F;&#x6210;&#x8FC1;&#x79FB;&#x8BA1;&#x5212;&#x3002;generate&#x5E76;&#x4E0D;&#x4F1A;&#x771F;&#x6B63;&#x8FDB;&#x884C;&#x6D88;&#x606F;&#x8FC1;&#x79FB;&#xFF0C;&#x800C;&#x662F;&#x5C06;&#x6D88;&#x606F;&#x8FC1;&#x79FB;&#x8BA1;&#x5212;&#x8BA1;&#x7B97;&#x51FA;&#x6765;&#xFF0C;&#x4F9B;execute&#x547D;&#x4EE4;&#x4F7F;&#x7528;&#x3002; --execute: &#x6839;&#x636E;&#x7ED9;&#x4E88;&#x7684;&#x6D88;&#x606F;&#x8FC1;&#x79FB;&#x8BA1;&#x5212;&#x8FDB;&#x884C;&#x8FC1;&#x79FB;&#x3002; --verify: &#x68C0;&#x67E5;&#x6D88;&#x606F;&#x662F;&#x5426;&#x5DF2;&#x7ECF;&#x8FC1;&#x79FB;&#x5B8C;&#x6210;&#x3002; &#x793A;&#x4F8B;topic&#x4E3A;test&#x76EE;&#x524D;&#x5728;broker id&#x4E3A;1,2,3&#x7684;&#x673A;&#x5668;&#x4E0A;&#xFF0C;&#x73B0;&#x53C8;&#x6DFB;&#x52A0;&#x4E86;&#x4E24;&#x53F0;&#x673A;&#x5668;&#xFF0C;broker id&#x4E3A;4,5&#xFF0C;&#x73B0;&#x5728;&#x60F3;&#x8981;&#x5C06;&#x538B;&#x529B;&#x5E73;&#x5747;&#x5206;&#x6563;&#x5230;&#x8FD9;5&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x3002; &#x624B;&#x52A8;&#x751F;&#x6210;&#x4E00;&#x4E2A;json&#x6587;&#x4EF6;topic.json123456{ &quot;topics&quot;: [ {&quot;topic&quot;: &quot;test&quot;} ], &quot;version&quot;: 1} &#x8C03;&#x7528;--generate&#x751F;&#x6210;&#x8FC1;&#x79FB;&#x8BA1;&#x5212;&#xFF0C;&#x5C06;test&#x6269;&#x5145;&#x5230;&#x6240;&#x6709;&#x673A;&#x5668;&#x4E0A;1./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --topics-to-move-json-file topic.json --broker-list &quot;1,2,3,4,5&quot; --generate &#x751F;&#x6210;&#x7C7B;&#x4F3C;&#x4E8E;&#x4E0B;&#x65B9;&#x7684;&#x7ED3;&#x679C; 1234567891011Current partition replica assignment{&quot;version&quot;:1, &quot;partitions&quot;:[....]}Proposed partition reassignment configuration{&quot;version&quot;:1, &quot;partitions&quot;:[.....]} Current partition replica assignment&#x8868;&#x793A;&#x5F53;&#x524D;&#x7684;&#x6D88;&#x606F;&#x5B58;&#x50A8;&#x72B6;&#x51B5;&#x3002;Proposed partition reassignment configuration&#x8868;&#x793A;&#x8FC1;&#x79FB;&#x540E;&#x7684;&#x6D88;&#x606F;&#x5B58;&#x50A8;&#x72B6;&#x51B5;&#x3002;&#x5C06;&#x8FC1;&#x79FB;&#x540E;&#x7684;json&#x5B58;&#x5165;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;reassignment.json&#xFF0C;&#x4F9B;--execute&#x547D;&#x4EE4;&#x4F7F;&#x7528;&#x3002; &#x6267;&#x884C;--execute&#x8FDB;&#x884C;&#x6269;&#x5BB9;&#x3002;123456./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --reassignment-json-file reassignment.json --executeCurrent partition replica assignment... Save this to use as the --reassignment-json-file option during rollback... &#x4F7F;&#x7528;--verify&#x67E5;&#x770B;&#x8FDB;&#x5EA6;1./bin/kafka-reassign-partitions.sh --zookeeper vlnx111122:2181 --reassignment-json-file reassignment.json --verify &#x76F8;&#x5173;&#x547D;&#x4EE4; ./bin/kafka-console-producer.sh --broker-list vlnx111111:9092 --topic test ./bin/kafka-console-consumer.sh --zookeeper vlnx111122:2181 --topic test --from-beginning ./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --list ./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --create --replication-factor 2 --partition 6 --topic test ./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --delete --topic test ./bin/kafka-topics.sh --zookeeper vlnx111122:2181 --describe --topic test &#x53C2;&#x8003; http://kafka.apache.org/082/documentation.html#basic_ops_modify_topic How to choose the number of topics/partitions in a Kafka cluster? Kafka 0.9 Configuration Best Practices Apche Kafka &#x7684;&#x751F;&#x4E0E;&#x6B7B; &#x2013; failover &#x673A;&#x5236;&#x8BE6;&#x89E3;","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://wzktravel.github.io/tags/kafka/"}]},{"title":"flume-ng配置以及使用lzo","slug":"flume-ng","date":"2015-12-11T08:11:55.000Z","updated":"2016-10-24T11:41:18.000Z","comments":true,"path":"2015/12/11/flume-ng/","link":"","permalink":"http://wzktravel.github.io/2015/12/11/flume-ng/","excerpt":"flume-ng配置以及使用过程中遇到的问题和解决办法。重点说一下hdfs.codeC使用lzo的问题。另外附上自己实现的flume插件，https://github.com/wzktravel/flume-agent，当前有一个interceptor，两个source： HDFSInterceptor，在header中加入时间,文件名,ip等 SpoolDirectoryHourlySource，收集按小时进行切片的日志 DirTailPollableSource2, 动态tail目录下最后修改的文件 以下都基于flume ng 1.6.0版本，最后附上flume上报到hdfs的配置。","text":"flume-ng&#x914D;&#x7F6E;&#x4EE5;&#x53CA;&#x4F7F;&#x7528;&#x8FC7;&#x7A0B;&#x4E2D;&#x9047;&#x5230;&#x7684;&#x95EE;&#x9898;&#x548C;&#x89E3;&#x51B3;&#x529E;&#x6CD5;&#x3002;&#x91CD;&#x70B9;&#x8BF4;&#x4E00;&#x4E0B;hdfs.codeC&#x4F7F;&#x7528;lzo&#x7684;&#x95EE;&#x9898;&#x3002;&#x53E6;&#x5916;&#x9644;&#x4E0A;&#x81EA;&#x5DF1;&#x5B9E;&#x73B0;&#x7684;flume&#x63D2;&#x4EF6;&#xFF0C;https://github.com/wzktravel/flume-agent&#xFF0C;&#x5F53;&#x524D;&#x6709;&#x4E00;&#x4E2A;interceptor&#xFF0C;&#x4E24;&#x4E2A;source&#xFF1A; HDFSInterceptor&#xFF0C;&#x5728;header&#x4E2D;&#x52A0;&#x5165;&#x65F6;&#x95F4;,&#x6587;&#x4EF6;&#x540D;,ip&#x7B49; SpoolDirectoryHourlySource&#xFF0C;&#x6536;&#x96C6;&#x6309;&#x5C0F;&#x65F6;&#x8FDB;&#x884C;&#x5207;&#x7247;&#x7684;&#x65E5;&#x5FD7; DirTailPollableSource2, &#x52A8;&#x6001;tail&#x76EE;&#x5F55;&#x4E0B;&#x6700;&#x540E;&#x4FEE;&#x6539;&#x7684;&#x6587;&#x4EF6; &#x4EE5;&#x4E0B;&#x90FD;&#x57FA;&#x4E8E;flume ng 1.6.0&#x7248;&#x672C;&#xFF0C;&#x6700;&#x540E;&#x9644;&#x4E0A;flume&#x4E0A;&#x62A5;&#x5230;hdfs&#x7684;&#x914D;&#x7F6E;&#x3002; &#x5F15;&#x7528;&#x7B2C;&#x4E09;&#x65B9;jar&#x5305;&#x4E0D;&#x5FC5;&#x653E;&#x5728;flume&#x7684;lib&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x53C2;&#x8003;http://flume.apache.org/FlumeUserGuide.html#installing-third-party-plugins&#x5728;flume&#x76EE;&#x5F55;&#x4E0B;&#x65B0;&#x5EFA;plugins.d&#x76EE;&#x5F55;&#xFF0C;&#x6B64;&#x76EE;&#x5F55;&#x4E0B;&#x6BCF;&#x4E2A;&#x63D2;&#x4EF6;&#x5355;&#x72EC;&#x4E00;&#x4E2A;&#x76EE;&#x5F55;&#xFF0C;&#x6BCF;&#x4E2A;&#x63D2;&#x4EF6;&#x76EE;&#x5F55;&#x4E0B;&#x53EF;&#x4EE5;&#x6709;lib,libext,native&#x3002; lib: &#x653E;&#x7F6E;&#x63D2;&#x4EF6;jar&#x5305; libext: &#x653E;&#x7F6E;&#x63D2;&#x4EF6;&#x5F15;&#x7528;&#x7684;jar&#x5305; native: &#x653E;&#x7F6E;&#x6240;&#x9700;&#x7684;native&#x5E93;, &#x6BD4;&#x5982;.so&#x6587;&#x4EF6; &#x5982;&#x6211;&#x6709;hdfs&#x63D2;&#x4EF6;&#x548C;&#x81EA;&#x5DF1;&#x5B9E;&#x73B0;&#x7684;flume interceptor/source&#x4EE5;&#x53CA;lzo&#xFF0C;&#x76EE;&#x5F55;&#x683C;&#x5F0F;&#x5982;&#x4E0B;&#xFF1A;1234567891011121314151617plugins.d/plugins.d/custom/plugins.d/custom/lib/flume-agent-1.0-SNAPSHOT.jarplugins.d/hadoop/plugins.d/hadoop/lib/commons-configuration-1.6.jarplugins.d/hadoop/lib/hadoop-auth-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-common-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-hdfs-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-nfs-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/htrace-core-3.0.4.jarplugins.d/hadoop-lzo/plugins.d/hadoop-lzo/lib/hadoop-lzo-cdh4-0.4.15-gplextras.jarplugins.d/hadoop-lzo/native/libgplcompression.aplugins.d/hadoop-lzo/native/libgplcompression.laplugins.d/hadoop-lzo/native/libgplcompression.soplugins.d/hadoop-lzo/native/libgplcompression.so.0plugins.d/hadoop-lzo/native/libgplcompression.so.0.0.0 hdfs-sink&#x5BF9;&#x4E8E;flume&#x548C;hadoop&#x5728;&#x540C;&#x4E00;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x7684;&#xFF0C;&#x914D;&#x7F6E;&#x5F88;&#x7B80;&#x5355;&#xFF0C;&#x76F4;&#x63A5;&#x6309;&#x7167;flume&#x5B98;&#x7F51;&#x914D;&#x7F6E;&#x5373;&#x53EF;&#xFF0C;&#x4F46;&#x5982;&#x679C;&#x5728;&#x6CA1;&#x6709;hadoop&#x7684;&#x673A;&#x5668;&#x4E0A;&#x4F7F;&#x7528;hdfs-sink&#xFF0C;&#x9700;&#x8981;&#x4E00;&#x4E9B;&#x989D;&#x5916;&#x7684;jar&#x5305;&#xFF0C;&#x4E0D;&#x50CF;kafka-sink&#x4E00;&#x6837;&#xFF0C;flume/lib&#x4E0B;&#x5DF2;&#x7ECF;&#x6709;kafka&#x76F8;&#x5173;&#x7684;jar&#x5305;&#x4E86;&#x3002; hdfs-sink&#x6240;&#x9700;jar&#x5305;&#x6700;&#x5C11;&#x9700;&#x8981;&#x8FD9;&#x51E0;&#x4E2A;jar&#x5305;&#xFF0C;&#x5982;&#x679C;&#x60F3;&#x4F7F;&#x7528;lzo&#x538B;&#x7F29;&#xFF0C;&#x8FD8;&#x9700;&#x5176;&#x4ED6;&#x8BBE;&#x7F6E;&#xFF0C;&#x770B;&#x4E0B;&#x6587;&#x3002;123456plugins.d/hadoop/lib/commons-configuration-1.6.jarplugins.d/hadoop/lib/hadoop-auth-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-common-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-hdfs-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/hadoop-nfs-2.6.0-cdh5.4.8.jarplugins.d/hadoop/lib/htrace-core-3.0.4.jar hdfs.codeC&#x4F7F;&#x7528;lzo&#x5148;&#x5047;&#x5B9A;&#x4F60;&#x7684;&#x96C6;&#x7FA4;&#x5DF2;&#x7ECF;&#x652F;&#x6301;lzo&#x4E86;&#xFF0C;&#x5982;&#x679C;&#x4E0D;&#x652F;&#x6301;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;Cloudera&#x4E2D;&#x914D;&#x7F6E;hadoop_lzo:http://wzktravel.github.io/2015/12/10/hadoop-lzo/&#xFF0C; &#x7F51;&#x4E0A;&#x7684;&#x8D44;&#x6599;&#x4E00;&#x822C;&#x90FD;&#x662F;flume&#x548C;hadoop&#x5728;&#x540C;&#x4E00;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x7684;&#xFF0C;&#x8FD9;&#x65F6;&#x5019;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x5C06;hdfs.codeC&#x8BBE;&#x7F6E;&#x4E3A;lzo&#xFF0C;&#x56E0;&#x4E3A;&#x80FD;&#x627E;&#x5230;&#x5BF9;&#x5E94;&#x7684;jar&#x5305;&#x548C;&#x914D;&#x7F6E;&#x3002;&#x5728;&#x7EAF;&#x51C0;&#x7684;&#x673A;&#x5668;&#x4E0A;&#xFF0C;&#x9700;&#x8981;&#x4E0B;&#x9762;&#x51E0;&#x4E2A;&#x914D;&#x7F6E;&#xFF1A; &#x624B;&#x5DE5;&#x7F16;&#x8BD1;lzo&#x548C;hadoop-lzo&#x7684;&#xFF0C;&#x76F4;&#x63A5;&#x5C06;jar&#x5305;&#x653E;&#x5728;plugins.d&#x4E0B;&#x5373;&#x53EF;&#x3002;&#x4F7F;&#x7528;Cloudera&#x5B89;&#x88C5;hadoop-lzo parcel&#x7684;&#xFF0C;&#x8981;&#x5C06;jar&#x5305;&#x548C;native&#x4E0B;&#x94FE;&#x63A5;&#x90FD;&#x653E;&#x5728;plugins.d&#x4E0B;&#x3002;&#x4E3A;&#x4F55;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x53C2;&#x8003; hadoop-lzo.jar&#x548C;hadoop-gpl-compression.jar&#x533A;&#x522B;&#xFF1A;http://guoyunsky.iteye.com/blog/1289475 &#x4ECE;hadoop&#x96C6;&#x7FA4;&#x4E0A;&#x62C9;&#x53D6;core-site.xml&#x653E;&#x5728;flume/conf&#x4E0B;&#xFF0C;&#x5176;&#x5B9E;&#x4E3B;&#x8981;&#x4F7F;&#x7528; 1234&lt;property&gt; &lt;name&gt;io.compression.codecs&lt;/name&gt; &lt;value&gt;org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec&lt;/value&gt;&lt;/property&gt; &#x5728;flume&#x914D;&#x7F6E; 12a1.sinks.hdfs-sink.hdfs.fileType = CompressedStreama1.sinks.hdfs-sink.hdfs.codeC = com.hadoop.compression.lzo.LzopCodec &#x8FD9;&#x91CC;&#x8981;&#x8BF4;&#x660E;&#x4E00;&#x4E0B;&#xFF0C;&#x4E3A;&#x4EC0;&#x4E48;&#x53EA;&#x653E;&#x7F6E;jar&#x5305;&#x4E0D;&#x884C;&#x5462;&#xFF1F;&#x56E0;&#x4E3A;&#x5728;flume&#x6E90;&#x7801;flume/flume-ng-sinks/flume-hdfs-sink/src/main/java/org/apache/flume/sink/hdfs/HDFSEventSink.java getCodec()&#x65B9;&#x6CD5;&#x4E2D;&#x4F7F;&#x7528;hadoop&#x4E86;&#x7684;CompressionCodecFactory.getCodecClasses(conf)&#x3002; &#x518D;&#x53BB;hadoop&#x6E90;&#x7801;&#x4E2D;&#x770B;CompressionCodecFactory.getCodecClasses(conf)&#x65F6;&#x53D1;&#x73B0; &#x800C;IO_COMPRESSION_CODECS_KEY&#x5C31;&#x662F;io.compression.codecs&#x3002; &#x6240;&#x4EE5;&#x9700;&#x8981;core-site.xml&#x6765;&#x6307;&#x5B9A;io.compression.codecs&#x3002; HA(High Availability)&#x7531;&#x4E8E;HDFS&#x96C6;&#x7FA4;&#x7684;HA&#x673A;&#x5236;&#xFF0C;&#x5728;flume&#x4E0A;&#x4F20;&#x65F6;&#x6307;&#x5B9A;namenode&#x7684;&#x505A;&#x6CD5;&#x5C31;&#x4E0D;&#x592A;&#x597D;&#x4E86;&#xFF0C;&#x5F53;hdfs&#x96C6;&#x7FA4;&#x7684;namenode&#x72B6;&#x6001;&#x53D1;&#x751F;&#x53D8;&#x5316;&#x65F6;&#xFF0C;flume&#x4E0A;&#x62A5;&#x65F6;&#x4F1A;&#x62A5;&#x51FA;Exception, Operation category READ(WRITE) is not supported in state standby&#xFF0C;&#x56E0;&#x4E3A;standby namenode&#x662F;&#x4E0D;&#x5BF9;&#x63D0;&#x4F9B;&#x670D;&#x52A1;&#x7684;&#x3002;&#x90A3;&#x4E48;&#x6B64;&#x65F6;flume&#x5C31;&#x5904;&#x4E8E;&#x4E0D;&#x53EF;&#x7528;&#x72B6;&#x6001;&#xFF0C;&#x5FC5;&#x987B;&#x624B;&#x5DE5;&#x4FEE;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x7136;&#x540E;&#x91CD;&#x542F;flume&#x624D;&#x80FD;&#x89E3;&#x51B3;&#x3002;&#x5F53;&#x8981;&#x6536;&#x96C6;&#x65E5;&#x5FD7;&#x7684;&#x670D;&#x52A1;&#x5668;&#x5F88;&#x591A;&#x65F6;&#xFF0C;&#x4F1A;&#x589E;&#x52A0;&#x5F88;&#x591A;&#x4EBA;&#x529B;&#x6210;&#x672C;&#xFF1B;&#x53E6;&#x5916;&#xFF0C;&#x65E5;&#x5FD7;&#x4E0A;&#x62A5;&#x72B6;&#x6001;&#x76D1;&#x63A7;&#x6CA1;&#x6709;&#x505A;&#x597D;&#x7684;&#x8BDD;&#xFF0C;&#x4E5F;&#x8BB8;&#x7528;&#x5230;&#x8FD9;&#x4E2A;&#x65E5;&#x5FD7;&#x7684;&#x65F6;&#x5019;&#x624D;&#x4F1A;&#x53D1;&#x73B0;flume&#x51FA;&#x73B0;&#x95EE;&#x9898;&#x3002; &#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x4E5F;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#xFF0C;&#x5C31;&#x662F;&#x5C06;&#x96C6;&#x7FA4;&#x4E2D;hdfs-site.xml&#x590D;&#x5236;&#x4E00;&#x4EFD;&#x5230;flume conf&#x76EE;&#x5F55;&#x4E0B;&#x5373;&#x53EF;&#xFF0C;&#x5F53;namenode&#x72B6;&#x6001;&#x5207;&#x6362;&#x65F6;&#xFF0C;flume&#x4E5F;&#x80FD;&#x6B63;&#x786E;&#x5C06;&#x65E5;&#x5FD7;&#x4E0A;&#x62A5;&#x5230;hdfs&#x4E2D;&#x3002;&#x6B64;&#x65F6;&#xFF0C;hdfs.path&#x914D;&#x7F6E;&#x4E5F;&#x53EF;&#x4EE5;&#x7701;&#x7565;&#x57DF;&#x540D;&#x3002;1234## &#x4FEE;&#x6539;&#x524D;# a1.sinks.hdfs-sink.hdfs.path = hdfs://{active namenode ip}/facishare-data/app/center/web/%{year}/%{month}/%{day}/## &#x4FEE;&#x6539;&#x540E;a1.sinks.hdfs-sink.hdfs.path = /facishare-data/app/center/web/%{year}/%{month}/%{day}/ &#x5B9A;&#x5236;&#x53C2;&#x8003;http://flume.apache.org/FlumeDeveloperGuide.html &#x5BF9;source,interceptor&#xFF0C;&#x53C2;&#x8003;flume&#x4E2D;&#x7684;&#x6E90;&#x7801;&#x5199;&#x5373;&#x53EF;&#x3002;&#x9700;&#x8981;&#x5F15;&#x7528;jar&#x5305;flume-ng-core:12345&lt;dependency&gt; &lt;groupId&gt;org.apache.flume&lt;/groupId&gt; &lt;artifactId&gt;flume-ng-core&lt;/artifactId&gt; &lt;version&gt;${flume.version}&lt;/version&gt;&lt;/dependency&gt; &#x6211;&#x7684;flume&#x4E0A;&#x62A5;&#x5230;hdfs&#x914D;&#x7F6E;1234567891011121314151617181920212223242526272829303132333435363738394041424344# name the components on this agenta1.sources = r1a1.sinks = hdfs-sinka1.channels = hdfs-channel# define interceptora1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.firstshare.flume.interceptor.HDFSInterceptor$Buildera1.sources.r1.interceptors.i1.hdfsinterceptor.switch = true# describe/configure the sourcea1.sources.r1.type = spooldira1.sources.r1.spoolDir = /data/appStatLog/flumea1.sources.r1.deletePolicy = immediatea1.sources.r1.basenameHeader = truea1.sources.r1.basenameHeaderKey = filea1.sources.r1.ignorePattern = ^(.)*\\\\.tmp$a1.sources.r1.fileSuffix = .COMPLETED# hdfs sinka1.sinks.hdfs-sink.type = hdfs# hdfs&#x8DEF;&#x5F84;&#x89C4;&#x5219;: /facishare-data/&#x4EA7;&#x54C1;&#x7EBF;/&#x6A21;&#x5757;/&#x5B50;&#x6A21;&#x5757;/$year/$month/$day/$filename.$host.lzoa1.sinks.hdfs-sink.hdfs.path = /facishare-data/app/center/web/%{year}/%{month}/%{day}/a1.sinks.hdfs-sink.hdfs.filePrefix = %{filename}.%{host}a1.sinks.hdfs-sink.hdfs.fileSuffix = .lzoa1.sinks.hdfs-sink.hdfs.fileType = CompressedStreama1.sinks.hdfs-sink.hdfs.codeC = com.hadoop.compression.lzo.LzopCodec# roll -&gt; close current file and create a new one# Number of seconds to wait before rolling current file (0 = never roll based on time interval)a1.sinks.hdfs-sink.hdfs.rollInterval = 0# File size to trigger roll, in bytes (0: never roll based on file size)a1.sinks.hdfs-sink.hdfs.rollSize = 204800000a1.sinks.hdfs-sink.hdfs.rollCount = 0# Timeout after which inactive files get closed (0 = disable automatic closing of idle files)a1.sinks.hdfs-sink.hdfs.idleTimeout = 30a1.channels.hdfs-channel.type = filea1.channels.hdfs-channel.checkpointDir = ./checkpointDira1.channels.hdfs-channel.dataDirs = ./dataDir# bind the source and sink to the channela1.sources.r1.channels = hdfs-channela1.sinks.hdfs-sink.channel = hdfs-channel &#x5176;&#x4E2D;HDFSInterceptor&#x662F;&#x81EA;&#x5DF1;&#x5B9E;&#x73B0;&#x7684;&#xFF0C;&#x4E3B;&#x8981;&#x6DFB;&#x52A0;&#x51E0;&#x4E2A;&#x53C2;&#x6570;&#x5230;header&#x4E2D;&#xFF0C;&#x4F7F;&#x4E0A;&#x62A5;&#x5230;hdfs&#x4E2D;&#x7684;&#x6587;&#x4EF6;&#x540D;&#x66F4;&#x7B26;&#x5408;&#x6211;&#x4EEC;&#x7684;&#x9700;&#x6C42;&#x3002; &#x53C2;&#x8003;&#x6587;&#x6863; flume&#x5B98;&#x7F51;UserGuide: http://flume.apache.org/FlumeUserGuide.html Hadoop2.0&#x7684;HA&#x4ECB;&#x7ECD;: http://www.tuicool.com/articles/IBZFvy HDFS High Availability Using the Quorum Journal Manager:http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"flume","slug":"flume","permalink":"http://wzktravel.github.io/tags/flume/"}]},{"title":"Cloudera中配置hadoop_lzo","slug":"hadoop-lzo","date":"2015-12-10T13:09:53.000Z","updated":"2016-08-17T11:28:43.000Z","comments":true,"path":"2015/12/10/hadoop-lzo/","link":"","permalink":"http://wzktravel.github.io/2015/12/10/hadoop-lzo/","excerpt":"Hadoop经常用于处理大量的数据，如果期间的输出数据、中间数据能压缩存储，对系统的I/O性能会有提升。综合考虑压缩、解压速度、是否支持split，目前lzo是最好的选择。下面主要介绍在Cloudera中如何配置lzo。","text":"Hadoop&#x7ECF;&#x5E38;&#x7528;&#x4E8E;&#x5904;&#x7406;&#x5927;&#x91CF;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x5982;&#x679C;&#x671F;&#x95F4;&#x7684;&#x8F93;&#x51FA;&#x6570;&#x636E;&#x3001;&#x4E2D;&#x95F4;&#x6570;&#x636E;&#x80FD;&#x538B;&#x7F29;&#x5B58;&#x50A8;&#xFF0C;&#x5BF9;&#x7CFB;&#x7EDF;&#x7684;I/O&#x6027;&#x80FD;&#x4F1A;&#x6709;&#x63D0;&#x5347;&#x3002;&#x7EFC;&#x5408;&#x8003;&#x8651;&#x538B;&#x7F29;&#x3001;&#x89E3;&#x538B;&#x901F;&#x5EA6;&#x3001;&#x662F;&#x5426;&#x652F;&#x6301;split&#xFF0C;&#x76EE;&#x524D;lzo&#x662F;&#x6700;&#x597D;&#x7684;&#x9009;&#x62E9;&#x3002;&#x4E0B;&#x9762;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x5728;Cloudera&#x4E2D;&#x5982;&#x4F55;&#x914D;&#x7F6E;lzo&#x3002; &#x624B;&#x5DE5;&#x7F16;&#x8BD1;&#x914D;&#x7F6E;&#x624B;&#x5DE5;&#x5BF9;lzo&#x8FDB;&#x884C;&#x7F16;&#x8BD1;&#x548C;&#x5BF9;&#x96C6;&#x7FA4;&#x8FDB;&#x884C;&#x914D;&#x7F6E;&#x7684;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;Hadoop 2.2.0&#x5B89;&#x88C5;&#x548C;&#x914D;&#x7F6E;lzo&#x3002; Cloudera&#x4E2D;&#x914D;&#x7F6E;&#x6DFB;&#x52A0;parcel&#x6E90;&#xFF0C;&#x4E0B;&#x8F7D;&#xFF0C;&#x5206;&#x914D;&#xFF0C;&#x6FC0;&#x6D3B; &#x5728;cloudera manager&#x4E2D;&#x4FEE;&#x6539;&#x8FDC;&#x7A0B; Parcel &#x5B58;&#x50A8;&#x5E93; URL&#xFF0C;&#x6DFB;&#x52A0;http://archive.cloudera.com/gplextras/parcels/latest&#x3002; &#x5728;&#x4E3B;&#x673A;--Parceltab&#x4E0B;&#xFF0C;&#x70B9;&#x51FB;&#x68C0;&#x67E5;&#x65B0;parcel&#x6309;&#x94AE;&#xFF0C;&#x5DE6;&#x4FA7;&#x7B5B;&#x9009;&#x5668;&#x4F1A;&#x51FA;&#x73B0;HADOOP_LZO&#xFF0C;&#x7136;&#x540E;&#x4E0B;&#x8F7D;&#x3001;&#x5206;&#x914D;&#x3001;&#x6FC0;&#x6D3B;&#x3002;&#x5206;&#x914D;&#x662F;&#x5C06;&#x6B64;parcel&#x5206;&#x53D1;&#x5230;&#x5404;&#x4E2A;&#x673A;&#x5668;&#x4E2D;&#xFF0C;&#x6FC0;&#x6D3B;&#x662F;&#x5728; cloudera/parcels/&#x76EE;&#x5F55;&#x4E0B;&#x5EFA;&#x7ACB;&#x5BF9;&#x76F8;&#x5173;parcel&#x7684;&#x8F6F;&#x94FE;&#x63A5;&#x3002; HDFS&#x914D;&#x7F6E;&#x5728;io.compression.codecs&#x4E2D;&#x6DFB;&#x52A0;com.hadoop.compression.lzo.LzoCodec, com.hadoop.compression.lzo.LzopCodec&#x3002; yarn&#x914D;&#x7F6E; mapreduce.admin.user.env&#x4E2D;&#x6DFB;&#x52A0;hadoop_lzo&#x94FE;&#x63A5;&#xFF1A; /opt/cloudera/parcels/HADOOP_LZO/lib/hadoop/lib/native&#x3002; yarn.app.mapreduce.am.admin.user.env&#x4E2D;&#x6DFB;&#x52A0;hadoop_lzo&#x94FE;&#x63A5;&#xFF1A; /opt/cloudera/parcels/HADOOP_LZO/lib/hadoop/lib/native&#x3002; mapreduce.application.classpath&#x4E2D;&#x6DFB;&#x52A0;hadoop_lzo lib&#xFF1A; /opt/cloudera/parcels/HADOOP_LZO/lib/hadoop/lib/*&#x3002; yarn.application.classpath&#x4E2D;&#x6DFB;&#x52A0;hadoop_lzo lib&#xFF1A; /opt/cloudera/parcels/HADOOP_LZO/lib/hadoop/lib/*&#x3002; oozieoozie libpath&#x4E2D;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x6DFB;&#x52A0;hadoop_lzo.jar&#x3002; &#x5176;&#x4ED6;&#x6A21;&#x5757;&#x5176;&#x4ED6;&#x8DD1;&#x5728;yarn&#x4E2D;&#x7684;&#x670D;&#x52A1;&#xFF0C;&#x53EA;&#x8981;&#x8DDF;&#x968F;&#x96C6;&#x7FA4;&#x91CD;&#x542F;&#x5373;&#x53EF;&#x3002; &#x53C2;&#x8003;&#xFF1A; Hadoop 2.2.0&#x5B89;&#x88C5;&#x548C;&#x914D;&#x7F6E;lzo&#xFF1A;http://www.iteblog.com/archives/992 Cloudera Using the LZO Parcel:http://www.cloudera.com/content/www/en-us/documentation/archive/manager/4-x/4-8-3/Cloudera-Manager-Installation-Guide/cmig_install_LZO_Compression.html &#x53E6;&#x5916;&#x6709;lz4&#x538B;&#x7F29;&#x7B97;&#x6CD5;&#xFF0C;&#x5728;&#x538B;&#x7F29;&#x7387;&#x8FD1;&#x4F3C;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x6548;&#x7387;&#x66F4;&#x9AD8;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x3002;https://code.google.com/p/lz4/ hadoop-lzo.jar&#x548C;hadoop-gpl-compression.jar&#x533A;&#x522B;&#xFF1A;http://guoyunsky.iteye.com/blog/1289475","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"},{"name":"cdh","slug":"cdh","permalink":"http://wzktravel.github.io/tags/cdh/"}]},{"title":"SimpleDateFormat时区和语言环境","slug":"SimpleDateFormat","date":"2015-11-21T14:37:28.000Z","updated":"2016-08-24T07:25:11.000Z","comments":true,"path":"2015/11/21/SimpleDateFormat/","link":"","permalink":"http://wzktravel.github.io/2015/11/21/SimpleDateFormat/","excerpt":"对于类似于”20/Nov/2015:12:59:59 +0800”的字符串，怎么用SimpleDateFormat进行转换？","text":"&#x5BF9;&#x4E8E;&#x7C7B;&#x4F3C;&#x4E8E;&#x201D;20/Nov/2015:12:59:59 +0800&#x201D;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x600E;&#x4E48;&#x7528;SimpleDateFormat&#x8FDB;&#x884C;&#x8F6C;&#x6362;&#xFF1F; &#x6700;&#x8FD1;&#x505A;&#x7684;&#x4E00;&#x4E2A;&#x9879;&#x76EE;&#x4E2D;&#xFF0C;&#x6D89;&#x53CA;&#x5BF9;&#x65E5;&#x5FD7;&#x7684;&#x89E3;&#x6790;&#xFF0C;&#x5176;&#x4E2D;&#x6709;&#x4E2A;&#x5B57;&#x6BB5;&#x662F;&#x65F6;&#x95F4;&#xFF0C;&#x5F62;&#x5982;&#x201D;20/Nov/2015:12:59:59 +0800&#x201D;&#xFF0C;&#x8981;&#x5C06;&#x8FD9;&#x4E2A;&#x5B57;&#x6BB5;&#x8F6C;&#x6362;&#x4E3A;&#x65F6;&#x95F4;&#x6233;&#x3002;&#x5411;&#x666E;&#x901A;&#x7684;&#x201D;2015-11-20 12:59:59&#x201D;&#x81EA;&#x4E0D;&#x5FC5;&#x8BF4;&#x5B83;&#xFF0C;&#x5176;&#x4E2D;&#x201D;+0800&#x201D;&#x662F;&#x65F6;&#x533A;&#x5B57;&#x6BB5;&#xFF0C;&#x7528;Z&#x5373;&#x53EF;&#x3002;&#x4F46;&#x662F;&#x5BF9;&#x4E8E;&#x6708;&#x4EFD;&#x5B57;&#x6BB5;&#xFF0C;&#x5728;java api&#x4E2D;&#x6709;&#x4ECB;&#x7ECD; Month: If the number of pattern letters is 3 or more, the month is interpreted as text; otherwise, it is interpreted as a number. &#x6240;&#x4EE5;&#x6B64;&#x5904;&#x7528;&#x4E09;&#x4E2A;M&#x6765;&#x8868;&#x793A;&#x6708;&#x4EFD;&#xFF0C;&#x603B;&#x4F53;&#x5C31;&#x4F7F;&#x7528;dd/MMM/yyyy:HH:mm:ss Z&#x8FDB;&#x884C;&#x89E3;&#x6790;&#x3002;123String str = &quot;20/Nov/2015:12:59:59 +0800&quot;;SimpleDateFormat df = new SimpleDateFormat(&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;);Date date = df.parse(str); &#x4F46;&#x662F;&#x5B9E;&#x9645;&#x8FC7;&#x7A0B;&#x4E2D;&#x7ADF;&#x7136;&#x62A5;&#x9519;&#xFF1A;12java.text.ParseException: Unparseable date: &quot;20/Nov/2015:12:59:59 +0800&quot; at java.text.DateFormat.parse(DateFormat.java:366) &#x65E0;&#x5948;&#x4E4B;&#x4E0B;&#xFF0C;&#x53EA;&#x80FD;&#x5148;format&#x4E00;&#x4E0B;&#xFF0C;&#x770B;&#x770B;&#x51FA;&#x6765;&#x4EC0;&#x4E48;&#x5185;&#x5BB9;&#x3002;123String str = &quot;20/Nov/2015:12:59:59 +0800&quot;;SimpleDateFormat df = new SimpleDateFormat(&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;);System.out.println(df.format(new Date())); &#x7ED3;&#x679C;&#x662F;121/&#x5341;&#x4E00;&#x6708;/2015:22:54:26 +0800 &#x539F;&#x6765;&#x662F;&#x8BED;&#x8A00;&#x73AF;&#x5883;&#x6CA1;&#x6709;&#x8BBE;&#x7F6E;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x5728;&#x6784;&#x9020;SimpleDateFormat&#x65F6;&#x8BBE;&#x7F6E;locale&#x4E3A;us&#x5373;&#x53EF;&#x3002; SimpleDateFormat(String pattern, Locale locale)Constructs a SimpleDateFormat using the given pattern and the default date format symbols for the given locale. 123String str = &quot;20/Nov/2015:12:59:59 +0800&quot;;SimpleDateFormat df = new SimpleDateFormat(&quot;dd/MMM/yyyy:HH:mm:ss Z&quot;, Locale.US);Date date = df.parse(str); &#x5176;&#x4ED6;&#x4E00;&#x4E9B;pattern&#x548C;&#x793A;&#x4F8B;&#x90FD;&#x53EF;&#x4EE5;&#x53BB;java api&#x5B98;&#x7F51;&#x67E5;&#x770B;&#x3002;http://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"}]},{"title":"java8 lambda","slug":"java8-lambda","date":"2015-09-25T11:04:14.000Z","updated":"2016-08-17T11:33:05.000Z","comments":true,"path":"2015/09/25/java8-lambda/","link":"","permalink":"http://wzktravel.github.io/2015/09/25/java8-lambda/","excerpt":"java8出来很久了，在实际环境中很少用到它的特性。但是对lambda已经神往已久。最后添加IntelliJ IDEA配置修改以保证可以编译。","text":"java8&#x51FA;&#x6765;&#x5F88;&#x4E45;&#x4E86;&#xFF0C;&#x5728;&#x5B9E;&#x9645;&#x73AF;&#x5883;&#x4E2D;&#x5F88;&#x5C11;&#x7528;&#x5230;&#x5B83;&#x7684;&#x7279;&#x6027;&#x3002;&#x4F46;&#x662F;&#x5BF9;lambda&#x5DF2;&#x7ECF;&#x795E;&#x5F80;&#x5DF2;&#x4E45;&#x3002;&#x6700;&#x540E;&#x6DFB;&#x52A0;IntelliJ IDEA&#x914D;&#x7F6E;&#x4FEE;&#x6539;&#x4EE5;&#x4FDD;&#x8BC1;&#x53EF;&#x4EE5;&#x7F16;&#x8BD1;&#x3002; IntelliJ IDEA&#x914D;&#x7F6E; &#x5B89;&#x88C5;1.8&#x7248;&#x672C;&#x7684;jdk &#x4FEE;&#x6539;Preferences-&gt;Build,Execution,Deployment-&gt;Compiler-&gt;Java Compiler&#x4E2D;Per-module bytecode version &#x4FEE;&#x6539;Project Structure-&gt;Project Settings-&gt;Project&#x4E2D;Project SDK&#x548C;Project language level &#x4FEE;&#x6539;Project Structure-&gt;Project Settings-&gt;Module-&gt;Source&#x4E2D;Language level &#x53C2;&#x8003; lambda expressions not supported at this language level","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"}]},{"title":"如何查看Linux中登陆的用户/踢出用户","slug":"linux-kick-user","date":"2015-09-24T11:03:10.000Z","updated":"2016-08-24T07:25:18.000Z","comments":true,"path":"2015/09/24/linux-kick-user/","link":"","permalink":"http://wzktravel.github.io/2015/09/24/linux-kick-user/","excerpt":"介绍如何查看登陆用户，踢出用户。","text":"&#x4ECB;&#x7ECD;&#x5982;&#x4F55;&#x67E5;&#x770B;&#x767B;&#x9646;&#x7528;&#x6237;&#xFF0C;&#x8E22;&#x51FA;&#x7528;&#x6237;&#x3002; &#x67E5;&#x770B;&#x767B;&#x9646;&#x7684;&#x7528;&#x6237;who&#x547D;&#x4EE4;123456$ who -H&#x540D;&#x79F0; &#x7EBF;&#x8DEF; &#x65F6;&#x95F4; &#x5907;&#x6CE8;root pts/2 2014-12-04 14:19 (192.168.0.12)root pts/4 2014-12-04 14:29 (192.168.0.12)webfront pts/11 2015-09-18 16:41 (192.168.0.51)webfront pts/13 2015-09-24 10:04 (192.168.0.231) &#x8BF4;&#x660E;&#xFF1A; &#x7B2C;&#x4E00;&#x5217;&#x662F;&#x7528;&#x6237;&#x540D;&#x3002; &#x7B2C;&#x4E8C;&#x5217;&#x662F;&#x8FDE;&#x63A5;&#x7684;&#x7EC8;&#x7AEF;,tty&#x8868;&#x793A;&#x663E;&#x793A;&#x5668;,pts&#x8868;&#x793A;&#x8FDC;&#x7A0B;&#x8FDE;&#x63A5;&#x3002; &#x7B2C;&#x4E09;&#x5217;&#x662F;&#x767B;&#x9646;&#x65F6;&#x95F4;&#x3002; -H&#xFF1A;&#x663E;&#x793A;&#x6807;&#x9898;&#x680F;, -T&#xFF1A;&#x663E;&#x793A;&#x7528;&#x6237;&#x662F;&#x5426;&#x613F;&#x610F;&#x63A5;&#x53D7;&#x5176;&#x4ED6;&#x7528;&#x6237;&#x4FE1;&#x606F; &#x67E5;&#x770B;&#x7528;&#x6237;&#x767B;&#x9646;&#x64CD;&#x4F5C;&#x884C;&#x4E3A;&#x547D;&#x4EE4;w&#x547D;&#x4EE4;1234567$ w 19:09:59 up 594 days, 1:15, 4 users, load average: 0.07, 0.04, 0.01USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/2 192.168.0.12 04Dec14 145days 0.14s 0.14s -bashroot pts/4 192.168.0.12 04Dec14 17days 2days 4.38s -bashwebfront pts/11 192.168.0.51 18Sep15 6days 0.11s 0.11s -bashwebfront pts/13 192.168.0.231 10:04 0.00s 1.52s 0.00s w &#x8BF4;&#x660E;&#xFF1A; &#x7B2C;&#x4E00;&#x884C;&#x663E;&#x793A;&#x7CFB;&#x7EDF;&#x7684;&#x6C47;&#x603B;&#x4FE1;&#x606F;&#xFF0C;&#x5B57;&#x6BB5;&#x5206;&#x522B;&#x8868;&#x793A;&#x7CFB;&#x7EDF;&#x5F53;&#x524D;&#x65F6;&#x95F4;&#xFF0C;&#x7CFB;&#x7EDF;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF0C;&#x5F53;&#x524D;&#x7CFB;&#x7EDF;&#x767B;&#x9646;&#x7528;&#x6237;&#x603B;&#x6570;users&#xFF0C;&#x7CFB;&#x7EDF;&#x5E73;&#x5747;&#x8D1F;&#x8F7D;&#x4FE1;&#x606F;LOAD AVERAGE &#xFF08;&#x540E;&#x9762;&#x7684;&#x6570;&#x5B57;&#x8868;&#x793A;&#x7CFB;&#x7EDF;&#x5728;&#x8FC7;&#x53BB;1&#xFF0C;5&#xFF0C;10&#x5206;&#x949F;&#x5185;&#x7684;&#x8D1F;&#x8F7D;&#x7A0B;&#x5EA6;&#xFF0C;&#x6570;&#x503C;&#x8D8A;&#x5C0F;&#xFF0C;&#x7CFB;&#x7EDF;&#x8D1F;&#x8F7D;&#x8D8A;&#x8F7B;&#xFF09;&#x3002; &#x4ECE;&#x7B2C;&#x4E8C;&#x884C;&#x5F00;&#x59CB;&#x6784;&#x6210;&#x4E00;&#x4E2A;&#x8868;&#x683C;&#xFF0C;&#x5171;&#x6709;8&#x4E2A;&#x680F;&#x76EE;&#xFF0C;&#x5206;&#x522B;&#x663E;&#x793A;&#x5404;&#x4E2A;&#x7528;&#x6237;&#x6B63;&#x5728;&#x505A;&#x7684;&#x4E8B;&#x60C5;&#x53CA;&#x8BE5;&#x7528;&#x6237;&#x6240;&#x5360;&#x7528;&#x7684;&#x7CFB;&#x7EDF;&#x8D44;&#x6599;&#x3002; USER&#xFF1A;&#x663E;&#x793A;&#x767B;&#x9646;&#x7528;&#x6237;&#x5E10;&#x53F7;&#x540D;&#x3002;&#x7528;&#x6237;&#x91CD;&#x590D;&#x767B;&#x9646;&#xFF0C;&#x8BE5;&#x5E10;&#x53F7;&#x4E5F;&#x4F1A;&#x91CD;&#x590D;&#x51FA;&#x73B0;&#x3002; TTY&#xFF1A;&#x7528;&#x6237;&#x767B;&#x9646;&#x6240;&#x7528;&#x7684;&#x7EC8;&#x7AEF;&#xFF0C;tty&#x8868;&#x793A;&#x663E;&#x793A;&#x5668;,pts&#x8868;&#x793A;&#x8FDC;&#x7A0B;&#x8FDE;&#x63A5;&#x3002; FROM&#xFF1A;&#x663E;&#x793A;&#x7528;&#x6237;&#x5728;&#x4F55;&#x5904;&#x767B;&#x9646;&#x7CFB;&#x7EDF;&#x3002; LOGIN@&#xFF1A;&#x662F;LOGIN AT&#x7684;&#x610F;&#x601D;&#xFF0C;&#x8868;&#x793A;&#x767B;&#x9646;&#x8FDB;&#x5165;&#x7CFB;&#x7EDF;&#x7684;&#x65F6;&#x95F4;&#x3002; IDLE&#xFF1A;&#x7528;&#x6237;&#x7A7A;&#x95F2;&#x65F6;&#x95F4;&#xFF0C;&#x4ECE;&#x7528;&#x6237;&#x4E0A;&#x4E00;&#x6B21;&#x4EFB;&#x52A1;&#x7ED3;&#x675F;&#x540E;&#xFF0C;&#x5F00;&#x59CB;&#x8BB0;&#x65F6;&#x3002; JCPU&#xFF1A;&#x4E00;&#x7EC8;&#x7AEF;&#x4EE3;&#x53F7;&#x6765;&#x533A;&#x5206;&#xFF0C;&#x8868;&#x793A;&#x5728;&#x67D0;&#x6BB5;&#x65F6;&#x95F4;&#x5185;&#xFF0C;&#x6240;&#x6709;&#x4E0E;&#x8BE5;&#x7EC8;&#x7AEF;&#x76F8;&#x5173;&#x7684;&#x8FDB;&#x7A0B;&#x4EFB;&#x52A1;&#x6240;&#x8017;&#x8D39;&#x7684;CPU&#x65F6;&#x95F4;&#x3002; PCPU&#xFF1A;&#x6307;WHAT&#x57DF;&#x7684;&#x4EFB;&#x52A1;&#x6267;&#x884C;&#x540E;&#x8017;&#x8D39;&#x7684;CPU&#x65F6;&#x95F4;&#x3002; WHAT&#xFF1A;&#x8868;&#x793A;&#x5F53;&#x524D;&#x6267;&#x884C;&#x7684;&#x4EFB;&#x52A1; &#x67E5;&#x770B;&#x67D0;&#x7528;&#x6237;&#x767B;&#x9646;&#x4FE1;&#x606F;w {&#x7528;&#x6237;&#x540D;}: &#x5F53;&#x767B;&#x9646;&#x7CFB;&#x7EDF;&#x7528;&#x6237;&#x5F88;&#x591A;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;W&#x540E;&#x9762;&#x52A0;&#x4E0A;&#x67D0;&#x4E2A;&#x7528;&#x6237;&#x540D;&#xFF0C;&#x5219;&#x4F1A;&#x67E5;&#x770B;&#x8BE5;&#x7528;&#x6237;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x7684;&#x60C5;&#x51B5;12345$ w webfront19:13:52 up 594 days, 1:19, 4 users, load average: 0.00, 0.01, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATwebfront pts/11 192.168.0.51 18Sep15 6days 0.11s 0.11s -bashwebfront pts/13 192.168.0.231 10:04 0.00s 1.52s 0.00s w webfront &#x67E5;&#x770B;&#x767B;&#x9646;&#x7528;&#x6237;&#x5386;&#x53F2;last&#x547D;&#x4EE4;12345678$ last -n 5webfront pts/0 192.168.0.231 Thu Sep 24 10:21 - 10:22 (00:00) webfront pts/13 192.168.0.231 Thu Sep 24 10:04 still logged in webfront pts/13 192.168.0.172 Mon Sep 21 19:26 - 13:16 (17:49) webfront pts/12 192.168.0.231 Mon Sep 21 17:35 - 10:20 (2+16:44) webfront pts/11 192.168.0.251 Fri Sep 18 16:41 still logged in wtmp begins Wed Nov 21 09:42:45 2012 &#x4E5F;&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x6307;&#x5B9A;&#x7528;&#x6237;&#x767B;&#x5F55;&#x5386;&#x53F2;: last {&#x7528;&#x6237;&#x540D;}123456$ last webfront -n 5webfront pts/0 192.168.0.231 Thu Sep 24 10:21 - 10:22 (00:00) webfront pts/13 192.168.0.231 Thu Sep 24 10:04 still logged in webfront pts/13 192.168.0.172 Mon Sep 21 19:26 - 13:16 (17:49) webfront pts/12 192.168.0.231 Mon Sep 21 17:35 - 10:20 (2+16:44) webfront pts/11 192.168.0.251 Fri Sep 18 16:41 still logged in &#x8E22;&#x51FA;&#x7528;&#x6237;&#x4F7F;&#x7528;pkill pkill -u webfront &#x6839;&#x636E;&#x7528;&#x6237;&#x8E22;&#x51FA;&#x6240;&#x7528;&#x767B;&#x9646;&#x8FDB;&#x7A0B;(&#x614E;&#x7528;&#xFF01;&#xFF01;&#x8FD9;&#x4E2A;&#x7528;&#x6237;&#x7684;&#x6240;&#x6709;&#x64CD;&#x4F5C;&#x90FD;&#x5C06;&#x7ACB;&#x5373;&#x622A;&#x6B62;&#x5E76;&#x4E0D;&#x4FDD;&#x5B58;&#x3002;) pkill -kill -t pts/0 &#x6839;&#x636E;tty&#x8E22;&#x51FA;&#x7528;&#x6237;&#x8FDB;&#x7A0B; &#x4F7F;&#x7528;killps aux | grep {tty}, &#x627E;&#x5230;&#x5BF9;&#x5E94;shell&#x7684;pid&#xFF0C;&#x7136;&#x540E;kill -9 {pid}","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"linux awk命令","slug":"linux-awk","date":"2015-09-20T16:03:13.000Z","updated":"2016-08-24T07:25:15.000Z","comments":true,"path":"2015/09/21/linux-awk/","link":"","permalink":"http://wzktravel.github.io/2015/09/21/linux-awk/","excerpt":"相对于sed常常作用于一整行进行处理，awk更倾向与一行当中分成数个“栏位”来处理。平时对日志或者小型文件进行处理时，awk很有用。","text":"&#x76F8;&#x5BF9;&#x4E8E;sed&#x5E38;&#x5E38;&#x4F5C;&#x7528;&#x4E8E;&#x4E00;&#x6574;&#x884C;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;awk&#x66F4;&#x503E;&#x5411;&#x4E0E;&#x4E00;&#x884C;&#x5F53;&#x4E2D;&#x5206;&#x6210;&#x6570;&#x4E2A;&#x201C;&#x680F;&#x4F4D;&#x201D;&#x6765;&#x5904;&#x7406;&#x3002;&#x5E73;&#x65F6;&#x5BF9;&#x65E5;&#x5FD7;&#x6216;&#x8005;&#x5C0F;&#x578B;&#x6587;&#x4EF6;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x65F6;&#xFF0C;awk&#x5F88;&#x6709;&#x7528;&#x3002; &#x547D;&#x4EE4;&#x884C;&#x683C;&#x5F0F;1awk &apos;pattern {action} pattern {action} ...&apos; {filenames} pattern&#x8868;&#x793A;awk&#x5728;&#x6570;&#x636E;&#x4E2D;&#x67E5;&#x627E;&#x7684;&#x5185;&#x5BB9;&#xFF0C;action&#x662F;&#x5728;&#x627E;&#x5230;&#x5339;&#x914D;&#x5185;&#x5BB9;&#x65F6;&#x6240;&#x6267;&#x884C;&#x7684;&#x547D;&#x4EE4;&#x3002; awk&#x9ED8;&#x8BA4;&#x7684;&#x5206;&#x9694;&#x7B26;&#x662F;&#x7A7A;&#x683C;&#x6216;tab&#xFF0C;&#x7531;&#x5206;&#x9694;&#x7B26;&#x5206;&#x9694;&#x5F00;&#x7684;&#x6BCF;&#x4E00;&#x9879;&#x79F0;&#x4E3A;&#x57DF;&#x3002; awk&#x4E5F;&#x53EF;&#x4EE5;&#x8C03;&#x7528;awk&#x811A;&#x672C;&#x6267;&#x884C;&#x547D;&#x4EE4;, awk -f awk_script file(s)&#x3002; awk&#x57FA;&#x672C;&#x7528;&#x6CD5;&#x5206;&#x9694;&#x7B26;12345678910111213~ head -n 5 /etc/passwdroot:x:0:0:root:/root:/bin/zshbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin~~ head -n 5 /etc/passwd | awk -F &apos;:&apos; &apos;{print $1&quot;\\t&quot;$7}&apos;root /bin/zshbin /sbin/nologindaemon /sbin/nologinadm /sbin/nologinlp /sbin/nologin -F&#x6307;&#x5B9A;&#x4E86;&#x5206;&#x9694;&#x7B26;&#x4E3A;&#x201D;:&#x201D;&#xFF0C;&#x7136;&#x540E;&#x6253;&#x5370;&#x51FA;&#x4E86;&#x7B2C;&#x4E00;&#x4E2A;&#x57DF;&#x4E2D;&#x5185;&#x5BB9;&#x3002;awk&#x5DE5;&#x4F5C;&#x6D41;&#x7A0B;&#x662F;&#x8FD9;&#x6837;&#x7684;&#xFF1A;&#x8BFB;&#x5165;&#x6709;&#x2019;\\n&#x2019;&#x6362;&#x884C;&#x7B26;&#x5206;&#x5272;&#x7684;&#x4E00;&#x6761;&#x8BB0;&#x5F55;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x8BB0;&#x5F55;&#x6309;&#x6307;&#x5B9A;&#x7684;&#x57DF;&#x5206;&#x9694;&#x7B26;&#x5212;&#x5206;&#x57DF;&#xFF0C;&#x586B;&#x5145;&#x57DF;&#xFF0C;$0&#x5219;&#x8868;&#x793A;&#x6240;&#x6709;&#x57DF;, $1&#x8868;&#x793A;&#x7B2C;&#x4E00;&#x4E2A;&#x57DF;,$n&#x8868;&#x793A;&#x7B2C;n&#x4E2A;&#x57DF;&#x3002;&#x9ED8;&#x8BA4;&#x57DF;&#x5206;&#x9694;&#x7B26;&#x662F;&#x201D;&#x7A7A;&#x767D;&#x952E;&#x201D; &#x6216; &#x201C;[tab]&#x952E;&#x201D;&#xFF0C;$1&#x4EE3;&#x8868;&#x7684;&#x5C31;&#x662F;&#x7528;&#x6237;&#x540D;&#xFF0C;$7&#x4EE3;&#x8868;&#x7684;&#x662F;&#x7528;&#x6237;&#x767B;&#x5F55;&#x4F7F;&#x7528;&#x7684;shell&#x3002; BEGIN/END12345678~ head -n 5 /etc/passwd | awk -F &apos;:&apos; &apos;BEGIN {print &quot;name\\tshell&quot;} {print $1&quot;\\t&quot;$7} END {print &quot;blue\\t/bin/nosh&quot;}&apos;name shellroot /bin/zshbin /sbin/nologindaemon /sbin/nologinadm /sbin/nologinlp /sbin/nologinblue /bin/nosh &#x5148;&#x6267;&#x884C;BEGIN&#x64CD;&#x4F5C;&#xFF0C;&#x7136;&#x540E;&#x8BFB;&#x53D6;&#x6587;&#x4EF6;&#xFF0C;&#x5BF9;&#x6BCF;&#x4E00;&#x884C;&#x8FDB;&#x884C;&#x5206;&#x5272;&#xFF0C;&#x6267;&#x884C;action&#xFF0C;&#x6240;&#x6709;&#x884C;&#x6267;&#x884C;&#x5B8C;&#x6BD5;&#x540E;&#xFF0C;&#x6267;&#x884C;END&#x64CD;&#x4F5C;&#x3002; &#x4F7F;&#x7528;pattern12345~ head -n 5 /etc/passwd | awk -F &quot;:&quot; &apos;/root/&apos;root:x:0:0:root:/root:/bin/zsh~~ head -n 5 /etc/passwd | awk -F &quot;:&quot; &apos;/root/{print $7}&apos;/bin/zsh &#x53EA;&#x6709;&#x5339;&#x914D;&#x5230;&#x6307;&#x5B9A;pattern&#x7684;&#x884C;&#x624D;&#x4F1A;&#x6267;&#x884C;action&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;action&#xFF0C;&#x6253;&#x5370;&#x6B64;&#x884C;&#x5185;&#x5BB9;&#x3002; awk&#x5185;&#x7F6E;&#x53D8;&#x91CF; &#x53D8;&#x91CF; &#x8BF4;&#x660E; ARGC &#x547D;&#x4EE4;&#x884C;&#x53C2;&#x6570;&#x4E2A;&#x6570; ARGV &#x547D;&#x4EE4;&#x884C;&#x53C2;&#x6570;&#x6392;&#x5217; ENVIRON &#x652F;&#x6301;&#x961F;&#x5217;&#x4E2D;&#x7CFB;&#x7EDF;&#x73AF;&#x5883;&#x53D8;&#x91CF;&#x7684;&#x4F7F;&#x7528; FILENAME awk&#x6D4F;&#x89C8;&#x7684;&#x6587;&#x4EF6;&#x540D; FNR &#x5DF2;&#x8BFB;&#x5F53;&#x524D;&#x6587;&#x4EF6;&#x7684;&#x8BB0;&#x5F55;&#x6570; FS &#x8BBE;&#x7F6E;&#x8F93;&#x5165;&#x57DF;&#x5206;&#x9694;&#x7B26;&#xFF0C;&#x7B49;&#x4EF7;&#x4E8E;&#x547D;&#x4EE4;&#x884C; -F&#x9009;&#x9879; NF &#x6D4F;&#x89C8;&#x8BB0;&#x5F55;&#x7684;&#x57DF;&#x7684;&#x4E2A;&#x6570; NR &#x5DF2;&#x8BFB;&#x7684;&#x8BB0;&#x5F55;&#x6570; OFS &#x8F93;&#x51FA;&#x57DF;&#x5206;&#x9694;&#x7B26; ORS &#x8F93;&#x51FA;&#x8BB0;&#x5F55;&#x5206;&#x9694;&#x7B26; RS &#x63A7;&#x5236;&#x8BB0;&#x5F55;&#x5206;&#x9694;&#x7B26; &#x793A;&#x4F8B;&#xFF1A;&#x7EDF;&#x8BA1;/etc/passwd:&#x6587;&#x4EF6;&#x540D;&#xFF0C;&#x6BCF;&#x884C;&#x7684;&#x884C;&#x53F7;&#xFF0C;&#x6BCF;&#x884C;&#x7684;&#x5217;&#x6570;&#xFF0C;&#x5BF9;&#x5E94;&#x7684;&#x5B8C;&#x6574;&#x884C;&#x5185;&#x5BB9;123456~ awk -F &quot;:&quot; &apos;{printf(&quot;file:%10s, line:%s, columns:%s, content:%s\\n&quot;, FILENAME, NR, NF, $0)}&apos; /etc/passwd | head -n 5file:/etc/passwd, line:1, columns:7, content:root:x:0:0:root:/root:/bin/zshfile:/etc/passwd, line:2, columns:7, content:bin:x:1:1:bin:/bin:/sbin/nologinfile:/etc/passwd, line:3, columns:7, content:daemon:x:2:2:daemon:/sbin:/sbin/nologinfile:/etc/passwd, line:4, columns:7, content:adm:x:3:4:adm:/var/adm:/sbin/nologinfile:/etc/passwd, line:5, columns:7, content:lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin awk&#x6D41;&#x7A0B;&#x63A7;&#x5236;&#x6761;&#x4EF6;&#x5224;&#x65AD;(if) &#x7528;&#x6CD5;&#xFF1A;if(&#x8868;&#x8FBE;&#x5F0F;) {&#x8BED;&#x53E5;1} else if(&#x8868;&#x8FBE;&#x5F0F;) {&#x8BED;&#x53E5;2} else {&#x8BED;&#x53E5;3} &#x793A;&#x4F8B;&#xFF1A;1234567~ awk &apos;BEGIN { test=100; if (test &gt; 90) {print &quot;Very good!&quot;;} else if (test &gt; 60) {print &quot;good&quot;;} else {print &quot;shit&quot;;} }&apos; Very good! &#x5FAA;&#x73AF;(while,for,do)while&#x5FAA;&#x73AF; &#x7528;&#x6CD5;&#xFF1A; while(&#x8868;&#x8FBE;&#x5F0F;) {&#x8BED;&#x53E5;} &#x793A;&#x4F8B;&#xFF1A; 12345~ awk &apos;BEGIN { while (i &lt; 10) {i+=1} print i }&apos; 10 for&#x5FAA;&#x73AF; &#x7528;&#x6CD5;1&#xFF1A; for(&#x53D8;&#x91CF; in &#x6570;&#x7EC4;){&#x8BED;&#x53E5;} &#x7528;&#x6CD5;2&#xFF1A; for(&#x53D8;&#x91CF;;&#x6761;&#x4EF6;;&#x8868;&#x8FBE;&#x5F0F;){&#x8BED;&#x53E5;} &#x793A;&#x4F8B;&#xFF1A;12345678910111213141516~ awk &apos;BEGIN { for (a in ENVIRON) {print a&quot;=&quot;ENVIRON[a]} }&apos; HBASE_IDENT_STRING=rootMAIL=/var/spool/mail/rootLOADEDMODULES=NVM_IOJS_ORG_MIRROR=https://iojs.org/distNVM_RC_VERSION=ERRDATE=20150921....~ awk &apos;BEGIN { for (i = 0; i &lt;= 100; i++) {a+=i} print a }&apos;5050 do&#x5FAA;&#x73AF; &#x7528;&#x6CD5;&#xFF1A;do{&#x8BED;&#x53E5;}while(&#x6761;&#x4EF6;) &#x793A;&#x4F8B;&#xFF1A;12345~ awk &apos;BEGIN { do {a+=i;i++;} while(i&lt;=100) print a }&apos;5050 &#x5176;&#x4ED6;&#x63A7;&#x5236;&#x8BED;&#x53E5; &#x8BED;&#x53E5; &#x8BF4;&#x660E; break &#x5F53; break &#x8BED;&#x53E5;&#x7528;&#x4E8E; while &#x6216; for &#x8BED;&#x53E5;&#x65F6;&#xFF0C;&#x5BFC;&#x81F4;&#x9000;&#x51FA;&#x7A0B;&#x5E8F;&#x5FAA;&#x73AF;&#x3002; continue &#x5F53; continue &#x8BED;&#x53E5;&#x7528;&#x4E8E; while &#x6216; for &#x8BED;&#x53E5;&#x65F6;&#xFF0C;&#x4F7F;&#x7A0B;&#x5E8F;&#x5FAA;&#x73AF;&#x79FB;&#x52A8;&#x5230;&#x4E0B;&#x4E00;&#x4E2A;&#x8FED;&#x4EE3;&#x3002; next &#x80FD;&#x80FD;&#x591F;&#x5BFC;&#x81F4;&#x8BFB;&#x5165;&#x4E0B;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x884C;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x5230;&#x811A;&#x672C;&#x7684;&#x9876;&#x90E8;&#x3002;&#x8FD9;&#x53EF;&#x4EE5;&#x907F;&#x514D;&#x5BF9;&#x5F53;&#x524D;&#x8F93;&#x5165;&#x884C;&#x6267;&#x884C;&#x5176;&#x4ED6;&#x7684;&#x64CD;&#x4F5C;&#x8FC7;&#x7A0B;&#x3002; exit &#x8BED;&#x53E5;&#x4F7F;&#x4E3B;&#x8F93;&#x5165;&#x5FAA;&#x73AF;&#x9000;&#x51FA;&#x5E76;&#x5C06;&#x63A7;&#x5236;&#x8F6C;&#x79FB;&#x5230;END,&#x5982;&#x679C;END&#x5B58;&#x5728;&#x7684;&#x8BDD;&#x3002;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x5B9A;&#x4E49;END&#x89C4;&#x5219;&#xFF0C;&#x6216;&#x5728;END&#x4E2D;&#x5E94;&#x7528;exit&#x8BED;&#x53E5;&#xFF0C;&#x5219;&#x7EC8;&#x6B62;&#x811A;&#x672C;&#x7684;&#x6267;&#x884C;&#x3002; &#x5185;&#x7F6E;&#x51FD;&#x6570;&#x7B97;&#x672F;&#x51FD;&#x6570; &#x51FD;&#x6570;&#x540D; &#x8BF4;&#x660E; atan2(y, x) &#x8FD4;&#x56DE; y/x &#x7684;&#x53CD;&#x6B63;&#x5207;&#x3002; cos(x) &#x8FD4;&#x56DE; x &#x7684;&#x4F59;&#x5F26;&#xFF1B;x &#x662F;&#x5F27;&#x5EA6;&#x3002; sin(x) &#x8FD4;&#x56DE; x &#x7684;&#x6B63;&#x5F26;&#xFF1B;x &#x662F;&#x5F27;&#x5EA6;&#x3002; exp(x) &#x8FD4;&#x56DE; x &#x5E42;&#x51FD;&#x6570;&#x3002; log(x) &#x8FD4;&#x56DE; x &#x7684;&#x81EA;&#x7136;&#x5BF9;&#x6570;&#x3002; sqrt(x) &#x8FD4;&#x56DE; x &#x5E73;&#x65B9;&#x6839;&#x3002; int(x) &#x8FD4;&#x56DE; x &#x7684;&#x622A;&#x65AD;&#x81F3;&#x6574;&#x6570;&#x7684;&#x503C;&#x3002; rand() &#x8FD4;&#x56DE;&#x4EFB;&#x610F;&#x6570;&#x5B57; n&#xFF0C;&#x5176;&#x4E2D; 0 &lt;= n &lt; 1&#x3002; srand([Expr]) &#x5C06; rand &#x51FD;&#x6570;&#x7684;&#x79CD;&#x5B50;&#x503C;&#x8BBE;&#x7F6E;&#x4E3A; Expr &#x53C2;&#x6570;&#x7684;&#x503C;&#xFF0C;&#x6216;&#x5982;&#x679C;&#x7701;&#x7565; Expr &#x53C2;&#x6570;&#x5219;&#x4F7F;&#x7528;&#x67D0;&#x5929;&#x7684;&#x65F6;&#x95F4;&#x3002;&#x8FD4;&#x56DE;&#x5148;&#x524D;&#x7684;&#x79CD;&#x5B50;&#x503C;&#x3002; &#x5B57;&#x7B26;&#x4E32;&#x51FD;&#x6570; &#x51FD;&#x6570;&#x540D; &#x8BF4;&#x660E; gsub(Ere, Repl, [In]) &#x9664;&#x4E86;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x6240;&#x6709;&#x5177;&#x4F53;&#x503C;&#x88AB;&#x66FF;&#x4EE3;&#x8FD9;&#x70B9;&#xFF0C;&#x5B83;&#x548C; sub &#x51FD;&#x6570;&#x5B8C;&#x5168;&#x4E00;&#x6837;&#x5730;&#x6267;&#x884C;&#xFF0C;&#x3002; sub(Ere, Repl, [In]) &#x7528; Repl &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x66FF;&#x6362; In &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x7684;&#x7531; Ere &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x6269;&#x5C55;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x5177;&#x4F53;&#x503C;&#x3002;sub &#x51FD;&#x6570;&#x8FD4;&#x56DE;&#x66FF;&#x6362;&#x7684;&#x6570;&#x91CF;&#x3002;&#x51FA;&#x73B0;&#x5728; Repl &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x7684; &amp;&#xFF08;&#x548C;&#x7B26;&#x53F7;&#xFF09;&#x7531; In &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x4E0E; Ere &#x53C2;&#x6570;&#x7684;&#x6307;&#x5B9A;&#x7684;&#x6269;&#x5C55;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x5339;&#x914D;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x66FF;&#x6362;&#x3002;&#x5982;&#x679C;&#x672A;&#x6307;&#x5B9A; In &#x53C2;&#x6570;&#xFF0C;&#x7F3A;&#x7701;&#x503C;&#x662F;&#x6574;&#x4E2A;&#x8BB0;&#x5F55;&#xFF08;$0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#xFF09;&#x3002; index(String1, String2) &#x5728;&#x7531; String1 &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF08;&#x5176;&#x4E2D;&#x6709;&#x51FA;&#x73B0; String2 &#x6307;&#x5B9A;&#x7684;&#x53C2;&#x6570;&#xFF09;&#x4E2D;&#xFF0C;&#x8FD4;&#x56DE;&#x4F4D;&#x7F6E;&#xFF0C;&#x4ECE; 1 &#x5F00;&#x59CB;&#x7F16;&#x53F7;&#x3002;&#x5982;&#x679C; String2 &#x53C2;&#x6570;&#x4E0D;&#x5728; String1 &#x53C2;&#x6570;&#x4E2D;&#x51FA;&#x73B0;&#xFF0C;&#x5219;&#x8FD4;&#x56DE; 0&#xFF08;&#x96F6;&#xFF09;&#x3002; length [(String)] &#x8FD4;&#x56DE; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x7684;&#x957F;&#x5EA6;&#xFF08;&#x5B57;&#x7B26;&#x5F62;&#x5F0F;&#xFF09;&#x3002;&#x5982;&#x679C;&#x672A;&#x7ED9;&#x51FA; String &#x53C2;&#x6570;&#xFF0C;&#x5219;&#x8FD4;&#x56DE;&#x6574;&#x4E2A;&#x8BB0;&#x5F55;&#x7684;&#x957F;&#x5EA6;&#xFF08;$0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#xFF09;&#x3002; blength [(String)] &#x8FD4;&#x56DE; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x7684;&#x957F;&#x5EA6;&#xFF08;&#x4EE5;&#x5B57;&#x8282;&#x4E3A;&#x5355;&#x4F4D;&#xFF09;&#x3002;&#x5982;&#x679C;&#x672A;&#x7ED9;&#x51FA; String &#x53C2;&#x6570;&#xFF0C;&#x5219;&#x8FD4;&#x56DE;&#x6574;&#x4E2A;&#x8BB0;&#x5F55;&#x7684;&#x957F;&#x5EA6;&#xFF08;$0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#xFF09;&#x3002; substr(String, M, [N]) &#x8FD4;&#x56DE;&#x5177;&#x6709; N &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x6570;&#x91CF;&#x5B50;&#x4E32;&#x3002;&#x5B50;&#x4E32;&#x4ECE; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x53D6;&#x5F97;&#xFF0C;&#x5176;&#x5B57;&#x7B26;&#x4EE5; M &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x4F4D;&#x7F6E;&#x5F00;&#x59CB;&#x3002;M &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x4E3A;&#x5C06; String &#x53C2;&#x6570;&#x4E2D;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4F5C;&#x4E3A;&#x7F16;&#x53F7; 1&#x3002;&#x5982;&#x679C;&#x672A;&#x6307;&#x5B9A; N &#x53C2;&#x6570;&#xFF0C;&#x5219;&#x5B50;&#x4E32;&#x7684;&#x957F;&#x5EA6;&#x5C06;&#x662F; M &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x4F4D;&#x7F6E;&#x5230; String &#x53C2;&#x6570;&#x7684;&#x672B;&#x5C3E; &#x7684;&#x957F;&#x5EA6;&#x3002; match(String, Ere) &#x5728; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF08;Ere &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x6269;&#x5C55;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x51FA;&#x73B0;&#x5728;&#x5176;&#x4E2D;&#xFF09;&#x4E2D;&#x8FD4;&#x56DE;&#x4F4D;&#x7F6E;&#xFF08;&#x5B57;&#x7B26;&#x5F62;&#x5F0F;&#xFF09;&#xFF0C;&#x4ECE; 1 &#x5F00;&#x59CB;&#x7F16;&#x53F7;&#xFF0C;&#x6216;&#x5982;&#x679C; Ere &#x53C2;&#x6570;&#x4E0D;&#x51FA;&#x73B0;&#xFF0C;&#x5219;&#x8FD4;&#x56DE; 0&#xFF08;&#x96F6;&#xFF09;&#x3002;RSTART &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x8FD4;&#x56DE;&#x503C;&#x3002;RLENGTH &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x5339;&#x914D;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x7684;&#x957F;&#x5EA6;&#xFF0C;&#x6216;&#x5982;&#x679C;&#x672A;&#x627E;&#x5230;&#x4EFB;&#x4F55;&#x5339;&#x914D;&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;&#x4E3A; -1&#xFF08;&#x8D1F;&#x4E00;&#xFF09;&#x3002; split(String, A, [Ere]) &#x5C06; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x53C2;&#x6570;&#x5206;&#x5272;&#x4E3A;&#x6570;&#x7EC4;&#x5143;&#x7D20; A[1], A[2], . . ., A[n]&#xFF0C;&#x5E76;&#x8FD4;&#x56DE; n &#x53D8;&#x91CF;&#x7684;&#x503C;&#x3002;&#x6B64;&#x5206;&#x9694;&#x53EF;&#x4EE5;&#x901A;&#x8FC7; Ere &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x6269;&#x5C55;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x8FDB;&#x884C;&#xFF0C;&#x6216;&#x7528;&#x5F53;&#x524D;&#x5B57;&#x6BB5;&#x5206;&#x9694;&#x7B26;&#xFF08;FS &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#xFF09;&#x6765;&#x8FDB;&#x884C;&#xFF08;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x7ED9;&#x51FA; Ere &#x53C2;&#x6570;&#xFF09;&#x3002;&#x9664;&#x975E;&#x4E0A;&#x4E0B;&#x6587;&#x6307;&#x660E;&#x7279;&#x5B9A;&#x7684;&#x5143;&#x7D20;&#x8FD8;&#x5E94;&#x5177;&#x6709;&#x4E00;&#x4E2A;&#x6570;&#x5B57;&#x503C;&#xFF0C;&#x5426;&#x5219; A &#x6570;&#x7EC4;&#x4E2D;&#x7684;&#x5143;&#x7D20;&#x7528;&#x5B57;&#x7B26;&#x4E32;&#x503C;&#x6765;&#x521B;&#x5EFA;&#x3002; tolower(String) &#x8FD4;&#x56DE; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x6BCF;&#x4E2A;&#x5927;&#x5199;&#x5B57;&#x7B26;&#x5C06;&#x66F4;&#x6539;&#x4E3A;&#x5C0F;&#x5199;&#x3002;&#x5927;&#x5199;&#x548C;&#x5C0F;&#x5199;&#x7684;&#x6620;&#x5C04;&#x7531;&#x5F53;&#x524D;&#x8BED;&#x8A00;&#x73AF;&#x5883;&#x7684; LC_CTYPE &#x8303;&#x7574;&#x5B9A;&#x4E49;&#x3002; toupper(String) &#x8FD4;&#x56DE; String &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x6BCF;&#x4E2A;&#x5C0F;&#x5199;&#x5B57;&#x7B26;&#x5C06;&#x66F4;&#x6539;&#x4E3A;&#x5927;&#x5199;&#x3002;&#x5927;&#x5199;&#x548C;&#x5C0F;&#x5199;&#x7684;&#x6620;&#x5C04;&#x7531;&#x5F53;&#x524D;&#x8BED;&#x8A00;&#x73AF;&#x5883;&#x7684; LC_CTYPE &#x8303;&#x7574;&#x5B9A;&#x4E49;&#x3002; printf(Format, Expr, Expr, &#x2026;) &#x6839;&#x636E; Format &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684; printf &#x5B50;&#x4F8B;&#x7A0B;&#x683C;&#x5F0F;&#x5B57;&#x7B26;&#x4E32;&#x6765;&#x683C;&#x5F0F;&#x5316; Expr &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x8868;&#x8FBE;&#x5F0F;&#x5E76;&#x8FD4;&#x56DE;&#x6700;&#x540E;&#x751F;&#x6210;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x3002; printf&#x683C;&#x5F0F; &#x683C;&#x5F0F;&#x7B26; &#x8BF4;&#x660E; %d &#x5341;&#x8FDB;&#x5236;&#x6709;&#x7B26;&#x53F7;&#x6574;&#x6570; %u &#x5341;&#x8FDB;&#x5236;&#x65E0;&#x7B26;&#x53F7;&#x6574;&#x6570; %f &#x6D6E;&#x70B9;&#x6570; %s &#x5B57;&#x7B26;&#x4E32; %c &#x5355;&#x4E2A;&#x5B57;&#x7B26; %p &#x6307;&#x9488;&#x7684;&#x503C; %e &#x6307;&#x6570;&#x5F62;&#x5F0F;&#x7684;&#x6D6E;&#x70B9;&#x6570; %x %X &#x65E0;&#x7B26;&#x53F7;&#x4EE5;&#x5341;&#x516D;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x6574;&#x6570; %o &#x65E0;&#x7B26;&#x53F7;&#x4EE5;&#x516B;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x6574;&#x6570; %g &#x81EA;&#x52A8;&#x9009;&#x62E9;&#x5408;&#x9002;&#x7684;&#x8868;&#x793A;&#x6CD5; &#x4E00;&#x822C;&#x51FD;&#x6570; &#x51FD;&#x6570; &#x8BF4;&#x660E; close(Expression) &#x7528;&#x540C;&#x4E00;&#x4E2A;&#x5E26;&#x5B57;&#x7B26;&#x4E32;&#x503C;&#x7684; Expression &#x53C2;&#x6570;&#x6765;&#x5173;&#x95ED;&#x7531; print &#x6216; printf &#x8BED;&#x53E5;&#x6253;&#x5F00;&#x7684;&#x6216;&#x8C03;&#x7528; getline &#x51FD;&#x6570;&#x6253;&#x5F00;&#x7684;&#x6587;&#x4EF6;&#x6216;&#x7BA1;&#x9053;&#x3002;&#x5982;&#x679C;&#x6587;&#x4EF6;&#x6216;&#x7BA1;&#x9053;&#x6210;&#x529F;&#x5173;&#x95ED;&#xFF0C;&#x5219;&#x8FD4;&#x56DE; 0&#xFF1B;&#x5176;&#x5B83;&#x60C5;&#x51B5;&#x4E0B;&#x8FD4;&#x56DE;&#x975E;&#x96F6;&#x503C;&#x3002;&#x5982;&#x679C;&#x6253;&#x7B97;&#x5199;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#xFF0C;&#x5E76;&#x7A0D;&#x540E;&#x5728;&#x540C;&#x4E00;&#x4E2A;&#x7A0B;&#x5E8F;&#x4E2D;&#x8BFB;&#x53D6;&#x6587;&#x4EF6;&#xFF0C;&#x5219; close &#x8BED;&#x53E5;&#x662F;&#x5FC5;&#x9700;&#x7684;&#x3002; system(Command) &#x6267;&#x884C; Command &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x547D;&#x4EE4;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x9000;&#x51FA;&#x72B6;&#x6001;&#x3002;&#x7B49;&#x540C;&#x4E8E; system &#x5B50;&#x4F8B;&#x7A0B;&#x3002; getline[Variable] &#x4ECE;&#x6765;&#x81EA; Expression &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#x4E2D;&#x901A;&#x8FC7;&#x7BA1;&#x9053;&#x4F20;&#x9001;&#x7684;&#x6D41;&#x4E2D;&#x8BFB;&#x53D6;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x8BB0;&#x5F55;&#xFF0C;&#x5E76;&#x5C06;&#x8BE5;&#x8BB0;&#x5F55;&#x7684;&#x503C;&#x6307;&#x5B9A;&#x7ED9; Variable &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x53D8;&#x91CF;&#x3002;&#x5982;&#x679C;&#x5F53;&#x524D;&#x672A;&#x6253;&#x5F00;&#x5C06; Expression &#x53C2;&#x6570;&#x7684;&#x503C;&#x4F5C;&#x4E3A;&#x5176;&#x547D;&#x4EE4;&#x540D;&#x79F0;&#x7684;&#x6D41;&#xFF0C;&#x5219;&#x521B;&#x5EFA;&#x6D41;&#x3002;&#x521B;&#x5EFA;&#x7684;&#x6D41;&#x7B49;&#x540C;&#x4E8E;&#x8C03;&#x7528; popen &#x5B50;&#x4F8B;&#x7A0B;&#xFF0C;&#x6B64;&#x65F6; Command &#x53C2;&#x6570;&#x53D6; Expression &#x53C2;&#x6570;&#x7684;&#x503C;&#x4E14; Mode &#x53C2;&#x6570;&#x8BBE;&#x7F6E;&#x4E3A;&#x4E00;&#x4E2A;&#x662F; r &#x7684;&#x503C;&#x3002;&#x53EA;&#x8981;&#x6D41;&#x4FDD;&#x7559;&#x6253;&#x5F00;&#x4E14; Expression &#x53C2;&#x6570;&#x6C42;&#x5F97;&#x540C;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5219;&#x5BF9; getline &#x51FD;&#x6570;&#x7684;&#x6BCF;&#x6B21;&#x540E;&#x7EED;&#x8C03;&#x7528;&#x8BFB;&#x53D6;&#x53E6;&#x4E00;&#x4E2A;&#x8BB0;&#x5F55;&#x3002;&#x5982;&#x679C;&#x672A;&#x6307;&#x5B9A; Variable &#x53C2;&#x6570;&#xFF0C;&#x5219; $0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#x548C; NF &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x4ECE;&#x6D41;&#x8BFB;&#x53D6;&#x7684;&#x8BB0;&#x5F55;&#x3002; getline[Variable] &lt; Expression &#x4ECE; Expression &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x6587;&#x4EF6;&#x8BFB;&#x53D6;&#x8F93;&#x5165;&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8BB0;&#x5F55;&#xFF0C;&#x5E76;&#x5C06; Variable &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x8BE5;&#x8BB0;&#x5F55;&#x7684;&#x503C;&#x3002;&#x53EA;&#x8981;&#x6D41;&#x4FDD;&#x7559;&#x6253;&#x5F00;&#x4E14; Expression &#x53C2;&#x6570;&#x5BF9;&#x540C;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#x6C42;&#x503C;&#xFF0C;&#x5219;&#x5BF9; getline &#x51FD;&#x6570;&#x7684;&#x6BCF;&#x6B21;&#x540E;&#x7EED;&#x8C03;&#x7528;&#x8BFB;&#x53D6;&#x53E6;&#x4E00;&#x4E2A;&#x8BB0;&#x5F55;&#x3002;&#x5982;&#x679C;&#x672A;&#x6307;&#x5B9A; Variable &#x53C2;&#x6570;&#xFF0C;&#x5219; $0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#x548C; NF &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x4ECE;&#x6D41;&#x8BFB;&#x53D6;&#x7684;&#x8BB0;&#x5F55;&#x3002; getline[Variable] &#x5C06; Variable &#x53C2;&#x6570;&#x6307;&#x5B9A;&#x7684;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x4ECE;&#x5F53;&#x524D;&#x8F93;&#x5165;&#x6587;&#x4EF6;&#x8BFB;&#x53D6;&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x8BB0;&#x5F55;&#x3002;&#x5982;&#x679C;&#x672A;&#x6307;&#x5B9A; Variable &#x53C2;&#x6570;&#xFF0C;&#x5219; $0 &#x8BB0;&#x5F55;&#x53D8;&#x91CF;&#x8BBE;&#x7F6E;&#x4E3A;&#x8BE5;&#x8BB0;&#x5F55;&#x7684;&#x503C;&#xFF0C;&#x8FD8;&#x5C06;&#x8BBE;&#x7F6E; NF&#x3001;NR &#x548C; FNR &#x7279;&#x6B8A;&#x53D8;&#x91CF;&#x3002; &#x65F6;&#x95F4;&#x51FD;&#x6570; &#x51FD;&#x6570;&#x540D; &#x8BF4;&#x660E; mktime( YYYY MM DD HH MM SS[ DST]) &#x751F;&#x6210;&#x65F6;&#x95F4;&#x683C;&#x5F0F; strftime([format [, timestamp]]) &#x683C;&#x5F0F;&#x5316;&#x65F6;&#x95F4;&#x8F93;&#x51FA;&#xFF0C;&#x5C06;&#x65F6;&#x95F4;&#x6233;&#x8F6C;&#x4E3A;&#x65F6;&#x95F4;&#x5B57;&#x7B26;&#x4E32; systime() &#x5F97;&#x5230;&#x65F6;&#x95F4;&#x6233;,&#x8FD4;&#x56DE;&#x4ECE;1970&#x5E74;1&#x6708;1&#x65E5;&#x5F00;&#x59CB;&#x5230;&#x5F53;&#x524D;&#x65F6;&#x95F4;(&#x4E0D;&#x8BA1;&#x95F0;&#x5E74;)&#x7684;&#x6574;&#x79D2;&#x6570; strftime&#x8F93;&#x51FA;&#x683C;&#x5F0F; &#x683C;&#x5F0F; &#x63CF;&#x8FF0; %a &#x661F;&#x671F;&#x51E0;&#x7684;&#x7F29;&#x5199;(Sun) %A &#x661F;&#x671F;&#x51E0;&#x7684;&#x5B8C;&#x6574;&#x5199;&#x6CD5;(Sunday) %b &#x6708;&#x540D;&#x7684;&#x7F29;&#x5199;(Oct) %B &#x6708;&#x540D;&#x7684;&#x5B8C;&#x6574;&#x5199;&#x6CD5;(October) %c &#x672C;&#x5730;&#x65E5;&#x671F;&#x548C;&#x65F6;&#x95F4; %d &#x5341;&#x8FDB;&#x5236;&#x65E5;&#x671F; %D &#x65E5;&#x671F; 08/20/99 %e &#x65E5;&#x671F;&#xFF0C;&#x5982;&#x679C;&#x53EA;&#x6709;&#x4E00;&#x4F4D;&#x4F1A;&#x8865;&#x4E0A;&#x4E00;&#x4E2A;&#x7A7A;&#x683C; %H &#x7528;&#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;24&#x5C0F;&#x65F6;&#x683C;&#x5F0F;&#x7684;&#x5C0F;&#x65F6; %I &#x7528;&#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;12&#x5C0F;&#x65F6;&#x683C;&#x5F0F;&#x7684;&#x5C0F;&#x65F6; %j &#x4ECE;1&#x6708;1&#x65E5;&#x8D77;&#x4E00;&#x5E74;&#x4E2D;&#x7684;&#x7B2C;&#x51E0;&#x5929; %m &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x6708;&#x4EFD; %M &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x5206;&#x949F; %p 12&#x5C0F;&#x65F6;&#x8868;&#x793A;&#x6CD5;(AM/PM) %S &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x79D2; %U &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x4E00;&#x5E74;&#x4E2D;&#x7684;&#x7B2C;&#x51E0;&#x4E2A;&#x661F;&#x671F;(&#x661F;&#x671F;&#x5929;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x661F;&#x671F;&#x7684;&#x5F00;&#x59CB;) %w &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x661F;&#x671F;&#x51E0;(&#x661F;&#x671F;&#x5929;&#x662F;0) %W &#x5341;&#x8FDB;&#x5236;&#x8868;&#x793A;&#x7684;&#x4E00;&#x5E74;&#x4E2D;&#x7684;&#x7B2C;&#x51E0;&#x4E2A;&#x661F;&#x671F;(&#x661F;&#x671F;&#x4E00;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x661F;&#x671F;&#x7684;&#x5F00;&#x59CB;) %x &#x91CD;&#x65B0;&#x8BBE;&#x7F6E;&#x672C;&#x5730;&#x65E5;&#x671F;(08/20/99) %X &#x91CD;&#x65B0;&#x8BBE;&#x7F6E;&#x672C;&#x5730;&#x65F6;&#x95F4;(12&#xFF1A;00&#xFF1A;00) %y &#x4E24;&#x4F4D;&#x6570;&#x5B57;&#x8868;&#x793A;&#x7684;&#x5E74;(15) %Y &#x5B8C;&#x6574;&#x8868;&#x793A;&#x7684;&#x5E74;(2015) %Z &#x65F6;&#x533A;(PDT) %% &#x767E;&#x5206;&#x53F7;(%) &#x793A;&#x4F8B; gsub/sub&#xFF0C;&#x5C06;&#x8FDE;&#x7EED;&#x7684;&#x6570;&#x5B57;&#x66FF;&#x6362;&#x4E3A;&#x201D;!&#x201D; 12~ awk &apos;BEGIN {a=&quot;test2015&quot;; gsub(/[0-9]+/, &quot;!&quot;, a); print a}&apos;test! index&#xFF0C;&#x67E5;&#x627E;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x662F;&#x5426;&#x5B58;&#x5728;&#x201D;t2&#x201D;&#x5B50;&#x4E32; 12~ awk &apos;BEGIN {a=&quot;test2015&quot;; b = index(a, &quot;t2&quot;); print b ? &quot;found&quot; : &quot;not found&quot;;}&apos;found match, &#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x5339;&#x914D;&#x67E5;&#x627E; 12~ awk &apos;BEGIN {a=&quot;test2015&quot;; b = match(a, /[0-9]+/); print b ? &quot;found&quot; : &quot;not found&quot;; }&apos; found substr, &#x5B57;&#x7B26;&#x4E32;&#x622A;&#x53D6;&#xFF0C;&#x4ECE;&#x7B2C;2&#x4E2A;&#x5B57;&#x7B26;&#x5F00;&#x59CB;&#x622A;&#x53D6;4&#x4E2A;&#x5B57;&#x7B26; 12~ awk &apos;BEGIN {a=&quot;test2015&quot;; print substr(a, 2, 4); }&apos; est2 split, &#x5B57;&#x7B26;&#x4E32;&#x5206;&#x5272; 1234~ awk &apos;BEGIN {a=&quot;test2015&quot;; split(a, b, &quot;t2&quot;); print length(b); for (i in b) {print b[i]} }&apos; 2tes015 printf, &#x683C;&#x5F0F;&#x5316;&#x8F93;&#x51FA; 12~ awk &apos;BEGIN{n1=124.113; n2=-1.224; n3=1.2345; printf(&quot;%.2f, %.2u, %.2g, %X, %o\\n&quot;,n1,n2,n3,n1,n1);}&apos;124.11, 18446744073709551615, 1.2, 7C, 174 printf, &#x5341;&#x516D;&#x8FDB;&#x5236;&#x8F6C;&#x5341;&#x8FDB;&#x5236; 1~ echo &quot;1509d314690&quot; | awk &apos;{print strtonum(&quot;0x&quot;$0)}&apos; strftime, &#x683C;&#x5F0F;&#x5316;&#x65F6;&#x95F4;&#x8F93;&#x51FA; 123~ gawk &apos;BEGIN{tstamp=mktime(&quot;2015 01 01 12 12 12&quot;); print tstamp; print strftime(&quot;%Y-%m-%d&quot;, tstamp);}&apos; 14200855322015-01-01 &#x5B9E;&#x8DF5;&#x51FA;&#x771F;&#x77E5; &#x6839;&#x636E;&#x6587;&#x4EF6;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x7EDF;&#x8BA1; 12~ awk -F &apos;\\t&apos; &apos;{w[$1]+=1} END{for (a in w) printf(&quot;%u\\t%s\\n&quot;, w[a], a)}&apos;~ awk -F &apos;\\t&apos; &apos;{w[$2]+=$1} END{for (a in w) printf(&quot;%u\\t%s\\n&quot;, w[a], a)}&apos; &#x5C06;&#x591A;&#x4E2A;&#x6587;&#x4EF6;&#x5185;&#x5BB9;&#x5408;&#x5E76;&#x5230;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;(&#x4E0D;&#x6539;&#x53D8;&#x683C;&#x5F0F;) 1awk &apos;{v=FILENAME}!a[v]++1&apos; *.sort &gt; all.sort awk&#x4F7F;&#x7528;shell&#x53D8;&#x91CF;&#xFF0C;&#x9700;&#x8981;&#x52A0;&#x4E0A;&#x5355;&#x5F15;&#x53F7;&#x3002;&apos;${var}&apos; &#x53C2;&#x8003; The GNU Awk User&#x2019;s Guide Awk &#x547D;&#x4EE4;&#x5B66;&#x4E60;&#x603B;&#x7ED3;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"linux sed命令","slug":"linux-sed","date":"2015-09-19T15:53:30.000Z","updated":"2016-08-24T07:25:19.000Z","comments":true,"path":"2015/09/19/linux-sed/","link":"","permalink":"http://wzktravel.github.io/2015/09/19/linux-sed/","excerpt":"sed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作。我一般喜欢使用awk来处理文件，如果遇到需要进行替换的，会使用sed处理。","text":"sed&#x662F;&#x4E00;&#x4E2A;&#x5F88;&#x597D;&#x7684;&#x6587;&#x4EF6;&#x5904;&#x7406;&#x5DE5;&#x5177;&#xFF0C;&#x672C;&#x8EAB;&#x662F;&#x4E00;&#x4E2A;&#x7BA1;&#x9053;&#x547D;&#x4EE4;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x4EE5;&#x884C;&#x4E3A;&#x5355;&#x4F4D;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;&#x6570;&#x636E;&#x884C;&#x8FDB;&#x884C;&#x66FF;&#x6362;&#x3001;&#x5220;&#x9664;&#x3001;&#x65B0;&#x589E;&#x3001;&#x9009;&#x53D6;&#x7B49;&#x7279;&#x5B9A;&#x5DE5;&#x4F5C;&#x3002;&#x6211;&#x4E00;&#x822C;&#x559C;&#x6B22;&#x4F7F;&#x7528;awk&#x6765;&#x5904;&#x7406;&#x6587;&#x4EF6;&#xFF0C;&#x5982;&#x679C;&#x9047;&#x5230;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x66FF;&#x6362;&#x7684;&#xFF0C;&#x4F1A;&#x4F7F;&#x7528;sed&#x5904;&#x7406;&#x3002; &#x547D;&#x4EE4;&#x884C;&#x683C;&#x5F0F;12sed [-Ealn] command [file ...]sed [-Ealn] [-e command] [-f command_file] [-i extension] [file ...] &#x9009;&#x9879;&#x4E0E;&#x53C2;&#x6570;&#xFF1A;-n : &#x4F7F;&#x7528;&#x5B89;&#x9759;(silent)&#x6A21;&#x5F0F;&#x3002;&#x5728;&#x4E00;&#x822C; sed &#x7684;&#x7528;&#x6CD5;&#x4E2D;&#xFF0C;&#x6240;&#x6709;&#x6765;&#x81EA; STDIN &#x7684;&#x6570;&#x636E;&#x4E00;&#x822C;&#x90FD;&#x4F1A;&#x88AB;&#x5217;&#x51FA;&#x5230;&#x8424;&#x5E55;&#x4E0A;&#x3002;&#x4F46;&#x5982;&#x679C;&#x52A0;&#x4E0A; -n &#x53C2;&#x6570;&#x540E;&#xFF0C;&#x5219;&#x53EA;&#x6709;&#x7ECF;&#x8FC7;sed &#x7279;&#x6B8A;&#x5904;&#x7406;&#x7684;&#x90A3;&#x4E00;&#x884C;(&#x6216;&#x8005;&#x52A8;&#x4F5C;)&#x624D;&#x4F1A;&#x88AB;&#x5217;&#x51FA;&#x6765;&#x3002;-e : &#x76F4;&#x63A5;&#x5728;&#x547D;&#x4EE4;&#x5217;&#x6A21;&#x5F0F;&#x4E0A;&#x8FDB;&#x884C; sed &#x7684;&#x52A8;&#x4F5C;&#x7F16;&#x8F91;&#xFF1B;-f : &#x76F4;&#x63A5;&#x5C06; sed &#x7684;&#x52A8;&#x4F5C;&#x5199;&#x5728;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x5185;&#xFF0C; -f filename &#x5219;&#x53EF;&#x4EE5;&#x8FD0;&#x884C; filename &#x5185;&#x7684; sed &#x52A8;&#x4F5C;&#xFF1B;-r : sed &#x7684;&#x52A8;&#x4F5C;&#x652F;&#x6301;&#x7684;&#x662F;&#x5EF6;&#x4F38;&#x578B;&#x6B63;&#x89C4;&#x8868;&#x793A;&#x6CD5;&#x7684;&#x8BED;&#x6CD5;&#x3002;(&#x9ED8;&#x8BA4;&#x662F;&#x57FA;&#x7840;&#x6B63;&#x89C4;&#x8868;&#x793A;&#x6CD5;&#x8BED;&#x6CD5;)-i : &#x76F4;&#x63A5;&#x4FEE;&#x6539;&#x8BFB;&#x53D6;&#x7684;&#x6587;&#x4EF6;&#x5185;&#x5BB9;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x7531;&#x8424;&#x5E55;&#x8F93;&#x51FA;&#x3002; &#x52A8;&#x4F5C;&#x8BF4;&#x660E;&#xFF1A; [n1[,n2]]functionn1, n2 : &#x4E0D;&#x89C1;&#x5F97;&#x4F1A;&#x5B58;&#x5728;&#xFF0C;&#x4E00;&#x822C;&#x4EE3;&#x8868;&#x300E;&#x9009;&#x62E9;&#x8FDB;&#x884C;&#x52A8;&#x4F5C;&#x7684;&#x884C;&#x6570;&#x300F;&#xFF0C;&#x4E3E;&#x4F8B;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x6211;&#x7684;&#x52A8;&#x4F5C;&#x662F;&#x9700;&#x8981;&#x5728; 10 &#x5230; 20 &#x884C;&#x4E4B;&#x95F4;&#x8FDB;&#x884C;&#x7684;&#xFF0C;&#x5219;&#x300E; 10,20[&#x52A8;&#x4F5C;&#x884C;&#x4E3A;] &#x300F; commond&#xFF1A;a : &#x65B0;&#x589E;&#xFF0C;a &#x7684;&#x540E;&#x9762;&#x53EF;&#x4EE5;&#x63A5;&#x5B57;&#x4E32;&#xFF0C;&#x800C;&#x8FD9;&#x4E9B;&#x5B57;&#x4E32;&#x4F1A;&#x5728;&#x65B0;&#x7684;&#x4E00;&#x884C;&#x51FA;&#x73B0;(&#x76EE;&#x524D;&#x7684;&#x4E0B;&#x4E00;&#x884C;)&#xFF5E;c : &#x53D6;&#x4EE3;&#xFF0C;c &#x7684;&#x540E;&#x9762;&#x53EF;&#x4EE5;&#x63A5;&#x5B57;&#x4E32;&#xFF0C;&#x8FD9;&#x4E9B;&#x5B57;&#x4E32;&#x53EF;&#x4EE5;&#x53D6;&#x4EE3; n1,n2 &#x4E4B;&#x95F4;&#x7684;&#x884C;&#xFF01;d : &#x5220;&#x9664;&#xFF0C;d &#x540E;&#x9762;&#x901A;&#x5E38;&#x4E0D;&#x63A5;&#x4EFB;&#x4F55;&#x4E1C;&#x897F;&#xFF1B;i : &#x63D2;&#x5165;&#xFF0C;i &#x7684;&#x540E;&#x9762;&#x53EF;&#x4EE5;&#x63A5;&#x5B57;&#x4E32;&#xFF0C;&#x800C;&#x8FD9;&#x4E9B;&#x5B57;&#x4E32;&#x4F1A;&#x5728;&#x65B0;&#x7684;&#x4E00;&#x884C;&#x51FA;&#x73B0;(&#x76EE;&#x524D;&#x7684;&#x4E0A;&#x4E00;&#x884C;)&#xFF1B;p : &#x5217;&#x5370;&#xFF0C;&#x4EA6;&#x5373;&#x5C06;&#x67D0;&#x4E2A;&#x9009;&#x62E9;&#x7684;&#x6570;&#x636E;&#x5370;&#x51FA;&#x3002;&#x901A;&#x5E38; p &#x4F1A;&#x4E0E;&#x53C2;&#x6570; sed -n &#x4E00;&#x8D77;&#x8FD0;&#x884C;&#xFF5E;s : &#x53D6;&#x4EE3;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x8FDB;&#x884C;&#x53D6;&#x4EE3;&#x7684;&#x5DE5;&#x4F5C;&#x54E9;&#xFF01;&#x901A;&#x5E38;&#x8FD9;&#x4E2A; s &#x7684;&#x52A8;&#x4F5C;&#x53EF;&#x4EE5;&#x642D;&#x914D;&#x6B63;&#x89C4;&#x8868;&#x793A;&#x6CD5;&#xFF01;&#x4F8B;&#x5982; 1,20s/old/new/g &#x4EE5;&#x884C;&#x4E3A;&#x5355;&#x4F4D;&#x5220;&#x9664;&#x5C06; /etc/passwd &#x7684;&#x5185;&#x5BB9;&#x5217;&#x51FA;&#x5E76;&#x4E14;&#x5217;&#x5370;&#x884C;&#x53F7;&#xFF0C;&#x540C;&#x65F6;&#xFF0C;&#x5C06;&#x7B2C; 2~5 &#x884C;&#x5220;&#x9664;&#xFF01;1234567~ nl /etc/passwd | head -10 | sed &apos;2,5d&apos; 1 root:x:0:0:root:/root:/bin/zsh 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown 8 halt:x:7:0:halt:/sbin:/sbin/halt 9 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin10 uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin nl&#x547D;&#x4EE4;&#x7C7B;&#x4F3C;&#x4E8E;cat&#xFF0C;&#x4F46;&#x662F;&#x53EF;&#x4EE5;&#x6253;&#x5370;&#x51FA;&#x884C;&#x53F7; &#x5982;&#x679C;&#x53EA;&#x5220;&#x9664;&#x4E00;&#x884C; sed &apos;2d&apos;&#x5373;&#x53EF; &#x5982;&#x679C;&#x5220;&#x9664;&#x5230;&#x6700;&#x540E;&#x4E00;&#x884C;&#xFF0C;sed &apos;2,$d&#x3002; &#x4EE5;&#x884C;&#x4E3A;&#x5355;&#x4F4D;&#x65B0;&#x589E;&#x5728;&#x7B2C;&#x4E8C;&#x884C;&#x540E;(&#x4EA6;&#x5373;&#x662F;&#x52A0;&#x5728;&#x7B2C;&#x4E09;&#x884C;)&#x52A0;&#x4E0A;&#x300E;drink tea?&#x300F;&#x5B57;&#x6837;&#xFF01;1234567 ~ nl /etc/passwd | head -5 | sed &apos;2a &quot;drink tea?&quot;&apos; 1 root:x:0:0:root:/root:/bin/zsh 2 bin:x:1:1:bin:/bin:/sbin/nologin&quot;drink tea?&quot; 3 daemon:x:2:2:daemon:/sbin:/sbin/nologin 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin &#x5728;&#x7B2C;&#x4E8C;&#x884C;&#x524D;&#x5462;&#xFF1F;nl /etc/passwd | head -5 | sed &apos;2i &quot;drink tea?&quot;&apos;&#xFF0C;&#x662F;&#x4E0D;&#x662F;&#x548C;vim&#x4E2D;i,a&#x7C7B;&#x4F3C;&#xFF1F; &#x5982;&#x679C;&#x6DFB;&#x52A0;&#x591A;&#x884C;&#x5462;&#xFF1F;&#x5728;&#x4EE5;&#x6BCF;&#x4E00;&#x884C;&#x4E4B;&#x95F4;&#x52A0;\\n&#x5373;&#x53EF;&#x3002; &#x4EE5;&#x884C;&#x4E3A;&#x5355;&#x4F4D;&#x53D6;&#x4EE3;&#x5C06;&#x7B2C;2-5&#x884C;&#x7684;&#x5185;&#x5BB9;&#x53D6;&#x4EE3;&#x6210;&#x4E3A;&#x300E;No 2-3 line&#x300F;12345 ~ nl /etc/passwd | head -5 | sed &apos;2,3c No 2-3 line&apos; 1 root:x:0:0:root:/root:/bin/zshNo 2-3 line 4 adm:x:3:4:adm:/var/adm:/sbin/nologin 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin &#x4EE5;&#x884C;&#x4E3A;&#x5355;&#x4F4D;&#x663E;&#x793A;&#x4EC5;&#x5217;&#x51FA; /etc/passwd &#x6587;&#x4EF6;&#x5185;&#x7684;&#x7B2C; 5-7 &#x884C;1234~ nl /etc/passwd | sed -n &apos;5,7p&apos; 5 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 6 sync:x:5:0:sync:/sbin:/bin/sync 7 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown &#x4E0A;&#x8FF0;&#x7684;&#x547D;&#x4EE4;&#x4E2D;&#x6709;&#x4E2A;&#x91CD;&#x8981;&#x7684;&#x9009;&#x9879;&#x300E; -n &#x300F;&#xFF0C;&#x6309;&#x7167;&#x8BF4;&#x660E;&#x6587;&#x4EF6;&#xFF0C;&#x8FD9;&#x4E2A; -n &#x4EE3;&#x8868;&#x7684;&#x662F;&#x300E;&#x5B89;&#x9759;&#x6A21;&#x5F0F;&#x300F;&#xFF01; &#x90A3;&#x4E48;&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x4F7F;&#x7528;&#x5B89;&#x9759;&#x6A21;&#x5F0F;&#x5462;&#xFF1F;&#x4F60;&#x53EF;&#x4EE5;&#x81EA;&#x884C;&#x4E0B;&#x8FBE; sed &apos;5,7p&apos; &#x5C31;&#x77E5;&#x9053;&#x4E86; (5-7 &#x884C;&#x4F1A;&#x91CD;&#x590D;&#x8F93;&#x51FA;)&#xFF01;&#x4F46;&#x5982;&#x679C;&#x52A0;&#x4E0A; -n &#x53C2;&#x6570;&#x540E;&#xFF0C;&#x5219;&#x53EA;&#x6709;&#x7ECF;&#x8FC7;sed &#x7279;&#x6B8A;&#x5904;&#x7406;&#x7684;&#x90A3;&#x4E00;&#x884C;(&#x6216;&#x8005;&#x52A8;&#x4F5C;)&#x624D;&#x4F1A;&#x88AB;&#x5217;&#x51FA;&#x6765;&#x3002; &#x90E8;&#x5206;&#x6570;&#x636E;&#x7684;&#x641C;&#x5BFB;&#x5E76;&#x53D6;&#x4EE3;&#x7684;&#x529F;&#x80FD;1sed &apos;s/&#x8981;&#x88AB;&#x53D6;&#x4EE3;&#x7684;&#x5B57;&#x4E32;/&#x65B0;&#x7684;&#x5B57;&#x4E32;/g&apos; &#x793A;&#x4F8B;&#x4E00;: &#x53D6;&#x5F97;ifconfig en0&#x4E2D;ip&#x5730;&#x5740;1234 ~ ifconfig en0 | fgrep inet | fgrep netmask inet 192.168.31.166 netmask 0xffffff00 broadcast 192.168.31.255 ~ ifconfig en0 | fgrep inet | fgrep netmask | sed &apos;s/inet //g&apos; | sed &apos;s/ netmask.*$//g&apos;192.168.31.166 &#x5176;&#x5B9E;&#x5C31;&#x662F;&#x7ECF;&#x8FC7;&#x4E24;&#x6B21;sed&#x66FF;&#x6362;&#xFF0C;&#x5C06;inet&#x548C;netmask&#x4E4B;&#x540E;&#x7684;&#x5B57;&#x7B26;&#x90FD;&#x66FF;&#x6362;&#x4E3A;&#x7A7A;&#x4E32; &#x627E;&#x5230;/etc/man.conf&#x4E2D;&#xFF0C;&#x6240;&#x6709;&#x5E26;&#x201D;MAN&#x201D;&#x5E76;&#x4E14;&#x4E0D;&#x662F;&#x4EE5;&#x201D;#&#x201D;&#x5F00;&#x5934;&#x7684;&#x884C; 123456~ cat /etc/man.conf | fgrep &quot;MAN&quot; | sed &apos;s/#.*$//g&apos; | sed &apos;/^$/d&apos; | tail -5MANPATH_MAP /usr/local/sbin /usr/local/share/manMANPATH_MAP /usr/X11/bin /usr/X11/manMANPATH_MAP /usr/bin/X11 /usr/X11/manMANPATH_MAP /usr/bin/mh /usr/share/manMANSECT 1:1p:8:2:3:3p:4:5:6:7:9:0p:tcl:n:l:p:o &#x9996;&#x5148;&#x5C06;&#x5E26;&#x201D;MAN&#x201D;&#x7684;&#x884C;&#x8FC7;&#x6EE4;&#x51FA;&#x6765;&#xFF0C;&#x7136;&#x540E;sed &apos;s/#.*$//g&apos;&#x5C06;&#x201D;#&#x201D;&#x5F00;&#x5934;&#x7684;&#x884C;&#x53D8;&#x6210;&#x7A7A;&#x884C;&#xFF0C;&#x6700;&#x540E;sed &apos;/^$/d&apos;&#x5220;&#x9664;&#x7A7A;&#x884C; &#x627E;&#x5230;pid&#x4E3A;23975&#x7684;pstree&#x4E2D;&#x6240;&#x6709;Pid12~ pstree -p 23975 | sed &apos;s/(/\\n(/g&apos; | grep &apos;(&apos; | sed &apos;s/(\\(.*\\))/\\1/g&apos; | tr &quot;\\n&quot; &quot; &quot;23975-+-nginx 30180 30181 30182 30183 30184 30185 30186 30187 30188---{nginx} 30189 &#x76F4;&#x63A5;&#x4FEE;&#x6539;&#x6587;&#x4EF6;(&#x614E;&#x7528;!) &#x5C06;sed.log&#x4E2D;&#x7B2C;2&#x884C;&#x672B;&#x5C3E;&#x7684;.&#x66FF;&#x6362;&#x4E3A;! 123456789~ cat sed.logHello world.Holy shit.~ sed -i &apos;2s/\\.$/!/g&apos; sed.log ~ cat sed.logHello world.Holy shit! &#x5728;sed.log&#x6700;&#x540E;&#x4E00;&#x884C;&#x63D2;&#x5165;&#x201D;#This is a test&#x201D; 12345~ sed -i &apos;$a #This is a test&apos; sed.log~ cat sed.logHello world.Holy shit!#This is a test sed &#x7684;&#x300E; -i &#x300F;&#x9009;&#x9879;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4FEE;&#x6539;&#x6587;&#x4EF6;&#x5185;&#x5BB9;&#xFF0C;&#x8FD9;&#x529F;&#x80FD;&#x975E;&#x5E38;&#x6709;&#x5E2E;&#x52A9;&#xFF01;&#x4E3E;&#x4F8B;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x6709;&#x4E00;&#x4E2A; 100 &#x4E07;&#x884C;&#x7684;&#x6587;&#x4EF6;&#xFF0C;&#x4F60;&#x8981;&#x5728;&#x7B2C; 100 &#x884C;&#x52A0;&#x67D0;&#x4E9B;&#x6587;&#x5B57;&#xFF0C;&#x6B64;&#x65F6;&#x4F7F;&#x7528; vim &#x53EF;&#x80FD;&#x4F1A;&#x75AF;&#x6389;&#xFF01;&#x56E0;&#x4E3A;&#x6587;&#x4EF6;&#x592A;&#x5927;&#x4E86;&#xFF01;&#x90A3;&#x600E;&#x529E;&#xFF1F;&#x4F7F;&#x7528;sed&#x80FD;&#x5F88;&#x597D;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x3002;&#x900F;&#x8FC7; sed &#x76F4;&#x63A5;&#x4FEE;&#x6539;/&#x53D6;&#x4EE3;&#x7684;&#x529F;&#x80FD;&#xFF0C;&#x4F60;&#x751A;&#x81F3;&#x4E0D;&#x9700;&#x8981;&#x4F7F;&#x7528; vim &#x53BB;&#x4FEE;&#x8BA2;&#xFF01;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"java多线程中的Queue","slug":"java-queue","date":"2015-09-14T15:02:37.000Z","updated":"2016-08-24T07:22:52.000Z","comments":true,"path":"2015/09/14/java-queue/","link":"","permalink":"http://wzktravel.github.io/2015/09/14/java-queue/","excerpt":"在Java多线程中，队列的使用率很高，很多生产者消费者模型的首选数据结构就是队列。Java提供的线程安全的Queue可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，今天也主要说一下这两个队列。之后可能会说一下Atomic家族，先备忘。","text":"&#x5728;Java&#x591A;&#x7EBF;&#x7A0B;&#x4E2D;&#xFF0C;&#x961F;&#x5217;&#x7684;&#x4F7F;&#x7528;&#x7387;&#x5F88;&#x9AD8;&#xFF0C;&#x5F88;&#x591A;&#x751F;&#x4EA7;&#x8005;&#x6D88;&#x8D39;&#x8005;&#x6A21;&#x578B;&#x7684;&#x9996;&#x9009;&#x6570;&#x636E;&#x7ED3;&#x6784;&#x5C31;&#x662F;&#x961F;&#x5217;&#x3002;Java&#x63D0;&#x4F9B;&#x7684;&#x7EBF;&#x7A0B;&#x5B89;&#x5168;&#x7684;Queue&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x963B;&#x585E;&#x961F;&#x5217;&#x548C;&#x975E;&#x963B;&#x585E;&#x961F;&#x5217;&#xFF0C;&#x5176;&#x4E2D;&#x963B;&#x585E;&#x961F;&#x5217;&#x7684;&#x5178;&#x578B;&#x4F8B;&#x5B50;&#x662F;BlockingQueue&#xFF0C;&#x975E;&#x963B;&#x585E;&#x961F;&#x5217;&#x7684;&#x5178;&#x578B;&#x4F8B;&#x5B50;&#x662F;ConcurrentLinkedQueue&#xFF0C;&#x4ECA;&#x5929;&#x4E5F;&#x4E3B;&#x8981;&#x8BF4;&#x4E00;&#x4E0B;&#x8FD9;&#x4E24;&#x4E2A;&#x961F;&#x5217;&#x3002;&#x4E4B;&#x540E;&#x53EF;&#x80FD;&#x4F1A;&#x8BF4;&#x4E00;&#x4E0B;Atomic&#x5BB6;&#x65CF;&#xFF0C;&#x5148;&#x5907;&#x5FD8;&#x3002; BlockingQueueBlockingQueue&#x662F;&#x4E00;&#x4E2A;&#x63A5;&#x53E3;&#xFF0C;&#x7EE7;&#x627F;&#x81EA;Queue&#x3002; &#x63A5;&#x53E3;&#x65B9;&#x6CD5;&#x5148;&#x770B;&#x4E00;&#x4E0B;&#x5B83;&#x6709;&#x54EA;&#x4E9B;&#x65B9;&#x6CD5;&#xFF1A;&#x518D;&#x52A0;&#x4E0A;&#x5176;&#x7236;&#x7C7B;Queue&#x4E2D;&#x65B9;&#x6CD5;&#xFF0C;&#x6574;&#x7406;&#x4E00;&#x4E0B;: &#x53EF;&#x80FD;&#x62A5;&#x5F02;&#x5E38; &#x8FD4;&#x56DE;&#x5E03;&#x5C14;&#x503C;&#x6216;null &#x53EF;&#x80FD;&#x963B;&#x585E; &#x8BBE;&#x5B9A;&#x7B49;&#x5F85;&#x65F6;&#x95F4; &#x5165;&#x961F; add(e) offer(e) put(e) offer(e, timeout, unit) &#x51FA;&#x961F; remove() poll() take() poll(timeout, unit) &#x67E5;&#x770B; element() peek() &#x65E0; &#x65E0; &#x8BF4;&#x660E;&#xFF1A; poll(), peek(), element()&#x662F;Queue&#x4E2D;&#x65B9;&#x6CD5;&#x3002; BlockingQueue&#x4E2D;&#x4E0D;&#x63A5;&#x53D7;null&#x3002;&#x5F53;add, put, offer&#x5C06;null&#x4F5C;&#x4E3A;&#x53C2;&#x6570;&#x65F6;&#xFF0C;&#x4F1A;&#x629B;&#x51FA;NullPointerException&#xFF0C;&#x8FD9;&#x662F;&#x56E0;&#x4E3A;&#x5F53;poll&#x5931;&#x8D25;&#x65F6;&#x4F1A;&#x8FD4;&#x56DE;null&#xFF0C;&#x6B64;&#x65F6;&#x4E0D;&#x77E5;&#x9053;queue&#x4E2D;&#x672C;&#x8EAB;&#x662F;null&#x8FD8;&#x662F;poll&#x5931;&#x8D25;&#x3002; A BlockingQueue does not accept null elements. Implementations throw NullPointerException on attempts to add, put or offer a null. A null is used as a sentinel value to indicate failure of poll operations. add(e), remove(), element()&#x90FD;&#x4E0D;&#x4F1A;&#x963B;&#x585E;&#x7EBF;&#x7A0B;&#xFF0C;&#x4F46;&#x662F;&#x5F53;&#x4E0D;&#x6EE1;&#x8DB3;&#x6761;&#x4EF6;&#x65F6;&#xFF0C;&#x4F1A;&#x629B;&#x51FA;IllegalStateException, &#x5426;&#x5219;&#x8FD4;&#x56DE;true&#x3002;&#x6BD4;&#x5982;&#xFF0C;&#x5F53;&#x961F;&#x5217;&#x5DF2;&#x6EE1;&#x65F6;&#xFF0C;&#x518D;&#x8C03;&#x7528;add(e)&#x65B9;&#x6CD5;&#xFF0C;&#x4F1A;&#x629B;&#x51FA;&#x5F02;&#x5E38;&#xFF1B;&#x5982;&#x679C;&#x961F;&#x5217;&#x6CA1;&#x6EE1;&#xFF0C;&#x6B64;&#x5143;&#x7D20;&#x4F1A;&#x5165;&#x5230;&#x961F;&#x5217;&#x4E2D;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;true&#x3002; offer(e), poll(), peek()&#x65B9;&#x6CD5;&#xFF0C;&#x65E2;&#x4E0D;&#x4F1A;&#x963B;&#x585E;&#x7EBF;&#x7A0B;&#xFF0C;&#x4E5F;&#x4E0D;&#x4F1A;&#x629B;&#x51FA;&#x5F02;&#x5E38;&#xFF0C;&#x53EA;&#x662F;&#x8FD4;&#x56DE;&#x5E03;&#x5C14;&#x503C;&#x6216;null&#x3002; put(e), take()&#x65B9;&#x6CD5;&#x5F53;&#x4E0D;&#x6EE1;&#x8DB3;&#x6761;&#x4EF6;&#x65F6;&#xFF0C;&#x4F1A;&#x963B;&#x585E;&#x7EBF;&#x7A0B;(waiting if necessary until an element becomes available)&#x3002; offer(e, timeout, unit), poll(timeout, unit)&#x53EF;&#x4EE5;&#x8BBE;&#x5B9A;&#x7B49;&#x5F85;&#x65F6;&#x95F4;&#xFF0C;&#x5982;&#x679C;&#x8D85;&#x65F6;&#x8FD4;&#x56DE;false&#x6216;null&#x3002; &#x5B9E;&#x73B0; ArrayBlockingQueue&#xFF1A;&#x89C4;&#x5B9A;&#x5927;&#x5C0F;&#x7684;BlockingQueue&#xFF0C;&#x5176;&#x6784;&#x9020;&#x51FD;&#x6570;&#x5FC5;&#x987B;&#x5E26;&#x4E00;&#x4E2A;int&#x53C2;&#x6570;&#x6765;&#x6307;&#x660E;&#x5176;&#x5927;&#x5C0F;&#x3002;&#x5176;&#x6240;&#x542B;&#x7684;&#x5BF9;&#x8C61;&#x662F;&#x4EE5;FIFO&#xFF08;&#x5148;&#x5165;&#x5148;&#x51FA;&#xFF09;&#x987A;&#x5E8F;&#x6392;&#x5E8F;&#x7684;&#x3002; LinkedBlockingQueue&#xFF1A;&#x5927;&#x5C0F;&#x4E0D;&#x5B9A;&#x7684;BlockingQueue&#xFF0C;&#x82E5;&#x5176;&#x6784;&#x9020;&#x51FD;&#x6570;&#x5E26;&#x4E00;&#x4E2A;&#x89C4;&#x5B9A;&#x5927;&#x5C0F;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x751F;&#x6210;&#x7684;BlockingQueue&#x6709;&#x5927;&#x5C0F;&#x9650;&#x5236;&#xFF0C;&#x82E5;&#x4E0D;&#x5E26;&#x5927;&#x5C0F;&#x53C2;&#x6570;&#xFF0C;&#x6240;&#x751F;&#x6210;&#x7684;BlockingQueue&#x7684;&#x5927;&#x5C0F;&#x7531;Integer.MAX_VALUE&#x6765;&#x51B3;&#x5B9A;&#x3002;&#x5176;&#x6240;&#x542B;&#x7684;&#x5BF9;&#x8C61;&#x662F;&#x4EE5;FIFO&#x987A;&#x5E8F;&#x6392;&#x5E8F;&#x7684;&#x3002; PriorityBlockingQueue&#xFF1A;&#x7C7B;&#x4F3C;&#x4E8E;LinkedBlockingQueue&#xFF0C;&#x4F46;&#x5176;&#x6240;&#x542B;&#x5BF9;&#x8C61;&#x7684;&#x6392;&#x5E8F;&#x4E0D;&#x662F;FIFO&#xFF0C;&#x800C;&#x662F;&#x4F9D;&#x636E;&#x5BF9;&#x8C61;&#x7684;&#x81EA;&#x7136;&#x6392;&#x5E8F;&#x987A;&#x5E8F;&#x6216;&#x8005;&#x662F;&#x6784;&#x9020;&#x51FD;&#x6570;&#x6240;&#x5E26;&#x7684;Comparator&#x51B3;&#x5B9A;&#x7684;&#x987A;&#x5E8F;&#x3002; SynchronousQueue&#xFF1A;&#x7279;&#x6B8A;&#x7684;BlockingQueue&#xFF0C;&#x5BF9;&#x5176;&#x7684;&#x64CD;&#x4F5C;&#x5FC5;&#x987B;&#x662F;&#x653E;&#x548C;&#x53D6;&#x4EA4;&#x66FF;&#x5B8C;&#x6210;&#x7684;&#x3002; ConcurrentLinkedQueueConcurrentLinkedQueue&#x7684;size()&#x65B9;&#x6CD5;&#x9700;&#x8981;&#x904D;&#x5386;&#x4E00;&#x904D;&#xFF0C;&#x6240;&#x4EE5;&#x8981;&#x5C3D;&#x91CF;&#x907F;&#x514D;&#x4F7F;&#x7528;&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x4F7F;&#x7528;isEmpty()&#x65B9;&#x6CD5;&#x3002;ConcurrentLinkedQueue&#x5145;&#x5206;&#x4F7F;&#x7528;&#x4E86;atomic&#x5305;&#x7684;&#x5B9E;&#x73B0;&#x6253;&#x9020;&#x4E86;&#x4E00;&#x4E2A;&#x65E0;&#x9501;&#x5E76;&#x53D1;&#x7EBF;&#x7A0B;&#x5B89;&#x5168;&#x7684;&#x961F;&#x5217;&#x3002;&#x4EE5;offer(e)&#x65B9;&#x6CD5;&#x4E3A;&#x4F8B;&#xFF0C;&#x770B;&#x770B;&#x5728;&#x65E0;&#x9501;&#x60C5;&#x51B5;&#x4E0B;&#x662F;&#x600E;&#x4E48;&#x4FDD;&#x8BC1;&#x539F;&#x5B50;&#x6027;&#x7684;&#xFF1A; 12345678910111213141516171819public boolean offer(E e) { checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) { Node&lt;E&gt; q = p.next; if (q == null) { //--------------------------- a if (p.casNext(null, newNode)) { //--------------------------- b if (p != t) casTail(t, newNode); //--------------------------- c return true; } } else if (p == q) p = (t != (t = tail)) ? t : head; //--------------------------- d else p = (p != t &amp;&amp; t != (t = tail)) ? t : q; //--------------------------- e }} &#x6B64;&#x65B9;&#x6CD5;&#x7684;&#x5FAA;&#x73AF;&#x5185;&#x9996;&#x5148;&#x83B7;&#x5F97;tail&#x6307;&#x9488;&#x548C;&#x5176;next&#x6307;&#x5411;&#x7684;&#x5BF9;&#x8C61;&#xFF0C;&#x7531;&#x4E8E;tail&#x548C;next&#x5747;&#x662F;volatile&#x7684;&#xFF0C;&#x6240;&#x4EE5;&#x4FDD;&#x8BC1;&#x4E86;&#x83B7;&#x5F97;&#x7684;&#x5206;&#x522B;&#x90FD;&#x662F;&#x6700;&#x65B0;&#x7684;&#x503C;&#x3002; &#x4EE3;&#x7801;a &#x60C5;&#x51B5;1,q==null&#x3002;&#x8FD9;&#x610F;&#x5473;&#x7740;q&#x662F;&#x5C3E;&#x8282;&#x70B9;&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x3002;&#x6B64;&#x65F6;&#xFF0C;&#x901A;&#x8FC7;p.casNext(null, newNode)&#x5C06;&#x201C;p&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x8BBE;&#x4E3A;newNode&#x201D;&#xFF0C;&#x82E5;&#x8BBE;&#x7F6E;&#x6210;&#x529F;&#x7684;&#x8BDD;&#xFF0C;&#x5219;&#x6BD4;&#x8F83;&#x201C;p&#x548C;t&#x201D;&#xFF0C;&#x82E5;p&#x4E0D;&#x7B49;&#x4E8E;t&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;newNode&#x4E3A;&#x65B0;&#x7684;&#x5C3E;&#x8282;&#x70B9;&#xFF0C;&#x7136;&#x540E;&#x8FD4;&#x56DE;true&#x3002;&#x5426;&#x5219;&#x7684;&#x8BDD;(&#x610F;&#x5473;&#x7740;&#x201C;&#x5176;&#x5B83;&#x7EBF;&#x7A0B;&#x5BF9;&#x5C3E;&#x8282;&#x70B9;&#x8FDB;&#x884C;&#x4E86;&#x4FEE;&#x6539;&#x201D;)&#xFF0C;&#x4EC0;&#x4E48;&#x4E5F;&#x4E0D;&#x505A;&#xFF0C;&#x7EE7;&#x7EED;&#x8FDB;&#x884C;for&#x5FAA;&#x73AF;&#x3002; &#x4EE3;&#x7801;b p.casNext(null, newNode) &#x8C03;&#x7528;CAS&#x5BF9;p&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x3002;&#x82E5;&#x201C;p&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x7B49;&#x4E8E;null&#x201D;&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;&#x201C;p&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x7B49;&#x4E8E;newNode&#x201D;&#xFF1B;&#x8BBE;&#x7F6E;&#x6210;&#x529F;&#x7684;&#x8BDD;&#xFF0C;&#x8FD4;&#x56DE;true&#xFF0C;&#x5931;&#x8D25;&#x7684;&#x8BDD;&#x8FD4;&#x56DE;false&#x3002; &#x4EE3;&#x7801;c &#x66F4;&#x65B0;tail&#x7684;&#x6307;&#x5411;&#xFF0C;&#x6700;&#x6709;&#x610F;&#x601D;&#x7684;&#x534F;&#x8C03;&#x5728;&#x8FD9;&#x513F;&#x53C8;&#x6709;&#x4E86;&#x4F53;&#x73B0;&#x3002;&#x4ECE;&#x4EE3;&#x7801;&#x770B;casTail(t, newNode)&#x4E0D;&#x7BA1;&#x662F;&#x5426;&#x6210;&#x529F;&#x90FD;&#x4F1A;&#x63A5;&#x7740;&#x8FD4;&#x56DE;true&#x6807;&#x5FD7;&#x7740;&#x66F4;&#x65B0;&#x7684;&#x6210;&#x529F;&#x3002;&#x9996;&#x5148;&#x5982;&#x679C;&#x6210;&#x529F;&#x5219;&#x8868;&#x660E;&#x672C;&#x7EBF;&#x7A0B;&#x5B8C;&#x6210;&#x4E86;&#x4E24;&#x6B65;&#x7684;&#x66F4;&#x65B0;&#xFF0C;&#x8FD4;&#x56DE;true&#x662F;&#x7406;&#x6240;&#x5F53;&#x7136;&#x7684;&#xFF1B;&#x5982;&#x679C; casTail(t, newNode)&#x4E0D;&#x6210;&#x529F;&#x5462;&#xFF1F;&#x8981;&#x6E05;&#x695A;&#x7684;&#x662F;&#x5B8C;&#x6210;&#x4EE3;&#x7801;b&#x5219;&#x4EE3;&#x8868;&#x7740;&#x66F4;&#x65B0;&#x8FDB;&#x5165;&#x4E86;&#x4E2D;&#x95F4;&#x6001;&#xFF0C;&#x4EE3;&#x7801;c&#x4E0D;&#x6210;&#x529F;&#x5219;&#x662F;tail&#x7684;&#x6307;&#x5411;&#x88AB;&#x5176;&#x4ED6;&#x7EBF;&#x7A0B;&#x6539;&#x53D8;&#x3002;&#x610F;&#x5473;&#x7740;&#x5BF9;&#x4E8E;&#x5176;&#x4ED6;&#x7684;&#x7EBF;&#x7A0B;&#x800C;&#x8A00;&#xFF1A;&#x5B83;&#x4EEC;&#x5F97;&#x5230;&#x7684;&#x662F;&#x4E2D;&#x95F4;&#x6001;&#x7684;&#x66F4;&#x65B0;&#xFF0C;q!=null&#xFF0C;&#x8FDB;&#x5165;&#x4EE3;&#x7801;e&#x5E2E;&#x52A9;&#x672C;&#x7EBF;&#x7A0B;&#x6267;&#x884C;&#x6700;&#x540E;&#x4E00;&#x6B65;&#x5E76;&#x4E14;&#x5148;&#x4E8E;&#x672C;&#x7EBF;&#x7A0B;&#x6210;&#x529F;&#x3002;&#x8FD9;&#x6837;&#x672C;&#x7EBF;&#x7A0B;&#x867D;&#x7136;&#x4EE3;&#x7801;c&#x5931;&#x8D25;&#x4E86;&#xFF0C;&#x4F46;&#x662F;&#x662F;&#x7531;&#x4E8E;&#x522B;&#x7684;&#x7EBF;&#x7A0B;&#x7684;&#x534F;&#x52A9;&#x5148;&#x5B8C;&#x6210;&#x4E86;&#xFF0C;&#x6240;&#x4EE5;&#x8FD4;&#x56DE;true&#x4E5F;&#x5C31;&#x7406;&#x6240;&#x5F53;&#x7136;&#x4E86;&#x3002; &#x4EE3;&#x7801;d &#x60C5;&#x51B5;2,q==p&#x3002;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4EC0;&#x4E48;&#x65F6;&#x5019;&#x4F1A;&#x53D1;&#x751F;&#x5462;&#xFF1F;&#x901A;&#x8FC7;&#x201C;&#x60C5;&#x51B5;3&#x201D;&#xFF0C;&#x6211;&#x4EEC;&#x77E5;&#x9053;&#xFF0C;&#x7ECF;&#x8FC7;&#x201C;&#x60C5;&#x51B5;3&#x201D;&#x7684;&#x5904;&#x7406;&#x540E;&#xFF0C;p&#x7684;&#x503C;&#x53EF;&#x80FD;&#x7B49;&#x4E8E;q&#x3002;&#x6B64;&#x65F6;&#xFF0C;&#x82E5;&#x5C3E;&#x8282;&#x70B9;&#x6CA1;&#x6709;&#x53D1;&#x751F;&#x53D8;&#x5316;&#x7684;&#x8BDD;&#xFF0C;&#x90A3;&#x4E48;&#xFF0C;&#x5E94;&#x8BE5;&#x662F;&#x5934;&#x8282;&#x70B9;&#x53D1;&#x751F;&#x4E86;&#x53D8;&#x5316;&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;p&#x4E3A;&#x5934;&#x8282;&#x70B9;&#xFF0C;&#x7136;&#x540E;&#x91CD;&#x65B0;&#x904D;&#x5386;&#x94FE;&#x8868;&#xFF1B;&#x5426;&#x5219;(&#x5C3E;&#x8282;&#x70B9;&#x53D8;&#x5316;&#x7684;&#x8BDD;)&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;p&#x4E3A;&#x5C3E;&#x8282;&#x70B9;&#x3002; &#x4EE3;&#x7801;e &#x60C5;&#x51B5;3&#x3002;&#x5982;&#x679C;p&#x548C;t&#x76F8;&#x7B49;&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;p&#x4E3A;q&#x3002;&#x5426;&#x5219;&#x7684;&#x8BDD;&#xFF0C;&#x5224;&#x65AD;&#x201C;&#x5C3E;&#x8282;&#x70B9;&#x662F;&#x5426;&#x53D1;&#x751F;&#x53D8;&#x5316;&#x201D;&#xFF0C;&#x6CA1;&#x6709;&#x53D8;&#x5316;&#x7684;&#x8BDD;&#xFF0C;&#x5219;&#x8BBE;&#x7F6E;p&#x4E3A;q&#xFF1B;&#x5426;&#x5219;&#xFF0C;&#x8BBE;&#x7F6E;p&#x4E3A;&#x5C3E;&#x8282;&#x70B9;&#x3002; &#x53C2;&#x8003; Interface BlockingQueue: Oracle&#x5B98;&#x7F51;BlockingQueue API Java &#x7406;&#x8BBA;&#x4E0E;&#x5B9E;&#x8DF5;: JDK 5.0 &#x4E2D;&#x66F4;&#x7075;&#x6D3B;&#x3001;&#x66F4;&#x5177;&#x53EF;&#x4F38;&#x7F29;&#x6027;&#x7684;&#x9501;&#x5B9A;&#x673A;&#x5236; Java &#x7406;&#x8BBA;&#x4E0E;&#x5B9E;&#x8DF5;: &#x975E;&#x963B;&#x585E;&#x7B97;&#x6CD5;&#x7B80;&#x4ECB; Java&#x591A;&#x7EBF;&#x7A0B;&#x603B;&#x7ED3;&#x4E4B;&#x804A;&#x4E00;&#x804A;Queue","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"},{"name":"thread","slug":"thread","permalink":"http://wzktravel.github.io/tags/thread/"}]},{"title":"shell常用命令整理","slug":"shell-command","date":"2015-09-13T08:23:13.000Z","updated":"2016-08-24T07:24:58.000Z","comments":true,"path":"2015/09/13/shell-command/","link":"","permalink":"http://wzktravel.github.io/2015/09/13/shell-command/","excerpt":"只整理一些平时想用，可能又突然记不起来的命令和用法。都是基于bash。如果不想在命令行使用man来阅读手册，可以在这个网站查看 http://explainshell.com/","text":"&#x53EA;&#x6574;&#x7406;&#x4E00;&#x4E9B;&#x5E73;&#x65F6;&#x60F3;&#x7528;&#xFF0C;&#x53EF;&#x80FD;&#x53C8;&#x7A81;&#x7136;&#x8BB0;&#x4E0D;&#x8D77;&#x6765;&#x7684;&#x547D;&#x4EE4;&#x548C;&#x7528;&#x6CD5;&#x3002;&#x90FD;&#x662F;&#x57FA;&#x4E8E;bash&#x3002;&#x5982;&#x679C;&#x4E0D;&#x60F3;&#x5728;&#x547D;&#x4EE4;&#x884C;&#x4F7F;&#x7528;man&#x6765;&#x9605;&#x8BFB;&#x624B;&#x518C;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x8FD9;&#x4E2A;&#x7F51;&#x7AD9;&#x67E5;&#x770B; http://explainshell.com/ &#x6982;&#x8FF0; &#x5B66;&#x4F1A;&#x4F7F;&#x7528;man&#x547D;&#x4EE4;&#xFF0C;&#x67E5;&#x770B;&#x7279;&#x5B9A;&#x547D;&#x4EE4;&#x7684;&#x624B;&#x518C;&#x3002;man -k&#x6216;apropos&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x4F60;&#x4E0D;&#x77E5;&#x9053;&#x6267;&#x884C;&#x67D0;&#x4E2A;&#x7279;&#x5B9A;&#x4EFB;&#x52A1;&#x6240;&#x9700;&#x8981;&#x547D;&#x4EE4;&#x7684;&#x540D;&#x79F0;&#x65F6;&#xFF0C;&#x67E5;&#x627E;&#x8FD9;&#x4E2A;&#x547D;&#x4EE4;&#x3002; &#x5B66;&#x4F1A;&#x4F7F;&#x7528;&gt;&#x548C;&lt;&#x6765;&#x91CD;&#x5B9A;&#x5411;&#x8F93;&#x5165;&#x8F93;&#x51FA;&#xFF0C;&#x7528;|&#x5EFA;&#x7ACB;&#x7BA1;&#x9053;&#x3002; &#x5B66;&#x4E60;&#x4F7F;&#x7528;&#x901A;&#x914D;&#x7B26;&#x3002; &#x5B66;&#x4E60;&#x4F7F;&#x7528;bash&#x7684;&#x4EFB;&#x52A1;&#x7BA1;&#x7406;&#x5668;, &amp;, ctrl-z, ctrl-c, jobs, fg, bg, kill, killall&#x7B49;&#x3002; &#x5B66;&#x4E60;&#x4F7F;&#x7528;ssh, &#x5E76;&#x4E14;&#x77E5;&#x9053;&#x5982;&#x679C;&#x901A;&#x8FC7;ssh-agent,ssh-add&#x7B49;&#x5B9E;&#x73B0;&#x65E0;&#x5BC6;&#x7801;&#x8BA4;&#x8BC1;&#x3002; &#x638C;&#x63E1;&#x6587;&#x4EF6;&#x7BA1;&#x7406;&#x547D;&#x4EE4;, ls, less, head, tail, ln ln -s(&#x786C;&#x94FE;&#x63A5;/&#x8F6F;&#x94FE;&#x63A5;), chown, chmod, du&#x7B49;&#x3002; &#x638C;&#x63E1;&#x6587;&#x4EF6;&#x7CFB;&#x7EDF;&#x547D;&#x4EE4;, df, mount, fdisk, mkfs, lsblk&#x7B49;&#x3002; &#x719F;&#x7EC3;&#x638C;&#x63E1;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x4EE5;&#x53CA;grep/egrep/fgrep&#x5DE5;&#x5177;&#x3002;&#x6709;&#x5FC5;&#x8981;&#x77E5;&#x9053; -i, -o, -A, -a &#x4EE5;&#x53CA; -B &#x9009;&#x9879;&#x7684;&#x610F;&#x601D;&#x3002; &#x5B66;&#x4E60;&#x57FA;&#x672C;&#x7684;&#x7F51;&#x7EDC;&#x7BA1;&#x7406;&#x547D;&#x4EE4;, ifconfig, dig&#x7B49;&#x3002; &#x5B66;&#x4E60;&#x4F7F;&#x7528;&#x5305;&#x7BA1;&#x7406;&#x5668;&#xFF0C;&#x9488;&#x5BF9;&#x4E0D;&#x540C;&#x7684;linux&#x53D1;&#x884C;&#x7248;&#x672C;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x5305;&#x7BA1;&#x7406;&#x5668;, apt-get, yum, brew&#x7B49;&#x3002; &#x5B66;&#x4E60;&#x4F7F;&#x7528;&#x6253;&#x5305;&#x547D;&#x4EE4;, tar, zip&#x7B49;&#x3002; &#x57FA;&#x7840;&#x77E5;&#x8BC6;bash&#x7EC4;&#x5408;&#x952E; ctrl-a &#x79FB;&#x52A8;&#x5230;&#x884C;&#x9996; ctrl-e &#x79FB;&#x52A8;&#x5230;&#x884C;&#x5C3E; ctrl-xx &#x5728;&#x547D;&#x4EE4;&#x884C;&#x9996;&#x548C;&#x5149;&#x6807;&#x4E4B;&#x95F4;&#x79FB;&#x52A8; ctrl-u &#x5220;&#x9664;&#x6574;&#x884C; ctrl-w &#x4ECE;&#x5149;&#x6807;&#x5904;&#x5220;&#x9664;&#x5230;&#x8BCD;&#x9996; ctrl-k &#x5220;&#x9664;&#x5230;&#x884C;&#x5C3E; ctrl-r &#x9006;&#x5411;&#x641C;&#x7D22;&#x547D;&#x4EE4;&#x5386;&#x53F2; ctrl-p &#x5386;&#x53F2;&#x4E2D;&#x4E0A;&#x4E00;&#x6761;&#x547D;&#x4EE4; ctrl-n &#x5386;&#x53F2;&#x4E2D;&#x4E0B;&#x4E00;&#x6761;&#x547D;&#x4EE4; ctrl-l clear&#xFF0C;&#x6E05;&#x7A7A;&#x5C4F;&#x5E55; !$ &#x4E0A;&#x4E00;&#x4E2A;&#x53C2;&#x6570; !! &#x5386;&#x53F2;&#x4E2D;&#x4E0A;&#x4E00;&#x6761;&#x547D;&#x4EE4; &#x901A;&#x914D;&#x7B26;&#x5F15;&#x53F7; &#x5355;&#x5F15;&#x53F7; &apos;&#x7531;&#x5355;&#x5F15;&#x53F7;&#x62EC;&#x8D77;&#x6765;&#x7684;&#x5B57;&#x7B26;&#x90FD;&#x4F5C;&#x4E3A;&#x666E;&#x901A;&#x5B57;&#x7B26;&#x51FA;&#x73B0;&#x3002;&#x7279;&#x6B8A;&#x5B57;&#x7B26;&#x7528;&#x5355;&#x5F15;&#x53F7;&#x62EC;&#x8D77;&#x6765;&#x4EE5;&#x540E;&#xFF0C;&#x4E5F;&#x4F1A;&#x5931;&#x53BB;&#x539F;&#x6709;&#x610F;&#x4E49;&#xFF0C;&#x800C;&#x53EA;&#x4F5C;&#x4E3A;&#x666E;&#x901A;&#x5B57;&#x7B26;&#x89E3;&#x91CA;&#x3002; &#x53CC;&#x5F15;&#x53F7; &quot;&#x5355;&#x5F15;&#x53F7;&#x544A;&#x8BC9;shell&#x5FFD;&#x7565;&#x6240;&#x6709;&#x7279;&#x6B8A;&#x5B57;&#x7B26;&#xFF0C;&#x800C;&#x53CC;&#x5F15;&#x53F7;&#x53EA;&#x8981;&#x6C42;&#x5FFD;&#x7565;&#x5927;&#x591A;&#x6570;&#xFF0C;&#x5177;&#x4F53;&#x8BF4;&#xFF0C;&#x62EC;&#x5728;&#x53CC;&#x5F15;&#x53F7;&#x4E2D;&#x7684;&#x4E09;&#x79CD;&#x7279;&#x6B8A;&#x5B57;&#x7B26;&#x4E0D;&#x88AB;&#x5FFD;&#x7565;&#xFF1A;$,\\,` .&#x6765;&#x770B;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#x6765;&#x8BF4;&#x660E;&#x5355;&#x5F15;&#x53F7;&#x548C;&#x53CC;&#x5F15;&#x53F7;&#x7684;&#x533A;&#x522B;&#xFF1A; 1234567~ x=*~ echo $xa b pet.txt wget~ echo &apos;$x&apos;$x~ echo &quot;$x&quot;* shell&#x5728;&#x5904;&#x7406;&#x65F6;&#x4F1A;&#x5148;&#x4F5C;&#x53D8;&#x91CF;&#x66FF;&#x6362;&#xFF0C;&#x7136;&#x540E;&#x4F5C;&#x6587;&#x4EF6;&#x540D;&#x66FF;&#x6362;&#xFF0C;&#x6700;&#x540E;&#x628A;&#x8FD9;&#x884C;&#x5904;&#x7406;&#x4E3A;&#x53C2;&#x6570;&#x3002; &#x53CD;&#x5F15;&#x53F7; ` &#x547D;&#x4EE4;&#x66FF;&#x6362;&#x662F;&#x6307;shell&#x80FD;&#x591F;&#x5C06;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x6807;&#x51C6;&#x8F93;&#x51FA;&#x63D2;&#x5728;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x884C;&#x4E2D;&#x4EFB;&#x4F55;&#x4F4D;&#x7F6E;&#x3002;shell&#x4E2D;&#x6709;&#x4E24;&#x79CD;&#x65B9;&#x6CD5;&#x4F5C;&#x547D;&#x4EE4;&#x66FF;&#x6362;&#xFF1A;&#x628A;shell&#x547D;&#x4EE4;&#x7528;&#x53CD;&#x5F15;&#x53F7;&#x6216;&#x8005;$(&#x2026;)&#x7ED3;&#x6784;&#x62EC;&#x8D77;&#x6765;&#xFF0C;&#x5176;&#x4E2D;&#xFF0C;$(&#x2026;)&#x683C;&#x5F0F;&#x53D7;&#x5230;POSIX&#x6807;&#x51C6;&#x652F;&#x6301;&#xFF0C;&#x4E5F;&#x5229;&#x4E8E;&#x5D4C;&#x5957;&#x3002; 1234~ echo &quot;now is `date`&quot;now is 2015&#x5E74; 9&#x6708;13&#x65E5; &#x661F;&#x671F;&#x65E5; 22&#x65F6;23&#x5206;42&#x79D2; CST~ echo &quot;now is $(date)&quot;now is 2015&#x5E74; 9&#x6708;13&#x65E5; &#x661F;&#x671F;&#x65E5; 22&#x65F6;23&#x5206;55&#x79D2; CST &#x6807;&#x51C6;&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x6267;&#x884C;&#x4E00;&#x4E2A;shell&#x547D;&#x4EE4;&#x884C;&#x65F6;&#x901A;&#x5E38;&#x4F1A;&#x81EA;&#x52A8;&#x6253;&#x5F00;&#x4E09;&#x4E2A;&#x6807;&#x51C6;&#x6587;&#x4EF6;&#xFF0C;&#x5373;&#x6807;&#x51C6;&#x8F93;&#x5165;&#x6587;&#x4EF6;&#xFF08;stdin&#xFF09;&#xFF0C;&#x901A;&#x5E38;&#x5BF9;&#x5E94;&#x7EC8;&#x7AEF;&#x7684;&#x952E;&#x76D8;&#xFF1B;&#x6807;&#x51C6;&#x8F93;&#x51FA;&#x6587;&#x4EF6;&#xFF08;stdout&#xFF09;&#x548C;&#x6807;&#x51C6;&#x9519;&#x8BEF;&#x8F93;&#x51FA;&#x6587;&#x4EF6;&#xFF08;stderr&#xFF09;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;&#x6587;&#x4EF6;&#x90FD;&#x5BF9;&#x5E94;&#x7EC8;&#x7AEF;&#x7684;&#x5C4F;&#x5E55;&#x3002;&#x8FDB;&#x7A0B;&#x5C06;&#x4ECE;&#x6807;&#x51C6;&#x8F93;&#x5165;&#x6587;&#x4EF6;&#x4E2D;&#x5F97;&#x5230;&#x8F93;&#x5165;&#x6570;&#x636E;&#xFF0C;&#x5C06;&#x6B63;&#x5E38;&#x8F93;&#x51FA;&#x6570;&#x636E;&#x8F93;&#x51FA;&#x5230;&#x6807;&#x51C6;&#x8F93;&#x51FA;&#x6587;&#x4EF6;&#xFF0C;&#x800C;&#x5C06;&#x9519;&#x8BEF;&#x4FE1;&#x606F;&#x9001;&#x5230;&#x6807;&#x51C6;&#x9519;&#x8BEF;&#x6587;&#x4EF6;&#x4E2D;&#x3002; &#x8F93;&#x5165;&#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411; &#x8F93;&#x5165;&#x91CD;&#x5B9A;&#x5411;&#x8F93;&#x5165;&#x91CD;&#x5B9A;&#x5411;&#x662F;&#x6307;&#x628A;&#x547D;&#x4EE4;&#xFF08;&#x6216;&#x53EF;&#x6267;&#x884C;&#x7A0B;&#x5E8F;&#xFF09;&#x7684;&#x6807;&#x51C6;&#x8F93;&#x5165;&#x91CD;&#x5B9A;&#x5411;&#x5230;&#x6307;&#x5B9A;&#x7684;&#x6587;&#x4EF6;&#x4E2D;&#x3002;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x8F93;&#x5165;&#x53EF;&#x4EE5;&#x4E0D;&#x6765;&#x81EA;&#x952E;&#x76D8;&#xFF0C;&#x800C;&#x6765;&#x81EA;&#x4E00;&#x4E2A;&#x6307;&#x5B9A;&#x7684;&#x6587;&#x4EF6;&#x3002;&#x6240;&#x4EE5;&#x8BF4;&#xFF0C;&#x8F93;&#x5165;&#x91CD;&#x5B9A;&#x5411;&#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x6539;&#x53D8;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x5165;&#x6E90;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x6539;&#x53D8;&#x90A3;&#x4E9B;&#x9700;&#x8981;&#x5927;&#x91CF;&#x8F93;&#x5165;&#x7684;&#x8F93;&#x5165;&#x6E90;&#x3002;&#x6709;&lt;&#x548C;&lt;&lt;&#x4E24;&#x79CD;&#x64CD;&#x4F5C;&#x7B26;&#x3002; &#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411;&#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411;&#x662F;&#x6307;&#x628A;&#x547D;&#x4EE4;&#xFF08;&#x6216;&#x53EF;&#x6267;&#x884C;&#x7A0B;&#x5E8F;&#xFF09;&#x7684;&#x6807;&#x51C6;&#x8F93;&#x51FA;&#x6216;&#x6807;&#x51C6;&#x9519;&#x8BEF;&#x8F93;&#x51FA;&#x91CD;&#x65B0;&#x5B9A;&#x5411;&#x5230;&#x6307;&#x5B9A;&#x6587;&#x4EF6;&#x4E2D;&#x3002;&#x8FD9;&#x6837;&#xFF0C;&#x8BE5;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#x5C31;&#x4E0D;&#x663E;&#x793A;&#x5728;&#x5C4F;&#x5E55;&#x4E0A;&#xFF0C;&#x800C;&#x662F;&#x5199;&#x5165;&#x5230;&#x6307;&#x5B9A;&#x6587;&#x4EF6;&#x4E2D;&#x3002;&#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411;&#x8FD8;&#x53EF;&#x4EE5;&#x7528;&#x4E8E;&#x628A;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#x5F53;&#x4F5C;&#x53E6;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x5165;&#xFF08;&#x8FD8;&#x6709;&#x4E00;&#x79CD;&#x66F4;&#x7B80;&#x5355;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5C31;&#x662F;&#x4F7F;&#x7528;&#x7BA1;&#x9053;&#xFF09;&#x3002; &gt;&#x540E;&#x7684;&#x6587;&#x4EF6;&#x5982;&#x679C;&#x5B58;&#x5728;&#xFF0C;&#x6B64;&#x6587;&#x4EF6;&#x4F1A;&#x88AB;&#x91CD;&#x5199;&#xFF1B;&gt;&gt;&#x4F1A;&#x8FFD;&#x52A0;&#x5230;&#x6587;&#x4EF6;&#x540E;&#x9762;&#x3002; 2&gt;&#x6216;2&gt;&gt;&#x8868;&#x793A;&#x9519;&#x8BEF;&#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411; &amp;&gt;&#x8868;&#x793A;&#x5C06;&#x6807;&#x51C6;&#x8F93;&#x51FA;&#x548C;&#x9519;&#x8BEF;&#x8F93;&#x51FA;&#x540C;&#x65F6;&#x5199;&#x5230;&#x540C;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;&#x3002; &#x5176;&#x4ED6; &#x591A;&#x6761;&#x547D;&#x4EE4;, ;, &amp;&amp;, ||1231) command1 ; command2 //&#x4E0D;&#x7BA1;command1&#x662F;&#x5426;&#x6267;&#x884C;&#x6210;&#x529F;&#x90FD;&#x4F1A;&#x6267;&#x884C;command22) command1 &amp;&amp; command2 //&#x53EA;&#x6709;command1&#x6267;&#x884C;&#x6210;&#x529F;&#x540E;&#xFF0C;command2&#x624D;&#x4F1A;&#x6267;&#x884C;&#xFF0C;&#x5426;&#x5219;command2&#x4E0D;&#x6267;&#x884C;3) command1 || command2 //command1&#x6267;&#x884C;&#x6210;&#x529F;&#x540E;command2 &#x4E0D;&#x6267;&#x884C;&#xFF0C;&#x5426;&#x5219;&#x53BB;&#x6267;&#x884C;command2&#xFF0C;&#x603B;&#x4E4B;command1&#x548C;command2&#x603B;&#x6709;&#x4E00;&#x6761;&#x547D;&#x4EE4;&#x4F1A;&#x6267;&#x884C; &#x7BA1;&#x9053;&#x7BA1;&#x9053;&#x53EF;&#x4EE5;&#x628A;&#x4E00;&#x7CFB;&#x5217;&#x547D;&#x4EE4;&#x8FDE;&#x63A5;&#x8D77;&#x6765;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x7B2C;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#x4F1A;&#x4F5C;&#x4E3A;&#x7B2C;&#x4E8C;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x5165;&#x901A;&#x8FC7;&#x7BA1;&#x9053;&#x4F20;&#x7ED9;&#x7B2C;&#x4E8C;&#x4E2A;&#x547D;&#x4EE4;&#xFF0C;&#x7B2C;&#x4E8C;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#x53C8;&#x4F1A;&#x4F5C;&#x4E3A;&#x7B2C;&#x4E09;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x4EE5;&#x6B64;&#x7C7B;&#x63A8;&#x3002;&#x663E;&#x793A;&#x5728;&#x5C4F;&#x5E55;&#x4E0A;&#x7684;&#x662F;&#x7BA1;&#x9053;&#x884C;&#x4E2D;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7684;&#x8F93;&#x51FA;&#xFF08;&#x5982;&#x679C;&#x547D;&#x4EE4;&#x884C;&#x4E2D;&#x672A;&#x4F7F;&#x7528;&#x8F93;&#x51FA;&#x91CD;&#x5B9A;&#x5411;&#xFF09;&#x3002;&#x6BD4;&#x5982;&#x5F88;&#x5E38;&#x7528;&#x7684; ps -ef | grep resin&#xFF0C;&#x7ED3;&#x679C;&#x53EA;&#x4F1A;&#x5C55;&#x73B0;&#x51FA;resin&#x7684;ps&#x4FE1;&#x606F;&#x3002; &#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F; RE&#x5B57;&#x7B26; &#x610F;&#x4E49;&#x4E0E;&#x8303;&#x4F8B; ^word &#x610F;&#x4E49;&#xFF1A;&#x5F85;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x4E32;(word)&#x5728;&#x884C;&#x9996;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x884C;&#x9996;&#x4E3A; # &#x5F00;&#x59CB;&#x7684;&#x90A3;&#x4E00;&#x884C;&#xFF0C;&#x5E76;&#x5217;&#x51FA;&#x884C;&#x53F7;&#x3002; grep -n &apos;^#&apos; regular_express.txt word$ &#x610F;&#x4E49;&#xFF1A;&#x5F85;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x4E32;(word)&#x5728;&#x884C;&#x5C3E;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x5C06;&#x884C;&#x5C3E;&#x4E3A; ! &#x7684;&#x90A3;&#x4E00;&#x884C;&#x5217;&#x5370;&#x51FA;&#x6765;&#xFF0C;&#x5E76;&#x5217;&#x51FA;&#x884C;&#x53F7;&#x3002;grep -n &apos;!$&apos; regular_express.txt . &#x610F;&#x4E49;&#xFF1A;&#x4EE3;&#x8868;&#x300E;&#x4E00;&#x5B9A;&#x6709;&#x4E00;&#x4E2A;&#x4EFB;&#x610F;&#x5B57;&#x8282;&#x300F;&#x7684;&#x5B57;&#x7B26;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x4E32;&#x53EF;&#x4EE5;&#x662F; (eve) (eae) (eee) (e e)&#xFF0C; &#x4F46;&#x4E0D;&#x80FD;&#x4EC5;&#x6709; (ee) &#xFF01;&#x4EA6;&#x5373; e &#x4E0E; e &#x4E2D;&#x95F4;&#x300E;&#x4E00;&#x5B9A;&#x300F;&#x4EC5;&#x6709;&#x4E00;&#x4E2A;&#x5B57;&#x8282;&#xFF0C;&#x800C;&#x7A7A;&#x767D;&#x5B57;&#x8282;&#x4E5F;&#x662F;&#x5B57;&#x8282;&#xFF01;grep -n &apos;e.e&apos; regular_express.txt \\ &#x610F;&#x4E49;&#xFF1A;&#x8DF3;&#x8131;&#x5B57;&#x7B26;&#xFF0C;&#x5C06;&#x7279;&#x6B8A;&#x7B26;&#x53F7;&#x7684;&#x7279;&#x6B8A;&#x610F;&#x4E49;&#x53BB;&#x9664;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x542B;&#x6709;&#x5355;&#x5F15;&#x53F7; &#x2018; &#x7684;&#x90A3;&#x4E00;&#x884C;&#xFF01; grep -n \\&apos; regular_express.txt * &#x610F;&#x4E49;&#xFF1A;&#x91CD;&#x590D;&#x96F6;&#x4E2A;&#x5230;&#x65E0;&#x7A77;&#x591A;&#x4E2A;&#x7684;&#x524D;&#x4E00;&#x4E2A; RE &#x5B57;&#x7B26;&#x8303;&#x4F8B;&#xFF1A;&#x627E;&#x51FA;&#x542B;&#x6709; (es) (ess) (esss) &#x7B49;&#x7B49;&#x7684;&#x5B57;&#x4E32;&#xFF0C;&#x6CE8;&#x610F;&#xFF0C;&#x56E0;&#x4E3A; * &#x53EF;&#x4EE5;&#x662F; 0 &#x4E2A;&#xFF0C;&#x6240;&#x4EE5; es &#x4E5F;&#x662F;&#x7B26;&#x5408;&#x5E26;&#x641C;&#x5BFB;&#x5B57;&#x4E32;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x56E0;&#x4E3A; * &#x4E3A;&#x91CD;&#x590D;&#x201D;&#x524D;&#x4E00;&#x4E2A;RE&#x5B57;&#x7B26;&#x201D;&#x7684;&#x7B26;&#x53F7;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x5728;*&#x4E4B;&#x524D;&#x5FC5;&#x987B;&#x8981;&#x7D27;&#x63A5;&#x8457;&#x4E00;&#x4E2A;RE&#x5B57;&#x7B26;&#xFF01;&#x4F8B;&#x5982;&#x4EFB;&#x610F;&#x5B57;&#x8282;&#x5219;&#x4E3A;&#x201D;.*&#x201C;&#x3002; grep -n &apos;ess*&apos; regular_express.txt [list] &#x610F;&#x4E49;&#xFF1A;&#x5B57;&#x8282;&#x96C6;&#x5408;&#x7684; RE &#x5B57;&#x7B26;&#xFF0C;&#x91CC;&#x9762;&#x5217;&#x51FA;&#x60F3;&#x8981;&#x64B7;&#x53D6;&#x7684;&#x5B57;&#x8282;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x542B;&#x6709; (gl) &#x6216; (gd) &#x7684;&#x90A3;&#x4E00;&#x884C;&#xFF0C;&#x9700;&#x8981;&#x7279;&#x522B;&#x7559;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x5728; [] &#x5F53;&#x4E2D;&#x300E;&#x8C28;&#x4EE3;&#x8868;&#x4E00;&#x4E2A;&#x5F85;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x8282;&#x300F;&#xFF0C; &#x4F8B;&#x5982;&#x300E; a[afl]y &#x300F;&#x4EE3;&#x8868;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x4E32;&#x53EF;&#x4EE5;&#x662F; aay, afy, aly &#x5373; [afl] &#x4EE3;&#x8868; a &#x6216; f &#x6216; l &#x7684;&#x610F;&#x601D;&#xFF01;grep -n &apos;g[ld]&apos; regular_express.txt [n1-n2] &#x610F;&#x4E49;&#xFF1A;&#x5B57;&#x8282;&#x96C6;&#x5408;&#x7684; RE &#x5B57;&#x7B26;&#xFF0C;&#x91CC;&#x9762;&#x5217;&#x51FA;&#x60F3;&#x8981;&#x64B7;&#x53D6;&#x7684;&#x5B57;&#x8282;&#x8303;&#x56F4;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x542B;&#x6709;&#x4EFB;&#x610F;&#x6570;&#x5B57;&#x7684;&#x90A3;&#x4E00;&#x884C;&#xFF01;&#x9700;&#x7279;&#x522B;&#x7559;&#x610F;&#xFF0C;&#x5728;&#x5B57;&#x8282;&#x96C6;&#x5408; [] &#x4E2D;&#x7684;&#x51CF;&#x53F7; - &#x662F;&#x6709;&#x7279;&#x6B8A;&#x610F;&#x4E49;&#x7684;&#xFF0C;&#x4ED6;&#x4EE3;&#x8868;&#x4E24;&#x4E2A;&#x5B57;&#x8282;&#x4E4B;&#x95F4;&#x7684;&#x6240;&#x6709;&#x8FDE;&#x7EED;&#x5B57;&#x8282;&#xFF01;&#x4F46;&#x8FD9;&#x4E2A;&#x8FDE;&#x7EED;&#x4E0E;&#x5426;&#x4E0E; ASCII &#x7F16;&#x7801;&#x6709;&#x5173;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x4F60;&#x7684;&#x7F16;&#x7801;&#x9700;&#x8981;&#x914D;&#x7F6E;&#x6B63;&#x786E;(&#x5728; bash &#x5F53;&#x4E2D;&#xFF0C;&#x9700;&#x8981;&#x786E;&#x5B9A; LANG &#x4E0E; LANGUAGE &#x7684;&#x53D8;&#x91CF;&#x662F;&#x5426;&#x6B63;&#x786E;&#xFF01;) &#x4F8B;&#x5982;&#x6240;&#x6709;&#x5927;&#x5199;&#x5B57;&#x8282;&#x5219;&#x4E3A; [A-Z]grep -n &apos;[A-Z]&apos; regular_express.txt [^list] &#x610F;&#x4E49;&#xFF1A;&#x5B57;&#x8282;&#x96C6;&#x5408;&#x7684; RE &#x5B57;&#x7B26;&#xFF0C;&#x91CC;&#x9762;&#x5217;&#x51FA;&#x4E0D;&#x8981;&#x7684;&#x5B57;&#x4E32;&#x6216;&#x8303;&#x56F4;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x641C;&#x5BFB;&#x7684;&#x5B57;&#x4E32;&#x53EF;&#x4EE5;&#x662F; (oog) (ood) &#x4F46;&#x4E0D;&#x80FD;&#x662F; (oot) &#xFF0C;&#x90A3;&#x4E2A; ^ &#x5728; [] &#x5185;&#x65F6;&#xFF0C;&#x4EE3;&#x8868;&#x7684;&#x610F;&#x4E49;&#x662F;&#x300E;&#x53CD;&#x5411;&#x9009;&#x62E9;&#x300F;&#x7684;&#x610F;&#x601D;&#x3002; &#x4F8B;&#x5982;&#xFF0C;&#x6211;&#x4E0D;&#x8981;&#x5927;&#x5199;&#x5B57;&#x8282;&#xFF0C;&#x5219;&#x4E3A; [^A-Z]&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x9700;&#x8981;&#x7279;&#x522B;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x5982;&#x679C;&#x4EE5; grep -n [^A-Z] regular_express.txt &#x6765;&#x641C;&#x5BFB;&#xFF0C;&#x5374;&#x53D1;&#x73B0;&#x8BE5;&#x6587;&#x4EF6;&#x5185;&#x7684;&#x6240;&#x6709;&#x884C;&#x90FD;&#x88AB;&#x5217;&#x51FA;&#xFF0C;&#x4E3A;&#x4EC0;&#x4E48;&#xFF1F;&#x56E0;&#x4E3A;&#x8FD9;&#x4E2A; [^A-Z] &#x662F;&#x300E;&#x975E;&#x5927;&#x5199;&#x5B57;&#x8282;&#x300F;&#x7684;&#x610F;&#x601D;&#xFF0C;&#x56E0;&#x4E3A;&#x6BCF;&#x4E00;&#x884C;&#x5747;&#x6709;&#x975E;&#x5927;&#x5199;&#x5B57;&#x8282;&#xFF0C;&#x4F8B;&#x5982;&#x7B2C;&#x4E00;&#x884C;&#x7684; &#x201C;Open Source&#x201D; &#x5C31;&#x6709; p,e,n,o&#x2026;. &#x7B49;&#x7B49;&#x7684;&#x5C0F;&#x5199;&#x5B57;grep -n &apos;oo[^t]&apos; regular_express.txt {n,m} &#x610F;&#x4E49;&#xFF1A;&#x8FDE;&#x7EED; n &#x5230; m &#x4E2A;&#x7684;&#x300E;&#x524D;&#x4E00;&#x4E2A; RE &#x5B57;&#x7B26;&#x300F;&#x610F;&#x4E49;&#xFF1A;&#x82E5;&#x4E3A; {n} &#x5219;&#x662F;&#x8FDE;&#x7EED; n &#x4E2A;&#x7684;&#x524D;&#x4E00;&#x4E2A; RE &#x5B57;&#x7B26;&#x3002;&#x610F;&#x4E49;&#xFF1A;&#x82E5;&#x662F; {n,} &#x5219;&#x662F;&#x8FDE;&#x7EED; n &#x4E2A;&#x4EE5;&#x4E0A;&#x7684;&#x524D;&#x4E00;&#x4E2A; RE &#x5B57;&#x7B26;&#xFF01;&#x8303;&#x4F8B;&#xFF1A;&#x5728; g &#x4E0E; g &#x4E4B;&#x95F4;&#x6709; 2 &#x4E2A;&#x5230; 3 &#x4E2A;&#x7684; o &#x5B58;&#x5728;&#x7684;&#x5B57;&#x4E32;&#xFF0C;&#x4EA6;&#x5373; (goog)(gooog)grep -n &apos;go\\{2,3\\}g&apos; regular_express.txt &#x6587;&#x4EF6;&#x5904;&#x7406;awk&#x89C1;http://wzktravel.github.io/2015/09/21/linux-awk/ sed&#x89C1;http://wzktravel.github.io/2015/09/19/linux-sed/ shell&#x7F16;&#x7A0B;shell&#x6570;&#x7EC4;&#x89C1;linux shell&#x6570;&#x7EC4;&#x5EFA;&#x7ACB;&#x53CA;&#x4F7F;&#x7528;&#x6280;&#x5DE7; &#x5E38;&#x7528;&#x547D;&#x4EE4; cd - &#x56DE;&#x5230;&#x4E0A;&#x4E00;&#x4E2A;&#x76EE;&#x5F55; ls -lh -h&#x8868;&#x793A;human-readable&#xFF0C;&#x5373;&#x53CB;&#x597D;&#x53EF;&#x8BFB;&#x7684;&#x663E;&#x793A;&#x65B9;&#x5F0F;&#x3002; ls -lrt &#x4EE5;&#x6587;&#x4EF6;&#x4FEE;&#x6539;&#x65F6;&#x95F4;&#x6392;&#x5E8F; ls -lrS &#x4EE5;&#x6587;&#x4EF6;&#x5927;&#x5C0F;&#x6392;&#x5E8F; df -h &#x67E5;&#x770B;&#x5404;&#x6302;&#x8F7D;&#x70B9;&#x78C1;&#x76D8;&#x4F7F;&#x7528;&#x60C5;&#x51B5; du -hs . &#x67E5;&#x770B;&#x5F53;&#x524D;&#x76EE;&#x5F55;&#x7684;&#x603B;&#x5927;&#x5C0F; du -hs ./* &#x67E5;&#x770B;&#x5F53;&#x524D;&#x76EE;&#x5F55;&#x4E0B;&#x6587;&#x4EF6;&#x548C;&#x76EE;&#x5F55;&#x7684;&#x5927;&#x5C0F; echo $((0x1509d314690))&#x6216;echo $((16#1509d314690)) &#x5341;&#x516D;&#x8FDB;&#x5236;&#x8F6C;&#x5341;&#x8FDB;&#x5236; &#x9644;&#x51E0;&#x4E2A;dos&#x547D;&#x4EE4; dir &#x7C7B;&#x4F3C;&#x4E8E;ls rd /s/q ${path} &#x9012;&#x5F52;&#x5220;&#x9664;&#x8DEF;&#x5F84; &#x53C2;&#x8003; explain shell: &#x5728;&#x7EBF;&#x67E5;&#x770B;shell&#x547D;&#x4EE4; awesome shell: &#x7CBE;&#x5FC3;&#x5217;&#x51FA;shell&#x76F8;&#x5173;&#x5DE5;&#x5177;&#x548C;&#x8D44;&#x6E90; &#x9E1F;&#x54E5;&#x7684;Linu&#x79C1;&#x623F;&#x83DC;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"日志追查总结","slug":"log","date":"2015-09-10T12:03:00.000Z","updated":"2016-08-24T07:24:43.000Z","comments":true,"path":"2015/09/10/log/","link":"","permalink":"http://wzktravel.github.io/2015/09/10/log/","excerpt":"今天想统计一下无线的resin日志中rtype的数量和比例，然后看一个月以来的趋势，分析resin代码是否有异常。本来只要在统计平台中写hive脚本，很快就可以跑出来，但是hive仓库中resin日志竟然没有入库，更没有进行解析。于是乎，只能手动从hdfs上拉数据然后分析。在这个过程中，遇到一些问题，在这总结一下，也把解决方法贴出来。从日志中总是能发现各种各样的问题，任重而道远，还需要一一进行解决。","text":"&#x4ECA;&#x5929;&#x60F3;&#x7EDF;&#x8BA1;&#x4E00;&#x4E0B;&#x65E0;&#x7EBF;&#x7684;resin&#x65E5;&#x5FD7;&#x4E2D;rtype&#x7684;&#x6570;&#x91CF;&#x548C;&#x6BD4;&#x4F8B;&#xFF0C;&#x7136;&#x540E;&#x770B;&#x4E00;&#x4E2A;&#x6708;&#x4EE5;&#x6765;&#x7684;&#x8D8B;&#x52BF;&#xFF0C;&#x5206;&#x6790;resin&#x4EE3;&#x7801;&#x662F;&#x5426;&#x6709;&#x5F02;&#x5E38;&#x3002;&#x672C;&#x6765;&#x53EA;&#x8981;&#x5728;&#x7EDF;&#x8BA1;&#x5E73;&#x53F0;&#x4E2D;&#x5199;hive&#x811A;&#x672C;&#xFF0C;&#x5F88;&#x5FEB;&#x5C31;&#x53EF;&#x4EE5;&#x8DD1;&#x51FA;&#x6765;&#xFF0C;&#x4F46;&#x662F;hive&#x4ED3;&#x5E93;&#x4E2D;resin&#x65E5;&#x5FD7;&#x7ADF;&#x7136;&#x6CA1;&#x6709;&#x5165;&#x5E93;&#xFF0C;&#x66F4;&#x6CA1;&#x6709;&#x8FDB;&#x884C;&#x89E3;&#x6790;&#x3002;&#x4E8E;&#x662F;&#x4E4E;&#xFF0C;&#x53EA;&#x80FD;&#x624B;&#x52A8;&#x4ECE;hdfs&#x4E0A;&#x62C9;&#x6570;&#x636E;&#x7136;&#x540E;&#x5206;&#x6790;&#x3002;&#x5728;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x9047;&#x5230;&#x4E00;&#x4E9B;&#x95EE;&#x9898;&#xFF0C;&#x5728;&#x8FD9;&#x603B;&#x7ED3;&#x4E00;&#x4E0B;&#xFF0C;&#x4E5F;&#x628A;&#x89E3;&#x51B3;&#x65B9;&#x6CD5;&#x8D34;&#x51FA;&#x6765;&#x3002;&#x4ECE;&#x65E5;&#x5FD7;&#x4E2D;&#x603B;&#x662F;&#x80FD;&#x53D1;&#x73B0;&#x5404;&#x79CD;&#x5404;&#x6837;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x4EFB;&#x91CD;&#x800C;&#x9053;&#x8FDC;&#xFF0C;&#x8FD8;&#x9700;&#x8981;&#x4E00;&#x4E00;&#x8FDB;&#x884C;&#x89E3;&#x51B3;&#x3002; &#x5148;&#x5927;&#x4F53;&#x5217;&#x4E00;&#x4E0B;&#x7528;&#x5230;&#x7684;&#x77E5;&#x8BC6;&#x70B9;&#xFF1A; shell&#x4E2D;&#x5B9E;&#x73B0;trim, echo &quot; abs ssa &quot; | sed -e &apos;s/\\(^ *\\)//&apos; -e &apos;s/\\( *$\\)//&apos;&#xFF0C;&#x5176;&#x5B9E;&#x5C31;&#x662F;sed&#x7684;&#x66FF;&#x6362;&#x529F;&#x80FD;&#xFF0C;&#x628A;&#x591A;&#x4E2A;&#x7A7A;&#x683C;&#x66FF;&#x6362;&#x4E3A;&#x7A7A;&#x3002; nohup&#x65F6;&#xFF0C;&#x4E0A;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#x7ED3;&#x675F;&#x540E;&#x6267;&#x884C;&#x4E0B;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#xFF0C;&#x4F7F;&#x7528; &amp;&amp;&#xFF0C;&#x4E0D;&#x80FD;&#x7528;;&#x3002; awk&#x4F7F;&#x7528;shell&#x53D8;&#x91CF;, &quot;&apos;${var}&apos;&quot;, &#x53CC;&#x5F15;&#x53F7;&#x4E2D;&#x52A0;&#x5355;&#x5F15;&#x53F7;&#xFF0C;&#x56E0;&#x4E3A;awk&#x7528;&#x5355;&#x5F15;&#x53F7;&#x3002; uniq, sort hive&#x7C7B;&#x578B;&#x8F6C;&#x6362;: cast(pagesize as int) hive&#x6B63;&#x5219;: regexp_extract(str, regexp, [idx]) sql &#x7AD6;&#x8868;&#x53D8;&#x6A2A;&#x8868;&#xFF0C;&#x6A2A;&#x8868;&#x53D8;&#x7AD6;&#x8868; &#x5F00;&#x59CB;&#x5462;&#xFF0C;&#x8FD8;&#x4E0D;&#x77E5;&#x9053;resin&#x65E5;&#x5FD7;&#x6CA1;&#x6709;&#x5165;&#x5E93;&#xFF0C;&#x4E5F;&#x4E0D;&#x77E5;&#x9053;&#x89E3;&#x6790;&#xFF0C;&#x50BB;&#x4E4E;&#x4E4E;&#x7684;&#x5199;&#x4E86;&#x4E00;&#x4E2A;hive&#x811A;&#x672C;&#xFF0C;&#x653E;&#x5728;&#x7EDF;&#x8BA1;&#x5E73;&#x53F0;&#x4E2D;&#x8DD1;&#xFF0C;&#x5B57;&#x6BB5;&#x4E0D;&#x5BF9;&#xFF0C;&#x539F;&#x6765;&#x6CA1;&#x6709;&#x89E3;&#x6790;&#x3002;&#x6CA1;&#x89E3;&#x6790;&#x4E5F;&#x6CA1;&#x5173;&#x7CFB;&#xFF0C;&#x53CD;&#x6B63;&#x6682;&#x65F6;&#x53EA;&#x7528;&#x5230;&#x4E00;&#x4E2A;rtype&#x5B57;&#x6BB5;&#xFF0C;&#x7528;&#x6B63;&#x5219;&#x53D6;&#x5230;rtype&#x7684;&#x503C;&#x8FDB;&#x884C;&#x7EDF;&#x8BA1;&#x5457;&#x3002; 12--&#x4F7F;&#x7528;&#x5230;&#x4E86; regexp_extract(str, regexp, [idx])&#xFF0C;idx&#x662F;&#x6B63;&#x5219;&#x8868;&#x8FBE;&#x5F0F;&#x4E2D;&#x7B2C;&#x51E0;&#x4E2A;&#x53C2;&#x6570;&#xFF0C;idx&#x4E3A;0&#x8868;&#x793A;&#x6574;&#x4E2A;str&#x3002;select regexp_extract(line, &quot;rtype=(\\\\d),&quot;, 1) as rtype from resinlog where ... &#x7136;&#x800C;&#x5E76;&#x6CA1;&#x6709;&#x7ED3;&#x679C;&#x3002;&#x597D;&#x5427;&#xFF0C;&#x53EF;&#x80FD;&#x6B63;&#x5219;&#x5199;&#x7684;&#x4E0D;&#x592A;&#x5BF9;&#xFF0C;&#x4E0D;&#x7528;&#x4E86;&#xFF0C;rtype&#x603B;&#x5171;&#x5C31;&#x90A3;&#x4E48;&#x51E0;&#x79CD;&#xFF0C;&#x4E00;&#x4E2A;&#x4E00;&#x4E2A;like&#x51FA;&#x6765;&#xFF0C;&#x7136;&#x800C;&#x8FD8;&#x662F;&#x6CA1;&#x6709;&#x7ED3;&#x679C;&#xFF01;&#x55EF;&#xFF0C;&#x53D1;&#x73B0;&#x6709;&#x70B9;&#x4E0D;&#x5BF9;&#x5934;&#xFF0C;hql&#x5DF2;&#x7ECF;&#x89E3;&#x6790;&#x6210;&#x529F;&#xFF0C;&#x5C31;&#x7B97;&#x7ED3;&#x679C;&#x4E0D;&#x5BF9;&#xFF0C;&#x600E;&#x4E48;&#x4E5F;&#x4F1A;&#x6709;&#x4E2A;&#x4E1C;&#x897F;&#x51FA;&#x6765;&#x5427;&#x3002;&#x53BB;hive&#x4ED3;&#x5E93;&#x4E00;&#x770B;&#xFF0C;&#x679C;&#x7136;&#xFF0C;&#x672C;&#x6765;&#x5C31;&#x6CA1;&#x6709;&#x6570;&#x636E;&#xFF0C;&#x7ED3;&#x679C;&#x4E2A;&#x6BDB;&#x7EBF;&#x554A;&#x3002; &#x90A3;&#x5C31;&#x53EA;&#x80FD;&#x4ECE;hdfs&#x62C9;&#x53D6;&#x6570;&#x636E;&#xFF0C;&#x7528;shell grep&#x5230;&#x8FD9;&#x4E9B;&#x65E5;&#x5FD7;&#xFF0C;&#x7136;&#x540E;awk&#x628A;rtype&#x89E3;&#x51FA;&#x6765;&#xFF0C;&#x7136;&#x540E;&#x8FDB;&#x884C;&#x7EDF;&#x8BA1;&#x3002;&#x5E78;&#x597D;hdfs&#x4E2D;&#x662F;&#x6709;&#x65E5;&#x5FD7;&#x7684;&#xFF0C;&#x81F3;&#x5C11;&#x4E0D;&#x7528;&#x4ECE;&#x4E00;&#x53F0;&#x53F0;&#x670D;&#x52A1;&#x5668;&#x4E0A;&#x624B;&#x52A8;&#x62C9;&#x53D6;&#x6570;&#x636E;&#x3002;&#x53EA;&#x662F;&#x770B;&#x8D8B;&#x52BF;&#xFF0C;&#x6CA1;&#x5FC5;&#x8981;&#x4E00;&#x6574;&#x5929;&#x6570;&#x636E;&#xFF0C;&#x53EA;&#x53D6;&#x4E00;&#x4E2A;&#x5C0F;&#x65F6;&#x7684;&#x5C31;&#x53EF;&#x4EE5;&#x4E86;&#x3002;&#x4E3A;&#x4E86;&#x540E;&#x9762;&#x4E00;&#x4E2A;&#x6708;&#x6570;&#x636E;&#x7684;&#x5206;&#x6790;&#xFF0C;&#x628A;&#x65E5;&#x671F;&#x5B9A;&#x4E49;&#x6210;&#x53D8;&#x91CF;&#x4E86;&#x3002; 1234month=201509date=$month&quot;10&quot;time=12nohup hadoop fs -text hftp://hdfspath/$month/$date/resinlog.$date$time* | fgrep rtype | awk &apos;{split($0, a, &quot;rtype=&quot;); split(a[2], b, &quot;,&quot;); print b[1] }&apos; &gt; rtype.$date$time.log &amp; &#x65E5;&#x5FD7;&#x6765;&#x4E86;&#xFF0C;&#x6B64;&#x65F6;rtype.time.log&#x4E2D;&#xFF0C;&#x5168;&#x662F;rtype&#x7684;&#x503C;&#xFF0C;0,10,20,21,30&#x7B49;&#xFF0C;&#x5148;&#x7EDF;&#x8BA1;&#x4E00;&#x4E0B;&#x5404;&#x79CD;rtype&#x7684;&#x6570;&#x91CF;&#x3002;&#x60F3;&#x8981;&#x7528;uniq&#xFF0C;&#x5148;&#x628A;&#x6570;&#x636E;sort&#x4E00;&#x4E0B;&#xFF0C;uniq&#x53EA;&#x80FD;uniq&#x7D27;&#x6328;&#x7740;&#x7684;&#x76F8;&#x540C;&#x7684;&#x6570;&#x636E;&#x3002;sort&#x548C;uniq&#x5F88;&#x6709;&#x7528;&#xFF0C;&#x53EF;&#x4EE5;man&#x4E00;&#x4E0B;&#x7528;&#x6CD5;&#x3002; 1cat rtype.time.log | sort | uniq -c | sort -k1 -rn &gt; rtype.time.log.sort Ok&#xFF0C;&#x5F88;&#x597D;&#xFF0C;&#x7EDF;&#x8BA1;&#x51FA;&#x6765;&#x4E86;&#xFF0C;&#x524D;&#x9762;&#x662F;&#x6570;&#x91CF;&#xFF0C;&#x540E;&#x9762;&#x662F;rtype&#x7684;&#x503C;&#x3002; 1234565340421 0 44159 10 138 20 123 30 14 31 11 21 &#x7ED9;&#x4E00;&#x4E2A;&#x5B8C;&#x6574;&#x7248;&#x7684;shell&#x811A;&#x672C;&#xFF0C;&#x5BF9;&#x4E8E;8&#x6708;&#x4EFD;&#x548C;9&#x6708;&#x4EFD;&#x624B;&#x52A8;&#x6539;&#x4E00;&#x4E0B;&#x5373;&#x53EF;&#x3002;&#x8FD8;&#x5F97;&#x6CE8;&#x610F;seq&#x3002; 123456month=201508time=12for day in $(seq 10 20); do date=$month$day nohup hadoop fs -text hftp://hdfspath/$month/$date/resinlog.$date$time* | fgrep rtype | awk &apos;{split($0, a, &quot;rtype=&quot;); split(a[2], b, &quot;,&quot;); print b[1] }&apos; &gt; rtype.$date$time.log &amp;&amp; cat rtype.$date$time.log | sort | uniq -c | sort -k1 -rn &gt; rtype.$date$time.log.sort &amp;done &#x8DD1;&#x4E86;&#x4E00;&#x5C0F;&#x4F1A;&#x513F;&#xFF0C;&#x5495;&#x565C;&#x5495;&#x565C;&#x751F;&#x6210;&#x4E86;&#x4E00;&#x5806;&#x6587;&#x4EF6;&#x3002;&#x73B0;&#x5728;&#x5404;&#x5929;&#x7684;&#x6570;&#x636E;&#x5DF2;&#x7ECF;&#x6709;&#x4E86;&#xFF0C;&#x600E;&#x4E48;&#x770B;&#x8D8B;&#x52BF;&#x5462;&#xFF1F;&#x6211;&#x7684;&#x7ECF;&#x9A8C;&#x662F;&#x5728;excel&#x4E2D;&#x751F;&#x6210;&#x56FE;&#x8868;&#x3002;&#x600E;&#x4E48;&#x628A;&#x8FD9;&#x4E48;&#x591A;&#x6587;&#x4EF6;&#x7684;&#x6570;&#x636E;&#x5F04;&#x5230;excel&#x4E2D;&#x5462;&#xFF1F;&#x8FD9;&#x4E9B;&#x6570;&#x636E;&#x8FD8;&#x5F97;&#x5904;&#x7406;&#x4E00;&#x4E0B;&#xFF0C;&#x6700;&#x597D;&#x662F;&#x751F;&#x6210;&#x4E00;&#x5F20;&#x8868;&#xFF0C;&#x8FD9;&#x6837;&#x5728;excel&#x4E2D;&#x751F;&#x6210;&#x7684;&#x56FE;&#x8868;&#x5C31;&#x66F4;&#x5BB9;&#x6613;&#x5BF9;&#x6BD4;&#x3002;&#x8868;&#x7ED3;&#x6784;&#x5982;&#x4E0B;&#xFF1A; 12345date rtype0&#x6570;&#x91CF; rtype1&#x6570;&#x91CF; rtype2&#x6570;&#x91CF; ...2015-08-20 10000 10000 100002015-08-21 10000 10000 100002015-08-22 10000 10000 10000... &#x90A3;&#x600E;&#x4E48;&#x751F;&#x6210;&#x8FD9;&#x5F20;&#x8868;&#x5462;&#xFF1F;&#x6211;&#x6BD4;&#x8F83;&#x559C;&#x6B22;&#x5728;mysql&#x4E2D;&#x5904;&#x7406;&#x3002;&#x55EF;&#xFF0C;&#x8981;&#x7075;&#x6D3B;&#x8FD0;&#x7528;&#x5404;&#x79CD;&#x5DE5;&#x5177;&#x3002;&#x867D;&#x7136;shell&#x4E5F;&#x80FD;&#x505A;&#x5230;&#xFF0C;&#x4F46;&#x592A;&#x7E41;&#x7410;&#x3002;&#x600E;&#x4E48;&#x5904;&#x7406;&#x8FD9;&#x4E9B;&#x6570;&#x636E;&#x5462;&#xFF1F;&#x628A;&#x5404;&#x4E2A;sort&#x6587;&#x4EF6;&#x4E2D;&#x6BCF;&#x4E00;&#x884C;trim&#x4E00;&#x4E0B;&#xFF0C;&#x6216;&#x8005;&#x6362;&#x4E00;&#x4E0B;&#x683C;&#x5F0F;&#xFF0C;&#x65B9;&#x4FBF;&#x5411;mysql&#x4E2D;&#x63D2;&#x5165;&#x6570;&#x636E;&#x3002;&#x5E76;&#x4E14;&#x8FD8;&#x9700;&#x8981;&#x5728;&#x5404;&#x81EA;&#x6587;&#x4EF6;&#x4E2D;&#x63D2;&#x5165;&#x81EA;&#x5DF1;&#x7684;&#x65F6;&#x95F4;&#x3002; 123for day in $(seq 10 20); do cat rtype.201508${day}12.log.sort | sed &apos;s/ *$//g&apos;|sed &apos;s/^ *//g&apos; | awk &apos;{print &quot;201508&quot;&apos;${day}&apos;&quot;\\t&quot;$2&quot;\\t&quot;$1}&apos; &gt; 201509${day}.logdone ok&#xFF0C;&#x73B0;&#x5728;&#x770B;&#x770B;&#x5904;&#x7406;&#x4E4B;&#x540E;&#x7684;&#x6837;&#x5B50;&#xFF0C;&#x770B;&#x8D77;&#x6765;&#x50CF;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x5E93;&#x8868;&#x4E86;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;&#x6211;&#x4EEC;&#x8981;&#x7684;&#x7ED3;&#x679C;&#x3002; 12345620150910 0 534042120150910 10 4415920150910 20 13820150910 30 12320150910 31 1420150910 21 11 &#x4EE5;&#x4E0A;&#x6570;&#x636E;&#x5904;&#x7406;&#x90FD;&#x662F;&#x5728;linxu&#x865A;&#x673A;&#x4E2D;&#x505A;&#x7684;&#xFF0C;&#x73B0;&#x5728;&#x6211;&#x8981;&#x628A;&#x6570;&#x636E;&#x62FF;&#x5230;windows&#x5DE5;&#x4F5C;&#x673A;&#x4E0A;&#x5904;&#x7406;&#xFF0C;&#x4E3B;&#x8981;&#x662F;&#x4E3A;&#x4E86;&#x4F7F;&#x7528;navicat&#x3002;&#x628A;&#x4E0A;&#x9762;&#x7684;&#x6240;&#x6709;&#x6587;&#x4EF6;&#x5408;&#x5E76;&#x5230;&#x540C;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x7136;&#x540E;sz&#x5230;windows&#x672C;&#x5730;&#x3002;&#x5728;mysql&#x4E2D;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x8868;rtype&#xFF0C;&#x6709;&#x4E09;&#x5217;&#xFF0C;date,rtype,count&#x3002;&#x7136;&#x540E;&#x628A;&#x8FD9;&#x4E2A;&#x6587;&#x4EF6;load&#x5230;msyql&#x4E2D;&#x3002; 1LOAD DATA INFILE &apos;rtype.log&apos; INTO TABLE rtype FIELDS TERMINATED BY &apos;\\t&apos;; &#x73B0;&#x5728;&#x770B;&#x8D77;&#x6765;&#x662F;&#x4E00;&#x4E2A;&#x7AD6;&#x8868;&#xFF0C;&#x6570;&#x636E;&#x6BD4;&#x8F83;&#x5206;&#x6563;&#xFF0C;&#x5728;excel&#x4E2D;&#x4E0D;&#x597D;&#x751F;&#x6210;&#x56FE;&#x8868;&#xFF0C;&#x6240;&#x4EE5;&#x5C06;&#x8FD9;&#x4E2A;&#x8868;&#x53D8;&#x6210;&#x4E0A;&#x9762;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x90A3;&#x6837;&#x3002; 1234567891011121314select date, sum(rtype21) as rtype21, sum(rtype30) as rtype30, sum(rtype31) as rtype31from(select date, case when rtype=21 then count end as rtype21 , case when rtype=30 then count end as rtype30 , case when rtype=31 then count end as rtype31from rtype) agroup by date; &#x751F;&#x6210;&#x7684;&#x6570;&#x636E;&#x5927;&#x7EA6;&#x662F;&#x8FD9;&#x4E2A;&#x6837;&#x5B50;&#x7684;&#xFF1A;&#x7136;&#x540E;&#x5C06;&#x6570;&#x636E;&#x4ECE;mysql&#x4E2D;&#x5BFC;&#x51FA;&#x5230;excel&#xFF0C;&#x6211;&#x662F;&#x7528;&#x7684;navicat&#x81EA;&#x5E26;&#x529F;&#x80FD;&#x3002; excel&#x751F;&#x6210;&#x56FE;&#x8868;&#x53EF;&#x4EE5;&#x4E0A;&#x7F51;&#x67E5;&#x4E00;&#x4E0B;&#xFF0C;&#x5F88;&#x7B80;&#x5355;&#x3002;&#x6700;&#x7EC8;&#x7684;&#x6548;&#x679C;&#x5982;&#x4E0B;&#xFF1A; &#x54C8;&#x54C8;&#x54C8;&#xFF0C;&#x5927;&#x529F;&#x544A;&#x6210;&#xFF0C;&#x53EF;&#x4EE5;&#x5411;&#x8001;&#x5927;&#x4EA4;&#x4EE3;&#x4E86;&#xFF0C;&#x60F3;&#x60F3;&#x8FD8;&#x662F;&#x6709;&#x70B9;&#x5C0F;&#x6FC0;&#x52A8;&#x5462;&#x3002; &#x54ED;&#x3002;&#x6211;&#x4F1A;&#x8BF4;&#x65B9;&#x5411;&#x5B8C;&#x5168;&#x9519;&#x4E86;&#x5417;&#xFF1F; &#x53C2;&#x8003; &#x8FD9;&#x7BC7;&#x6587;&#x7AE0;&#x53EF;&#x4EE5;&#x5E2E;&#x4F60;&#x638C;&#x63E1;&#x547D;&#x4EE4;&#x884C;&#x7684;&#x827A;&#x672F;","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"},{"name":"hive","slug":"hive","permalink":"http://wzktravel.github.io/tags/hive/"}]},{"title":"Spark RDD学习","slug":"spark-rdd","date":"2015-08-31T16:12:43.000Z","updated":"2016-08-24T07:25:15.000Z","comments":true,"path":"2015/09/01/spark-rdd/","link":"","permalink":"http://wzktravel.github.io/2015/09/01/spark-rdd/","excerpt":"RDD(resilient distributed dataset)是spark核心概念之一，spark中数据的处理过程其实是rdd之间的互相转换，在此对rdd的一些东西进行整理。","text":"RDD(resilient distributed dataset)&#x662F;spark&#x6838;&#x5FC3;&#x6982;&#x5FF5;&#x4E4B;&#x4E00;&#xFF0C;spark&#x4E2D;&#x6570;&#x636E;&#x7684;&#x5904;&#x7406;&#x8FC7;&#x7A0B;&#x5176;&#x5B9E;&#x662F;rdd&#x4E4B;&#x95F4;&#x7684;&#x4E92;&#x76F8;&#x8F6C;&#x6362;&#xFF0C;&#x5728;&#x6B64;&#x5BF9;rdd&#x7684;&#x4E00;&#x4E9B;&#x4E1C;&#x897F;&#x8FDB;&#x884C;&#x6574;&#x7406;&#x3002; &#x6982;&#x5FF5;RDD: resilient distributed dataset, &#x5F39;&#x6027;&#x5206;&#x5E03;&#x5F0F;&#x6570;&#x636E;&#x96C6; A collection of elements partitioned across the nodes of the cluster that can be operated on in parallel. (&#x96C6;&#x5408;&#x3001;&#x5206;&#x5E03;&#x5F0F;,&#x5E76;&#x884C;&#x8BA1;&#x7B97;) Created by starting with a file in the Hadoop file system (or any other Hadoop-supported file system), or an existing Scala collection in the driver program, and transforming it. (&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x6765;&#x81EA;scala&#x96C6;&#x5408;&#x6216;&#x5916;&#x90E8;&#x5B58;&#x50A8;,&#x53EF;&#x4EE5;&#x8FDB;&#x884C;transform&#x548C;action) Persist an RDD in memory, allowing it to be reused efficiently across parallel operations. (&#x6301;&#x4E45;&#x5316;&#x4E2D;&#x95F4;RDD,&#x52A0;&#x901F;&#x8BA1;&#x7B97;) RDDs automatically recover from node failures. (&#x5931;&#x8D25;&#x540E;&#x57FA;&#x4E8E;lineage&#x91CD;&#x5EFA;) &#x521B;&#x5EFA;RDD&#x6765;&#x81EA;&#x96C6;&#x5408;123val data = Array(1, 2, 3, 4, 5)val distData = sc.parallelize(data)val distData2 = sc.parallelize(data, 10) //&#x6307;&#x5B9A;partition&#x6570;&#x91CF; &#x6765;&#x81EA;&#x5916;&#x90E8;&#x6570;&#x636E;Text File12val localFile = sc.textFile(&quot;file://path/data.txt&quot;) val hdfsFile = sc.textFile(&quot;hdfs://path/data.txt&quot;) Sequence File1sc.sequenceFile[K, V] Hadoop InputFormat12sc.hadoopRDD //old api: org.apache.hadoop.mapredsc.newAPIHadoopRDD //new api: org.apache.hadoop.mapreduce RDD&#x64CD;&#x4F5C;RDD&#x5305;&#x62EC;&#x4E24;&#x79CD;&#x7C7B;&#x578B;&#x7684;&#x64CD;&#x4F5C;: Transformation &#x548C; Action&#x3002;Transformation&#x4ECE;&#x5DF2;&#x6709;&#x7684;RDD&#x751F;&#x6210;&#x65B0;&#x7684;RDD&#xFF0C;lazy&#x6267;&#x884C;&#xFF1B;Action&#x89E6;&#x53D1;RDD&#x4E0A;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x5230;driver&#x3002; Transformation Transformation Example map(func) rdd.map(x =&gt; x*x) filter(func) rdd.filter(x =&gt; x/2==0) flatMap(func) rdd.flatMap(x =&gt; ) union(otherRDD) rdd1.union(rdd2) distinct([numTasks]) rdd.distinct() groupByKey([numTasks]) rdd.map((_, 1)).groupByKey() reduceByKey(func, [numTasks]) rdd.map((, 1)).reduceByKey(+_) sortByKey([ascending], [numTasks]) rdd.sortByKey() join(otherDataset, [numTasks]) rdd1.join(rdd2) cogroup(otherDataset, [numTasks]) rdd1.cogroup(rdd2) cartesian(otherDataset) rdd1.cartesian(rdd2) coalesce(numPartitions) rdd.coalesce(50) repartition(numPartitions) rdd.repartition(100) Action Action Example reduce(func) rdd.reduce(+) collect() rdd.collect() count() rdd.count() first() rdd.first() take(n) rdd.take(10) saveAsTextFile(path) rdd.saveAsTextFile(&#x201C;/output&#x201D;) saveAsSequenceFile(path) rdd.saveAsSequenceFile(&#x201C;/output&#x201D;) saveAsObjectFile(path) rdd.saveAsObjectFile(&#x201C;/output&#x201D;) countByKey() rdd.countByKey() foreach(func) rdd.foreach(func) &#x793A;&#x4F8B; WordCount step-1: &#x6570;&#x636E;&#x8BFB;&#x5165;, sc.textFile &#x521B;&#x5EFA;RDD 1val rdd1 = sc.textFile(&quot;README.md&quot;) step-2: map&#x64CD;&#x4F5C;, flatMap, map Transformation 1val rdd2 = rdd1.flatMap(x =&gt; x.split(&quot; &quot;)).map(x =&gt; (x, 1)) step-3: reduce&#x64CD;&#x4F5C;&#xFF0C;reduceByKey Transformation(shuffle) 1val rdd3 = rdd2.reduceByKey(v =&gt; v + v) step-4: &#x7ED3;&#x679C;&#x8F93;&#x51FA;, collect Action 1rdd3.collect() RDD&#x6301;&#x4E45;&#x5316;&#x4F7F;&#x7528;cache()/persist()&#x5BF9;RDD&#x8FDB;&#x884C;&#x6301;&#x4E45;&#x5316;,&#x9ED8;&#x8BA4;&#x5185;&#x5B58;. storage level Storage Level Meaning MEMORY_ONLY Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they&#x2019;re needed. This is the default level. MEMORY_AND_DISK Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that don&#x2019;t fit on disk, and read them from there when they&#x2019;re needed. MEMORY_ONLY_SER Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read. MEMORY_AND_DISK_SER Similar to MEMORY_ONLY_SER, but spill partitions that don&#x2019;t fit in memory to disk instead of recomputing them on the fly each time they&#x2019;re needed. DISK_ONLY Store the RDD partitions only on disk. MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc. Same as the levels above, but replicate each partition on two cluster nodes. OFF_HEAP (experimental) Store RDD in serialized format in Tachyon. Compared to MEMORY_ONLY_SER, OFF_HEAP reduces garbage collection overhead and allows executors to be smaller and to share a pool of memory, making it attractive in environments with large heaps or multiple concurrent applications. Furthermore, as the RDDs reside in Tachyon, the crash of an executor does not lead to losing the in-memory cache. In this mode, the memory in Tachyon is discardable. Thus, Tachyon does not attempt to reconstruct a block that it evicts from memory. If you plan to use Tachyon as the off heap store, Spark is compatible with Tachyon out-of-the-box. Please refer to this page for the suggested version pairings. &#x7ECF;&#x9A8C; &#x6700;&#x597D;&#x9009;&#x7528;MEMORY_ONLY &#x82E5;&#x5185;&#x5B58;&#x4E0D;&#x591F;,&#x5C1D;&#x8BD5;MEMORY_ONLY_SER(Kryo serialization&#x6548;&#x7387;&#x9AD8;&#x4E8E;Java serialization) &#x9664;&#x975E;RDD&#x7684;&#x8BA1;&#x7B97;&#x5F88;&#x590D;&#x6742;&#x6216;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x5F88;&#x591A;, &#x518D;&#x5C06;&#x5176;spill&#x5230;&#x78C1;&#x76D8;;&#x5426;&#x5219;,&#x5176;&#x6548;&#x7387;&#x4E0E;&#x4ECE;&#x6E90;&#x7AEF;&#x91CD;&#x7B97;&#x5DEE;&#x4E0D;&#x591A;&#x3002; &#x82E5;&#x60F3;&#x63D0;&#x9AD8;&#x5BB9;&#x9519;, &#x63D0;&#x5347;&#x5176;replicated storage level &#x4F7F;&#x7528;Tachyon OFF_HEAP:executor&#x6302;&#x6389;&#x7F13;&#x5B58;&#x6570;&#x636E;&#x4E0D;&#x4E22;&#x5931;&#x3001;&#x51CF;&#x5C11;executor&#x7684;gc&#x5F00;&#x9500;&#x3001;&#x4E0D;&#x540C;executor&#x95F4;&#x5171;&#x4EAB;&#x7F13;&#x5B58; &#x5171;&#x4EAB;&#x53D8;&#x91CF;Broadcast Variables &#x4F7F;&#x7528;sc.broadcase()&#x5C06;&#x53D8;&#x91CF;&#x5206;&#x53D1;&#x5230;&#x6240;&#x6709;&#x5DE5;&#x4F5C;&#x8282;&#x70B9; &#x5DE5;&#x4F5C;&#x8282;&#x70B9;&#x4F7F;&#x7528;value&#x83B7;&#x53D6;&#x53D8;&#x91CF;&#x503C; &#x4E00;&#x65E6;&#x88AB;&#x5206;&#x53D1;&#xFF0C;&#x4E0D;&#x80FD;&#x66F4;&#x6539; 12345scala&gt; val broadcastVar = sc.broadcast(Array(1,2,3))broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(0)scala&gt; broadcastVar.valueres1: Array[Int] = Array(1, 2, 3) Accumulator executor&#x4F7F;&#x7528; &#x201C;+=&#x201D; &#x64CD;&#x4F5C;&#x7B26;&#x589E;&#x52A0;&#x8BA1;&#x6570; driver&#x4F7F;&#x7528;value&#x8BFB;&#x53D6;&#x6570;&#x503C; 1234567scala&gt; val acc = sc.accumulator(0, &quot;test accumulator&quot;)acc: org.apache.spark.Accumulator[Int] = 0scala&gt; sc.parallelize(Array(1,2,3,4)).foreach(x=&gt; acc+=x)scala&gt; acc.valueres3: Int = 10 RDD&#x4F9D;&#x8D56;&#x5173;&#x7CFB;&#x7A84;&#x4F9D;&#x8D56;(narrow dependencies) &#x5B50;RDD&#x7684;&#x6BCF;&#x4E2A;&#x5206;&#x533A;&#x4F9D;&#x8D56;&#x4E8E;&#x5E38;&#x6570;&#x4E2A;&#x7236;RDD&#x5206;&#x533A;&#xFF08;&#x5373;&#x4E0E;&#x6570;&#x636E;&#x89C4;&#x6A21;&#x65E0;&#x5173;&#xFF09; &#x8F93;&#x5165;&#x8F93;&#x51FA;&#x4E00;&#x5BF9;&#x4E00;&#x7684;&#x7B97;&#x5B50;&#xFF0C;&#x4E14;&#x7ED3;&#x679C;RDD&#x7684;&#x5206;&#x533A;&#x7ED3;&#x6784;&#x4E0D;&#x53D8;&#xFF0C;&#x5982;map&#x3001;flatMap &#x8F93;&#x5165;&#x8F93;&#x51FA;&#x4E00;&#x5BF9;&#x4E00;&#xFF0C;&#x4F46;&#x7ED3;&#x679C;RDD&#x7684;&#x5206;&#x533A;&#x7ED3;&#x6784;&#x53D1;&#x751F;&#x53D8;&#x5316;&#xFF0C;&#x5982;union&#x3001;coalesce &#x4ECE;&#x8F93;&#x5165;&#x4E2D;&#x9009;&#x62E9;&#x90E8;&#x5206;&#x5143;&#x7D20;&#x7684;&#x7B97;&#x5B50;&#xFF0C;&#x5982;filter&#x3001;distinct&#x3001;subtract&#x3001;sample &#x5BBD;&#x4F9D;&#x8D56;(wide dependencies) &#x5B50;RDD&#x7684;&#x6BCF;&#x4E2A;&#x5206;&#x533A;&#x4F9D;&#x8D56;&#x4E8E;&#x6240;&#x6709;&#x7236;RDD&#x5206;&#x533A; &#x5BF9;&#x5355;&#x4E2A;RDD&#x57FA;&#x4E8E;Key&#x8FDB;&#x884C;&#x91CD;&#x7EC4;&#x548C;Reduce&#xFF0C;&#x5982;groupByKey&#x3001;reduceByKey &#x5BF9;&#x4E24;&#x4E2A;RDD&#x57FA;&#x4E8E;Key&#x8FDB;&#x884C;Join&#x548C;&#x91CD;&#x7EC4;&#xFF0C;&#x5982;join RDD&#x5BB9;&#x9519;&#x652F;&#x6301;&#x5BB9;&#x9519;&#x901A;&#x5E38;&#x91C7;&#x7528;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#xFF1A;&#x6570;&#x636E;&#x590D;&#x5236;&#x6216;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x3002;&#x5BF9;&#x4E8E;&#x4EE5;&#x6570;&#x636E;&#x4E3A;&#x4E2D;&#x5FC3;&#x7684;&#x7CFB;&#x7EDF;&#x800C;&#x8A00;&#xFF0C;&#x8FD9;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#x90FD;&#x975E;&#x5E38;&#x6602;&#x8D35;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x9700;&#x8981;&#x8DE8;&#x96C6;&#x7FA4;&#x7F51;&#x7EDC;&#x62F7;&#x8D1D;&#x5927;&#x91CF;&#x6570;&#x636E;&#xFF0C;&#x6BD5;&#x7ADF;&#x5E26;&#x5BBD;&#x7684;&#x6570;&#x636E;&#x8FDC;&#x8FDC;&#x4F4E;&#x4E8E;&#x5185;&#x5B58;&#x3002; RDD&#x5929;&#x751F;&#x662F;&#x652F;&#x6301;&#x5BB9;&#x9519;&#x7684;&#x3002;&#x9996;&#x5148;&#xFF0C;&#x5B83;&#x81EA;&#x8EAB;&#x662F;&#x4E00;&#x4E2A;&#x4E0D;&#x53D8;&#x7684;(immutable)&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x5176;&#x6B21;&#xFF0C;&#x5B83;&#x80FD;&#x591F;&#x8BB0;&#x4F4F;&#x6784;&#x5EFA;&#x5B83;&#x7684;&#x64CD;&#x4F5C;&#x56FE;&#xFF08;Graph of Operation&#xFF09;&#xFF0C;&#x56E0;&#x6B64;&#x5F53;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x7684;Worker&#x5931;&#x8D25;&#x65F6;&#xFF0C;&#x5B8C;&#x5168;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x64CD;&#x4F5C;&#x56FE;&#x83B7;&#x5F97;&#x4E4B;&#x524D;&#x6267;&#x884C;&#x7684;&#x64CD;&#x4F5C;&#xFF0C;&#x8FDB;&#x884C;&#x91CD;&#x65B0;&#x8BA1;&#x7B97;&#x3002;&#x7531;&#x4E8E;&#x65E0;&#x9700;&#x91C7;&#x7528;replication&#x65B9;&#x5F0F;&#x652F;&#x6301;&#x5BB9;&#x9519;&#xFF0C;&#x5F88;&#x597D;&#x5730;&#x964D;&#x4F4E;&#x4E86;&#x8DE8;&#x7F51;&#x7EDC;&#x7684;&#x6570;&#x636E;&#x4F20;&#x8F93;&#x6210;&#x672C;&#x3002; &#x4E0D;&#x8FC7;&#xFF0C;&#x5728;&#x67D0;&#x4E9B;&#x573A;&#x666F;&#x4E0B;&#xFF0C;Spark&#x4E5F;&#x9700;&#x8981;&#x5229;&#x7528;&#x8BB0;&#x5F55;&#x65E5;&#x5FD7;&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x652F;&#x6301;&#x5BB9;&#x9519;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5728;Spark Streaming&#x4E2D;&#xFF0C;&#x9488;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;update&#x64CD;&#x4F5C;&#xFF0C;&#x6216;&#x8005;&#x8C03;&#x7528;Streaming&#x63D0;&#x4F9B;&#x7684;window&#x64CD;&#x4F5C;&#x65F6;&#xFF0C;&#x5C31;&#x9700;&#x8981;&#x6062;&#x590D;&#x6267;&#x884C;&#x8FC7;&#x7A0B;&#x7684;&#x4E2D;&#x95F4;&#x72B6;&#x6001;&#x3002;&#x6B64;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x901A;&#x8FC7;Spark&#x63D0;&#x4F9B;&#x7684;checkpoint&#x673A;&#x5236;&#xFF0C;&#x4EE5;&#x652F;&#x6301;&#x64CD;&#x4F5C;&#x80FD;&#x591F;&#x4ECE;checkpoint&#x5F97;&#x5230;&#x6062;&#x590D;&#x3002; &#x9488;&#x5BF9;RDD&#x7684;wide dependency&#xFF0C;&#x6700;&#x6709;&#x6548;&#x7684;&#x5BB9;&#x9519;&#x65B9;&#x5F0F;&#x540C;&#x6837;&#x8FD8;&#x662F;&#x91C7;&#x7528;checkpoint&#x673A;&#x5236;&#x3002;&#x4E0D;&#x8FC7;&#xFF0C;&#x4F3C;&#x4E4E;Spark&#x7684;&#x6700;&#x65B0;&#x7248;&#x672C;&#x4ECD;&#x7136;&#x6CA1;&#x6709;&#x5F15;&#x5165;auto checkpointing&#x673A;&#x5236;&#x3002; &#x53C2;&#x8003; spark programming guide Resilient Distributed Datasets: A Fault-tolerant Abstraction for In-Memory Cluster Computing: Matei Zaharia&#x505A;&#x7684;spark&#x8BBA;&#x6587; Introduction to Spark Internals: Spark&#x4F5C;&#x8005;&#x5728;2012 Developer Meetup&#x4E0A;&#x505A;&#x7684;&#x6F14;&#x8BB2; RDD&#xFF1A;&#x57FA;&#x4E8E;&#x5185;&#x5B58;&#x7684;&#x96C6;&#x7FA4;&#x8BA1;&#x7B97;&#x5BB9;&#x9519;&#x62BD;&#x8C61; &#x7406;&#x89E3;Spark&#x6838;&#x5FC3;RDD","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://wzktravel.github.io/tags/scala/"},{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"}]},{"title":"spark学习笔记","slug":"spark-learning","date":"2015-08-16T10:21:16.000Z","updated":"2016-07-14T03:16:31.000Z","comments":true,"path":"2015/08/16/spark-learning/","link":"","permalink":"http://wzktravel.github.io/2015/08/16/spark-learning/","excerpt":"整理一下自己之前的spark学习笔记，温故而知新。","text":"&#x6574;&#x7406;&#x4E00;&#x4E0B;&#x81EA;&#x5DF1;&#x4E4B;&#x524D;&#x7684;spark&#x5B66;&#x4E60;&#x7B14;&#x8BB0;&#xFF0C;&#x6E29;&#x6545;&#x800C;&#x77E5;&#x65B0;&#x3002; spark rdd&#x76F8;&#x5173;&#x4F20;&#x9001;&#x95E8;spark rdd &#x542F;&#x52A8;spark-shelllocal&#x6A21;&#x5F0F;MASTER=local bin/spark-shell local master&#x6A21;&#x5F0F;local cluster&#x6A21;&#x5F0F;&#x662F;&#x4E00;&#x79CD;&#x4F2A;cluster&#x6A21;&#x5F0F;&#xFF0C;&#x5728;&#x5355;&#x673A;&#x73AF;&#x5883;&#x4E0B;&#x6A21;&#x62DF;standalone&#x7684;&#x96C6;&#x7FA4;&#xFF0C;&#x542F;&#x52A8;&#x987A;&#x5E8F;&#x5206;&#x522B;&#x5982;&#x4E0B; &#x542F;&#x52A8;master &#x542F;&#x52A8;worker &#x542F;&#x52A8;spark-shell &#x542F;&#x52A8;master&#x4FEE;&#x6539;&#x914D;&#x7F6E; &#x8FDB;&#x5165;$SPARK_HOME/conf&#x76EE;&#x5F55; cp spark-env.sh.template spark-env.sh &#x5411;spark-env.sh&#x4E2D;&#x6DFB;&#x52A0; export SPARK_MASTER_IP=localhost export SPARK_LOCAL_IP=localhost export SPARK_MASTER_PORT=7077 export SPARK_MASTER_WEBUI_PORT=8081 #&#x9ED8;&#x8BA4;8080 &#x542F;&#x52A8;master$SPARK_HOME/sbin/start-master.sh master&#x4E3B;&#x8981;&#x662F;&#x8FD0;&#x884C;&#x7C7B; org.apache.spark.deploy.master.Master&#xFF0C;&#x5728;8081&#x7AEF;&#x53E3;&#x542F;&#x52A8;&#x76D1;&#x542C;&#xFF0C;&#x65E5;&#x5FD7;&#x5728;logs&#x4E0B; &#x542F;&#x52A8;workerbin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077 -i 127.0.0.1 -c 1 -m 512M master web ui&#x7684;&#x5730;&#x5740;&#x662F;http://localhost:8081 &#x542F;&#x52A8;spark-shell./bin/spark-shell --master spark://localhost:7077 http://localhost:4040 &#x53EF;&#x4EE5;&#x67E5;&#x770B;spark jobs,stags,storage,environment,executors&#x7B49;&#x4FE1;&#x606F; &#x53C2;&#x8003; sbt&#x4ECB;&#x7ECD;&#x548C;&#x914D;&#x7F6E; Spark Overview Introduction to Spark Internals spark&#x6E90;&#x7801;&#x8D70;&#x8BFB;","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://wzktravel.github.io/tags/scala/"},{"name":"spark","slug":"spark","permalink":"http://wzktravel.github.io/tags/spark/"}]},{"title":"mac的一些小技巧和实用小软件","slug":"mac-tips","date":"2015-08-14T14:53:00.000Z","updated":"2016-08-24T07:25:11.000Z","comments":true,"path":"2015/08/14/mac-tips/","link":"","permalink":"http://wzktravel.github.io/2015/08/14/mac-tips/","excerpt":"mac的一些小技巧和实用小软件","text":"mac&#x7684;&#x4E00;&#x4E9B;&#x5C0F;&#x6280;&#x5DE7;&#x548C;&#x5B9E;&#x7528;&#x5C0F;&#x8F6F;&#x4EF6; &#x6280;&#x5DE7; &#x5728;&#x7EC8;&#x7AEF;&#x4E2D;&#x6253;&#x5F00;finder&#xFF0C; open .&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;open {path} chrome&#x7981;&#x7528;flash&#xFF1A;chrome://plugins/ crontab env EDITOR=vim crontab -e &#x7EC8;&#x7AEF;&#x4E2D;&#x590D;&#x5236;&#x9ECF;&#x8D34; pbcopy, pbpaste &#x8F6F;&#x4EF6; sizeup&#xFF0C;&#x5FEB;&#x901F;&#x5360;&#x6EE1;&#x5168;&#x5C4F;&#xFF0C;&#x5C4F;&#x5E55;&#x53F3;&#x4FA7;/&#x5DE6;&#x4FA7;&#x7B49;&#x7B49;&#x7B49; f.lux&#xFF0C;&#x6839;&#x636E;&#x65F6;&#x95F4;&#x8C03;&#x6574;&#x5C4F;&#x5E55;&#x4EAE;&#x5EA6; Alfred&#xFF0C;&#x529F;&#x80FD;&#x5F88;&#x5F3A;&#x5927;&#xFF0C;&#x4F46;&#x6211;&#x6CA1;&#x600E;&#x4E48;&#x7528;&#x5230; Dash&#xFF0C;&#x5404;&#x79CD;&#x6587;&#x6863; Synergy&#xFF0C;&#x591A;&#x53F0;&#x7535;&#x8111;&#x5171;&#x7528;&#x540C;&#x4E00;&#x5957;&#x952E;&#x76D8;&#x9F20;&#x6807; Visual Studio Code&#xFF0C;&#x5F3A; Parallels Desktop &#x865A;&#x62DF;&#x673A; HTML5 player&#x4E66;&#x7B7E; 1javascript:(function()%7Bvar%20l%20=%20document.createElement(&apos;link&apos;);l.setAttribute(&apos;rel&apos;,&apos;stylesheet&apos;);l.setAttribute(&apos;media&apos;,&apos;all&apos;);l.setAttribute(&apos;href&apos;,&apos;http://zythum.sinaapp.com/youkuhtml5playerbookmark/youkuhtml5playerbookmark2.css&apos;);document.body.appendChild(l);var%20s%20=%20document.createElement(&apos;script&apos;);s.setAttribute(&apos;src&apos;,&apos;http://zythum.sinaapp.com/youkuhtml5playerbookmark/youkuhtml5playerbookmark2.js&apos;);document.body.appendChild(s);%7D)();","categories":[],"tags":[{"name":"mac","slug":"mac","permalink":"http://wzktravel.github.io/tags/mac/"}]},{"title":"hadoop一些基本命令和配置","slug":"hadoop-2-7-1","date":"2015-08-14T14:50:41.000Z","updated":"2016-07-14T03:16:31.000Z","comments":true,"path":"2015/08/14/hadoop-2-7-1/","link":"","permalink":"http://wzktravel.github.io/2015/08/14/hadoop-2-7-1/","excerpt":"hadoop一些基本命令和配置，基于2.7.1版本","text":"hadoop&#x4E00;&#x4E9B;&#x57FA;&#x672C;&#x547D;&#x4EE4;&#x548C;&#x914D;&#x7F6E;&#xFF0C;&#x57FA;&#x4E8E;2.7.1&#x7248;&#x672C; &#x914D;&#x7F6E;ssh localhost ssh-keygen -t dsa -P &apos;&apos; -f ~/.ssh/id_dsa &#x751F;&#x6210;ssh&#x516C;&#x94A5;&#x79C1;&#x94A5; cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys ssh localhost&#x7B2C;&#x4E00;&#x6B21;&#x4F1A;&#x51FA;&#x73B0;&#x63D0;&#x793A;&#xFF0C;&#x8F93;&#x5165;&#x201D;yes&#x201D;&#x5373;&#x53EF; ### &#x7406;&#x89E3; &#x5B8F;&#x89C2;&#x4E0A;&#xFF0C;Hadoop&#x6BCF;&#x4E2A;&#x4F5C;&#x4E1A;&#x8981;&#x7ECF;&#x5386;&#x4E24;&#x4E2A;&#x9636;&#x6BB5;&#xFF1A;Map phase&#x548C;reduce phase&#x3002;&#x5BF9;&#x4E8E;Map phase&#xFF0C;&#x53C8;&#x4E3B;&#x8981;&#x5305;&#x542B;&#x56DB;&#x4E2A;&#x5B50;&#x9636;&#x6BB5;&#xFF1A;&#x4ECE;&#x78C1;&#x76D8;&#x4E0A;&#x8BFB;&#x6570;&#x636E;-&gt;&#x6267;&#x884C;map&#x51FD;&#x6570;-&gt;combine&#x7ED3;&#x679C;-&gt;&#x5C06;&#x7ED3;&#x679C;&#x5199;&#x5230;&#x672C;&#x5730;&#x78C1;&#x76D8;&#x4E0A;&#xFF1B;&#x5BF9;&#x4E8E;reduce phase&#xFF0C;&#x540C;&#x6837;&#x5305;&#x542B;&#x56DB;&#x4E2A;&#x5B50;&#x9636;&#x6BB5;&#xFF1A;&#x4ECE;&#x5404;&#x4E2A;map task&#x4E0A;&#x8BFB;&#x76F8;&#x5E94;&#x7684;&#x6570;&#x636E;(shuffle)-&gt;sort-&gt;&#x6267;&#x884C;reduce&#x51FD;&#x6570;-&gt;&#x5C06;&#x7ED3;&#x679C;&#x5199;&#x5230;HDFS&#x4E2D;&#x3002; &#x9875;&#x9762; hdfs namenode&#x9875;&#x9762; http://localhost:50070/dfshealth.html yarn&#x9875;&#x9762; http://localhost:8088/cluster &#x5E38;&#x7528;&#x547D;&#x4EE4; hadoop jar hadoop-sample-0.1.jar com.wzk.hadoop.wordcount.WordCount2 readme.txt output &#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#x8F93;&#x51FA;&#x76EE;&#x5F55;&#x4E0D;&#x80FD;&#x5B58;&#x5728;&#xFF0C;&#x4F1A;&#x62A5;&#x9519; &#x53C2;&#x8003; &#x63A8;&#x8350;&#x7684;&#x4E0B;&#x8F7D;&#x5730;&#x5740; hadoop&#x5B98;&#x65B9;&#x6587;&#x6863;","categories":[],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://wzktravel.github.io/tags/hadoop/"}]},{"title":"git常用命令","slug":"git","date":"2015-08-12T14:38:22.000Z","updated":"2016-10-24T11:34:10.000Z","comments":true,"path":"2015/08/12/git/","link":"","permalink":"http://wzktravel.github.io/2015/08/12/git/","excerpt":"git的用法。","text":"git&#x7684;&#x7528;&#x6CD5;&#x3002; &#x6700;&#x5E38;&#x7528;&#x547D;&#x4EE4; git status git reflog git add &lt;file&gt; git commit -m &quot;comment&quot; git push origin master git remote -v &#x67E5;&#x770B;&#x8FDC;&#x7A0B;&#x4ED3;&#x5E93;&#x5730;&#x5740; &#x56DE;&#x6EDA;&#x7248;&#x672C; HEAD&#x6307;&#x5411;&#x7684;&#x7248;&#x672C;&#x5C31;&#x662F;&#x5F53;&#x524D;&#x7248;&#x672C;&#xFF0C;Git&#x5141;&#x8BB8;&#x6211;&#x4EEC;&#x5728;&#x7248;&#x672C;&#x7684;&#x5386;&#x53F2;&#x4E4B;&#x95F4;&#x7A7F;&#x68AD;&#xFF0C;&#x4F7F;&#x7528;&#x547D;&#x4EE4;git reset --hard commit_id&#x7A7F;&#x68AD;&#x524D;&#xFF0C;&#x7528;git log&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x63D0;&#x4EA4;&#x5386;&#x53F2;&#xFF0C;&#x4EE5;&#x4FBF;&#x786E;&#x5B9A;&#x8981;&#x56DE;&#x9000;&#x5230;&#x54EA;&#x4E2A;&#x7248;&#x672C;&#x3002; &#x8981;&#x91CD;&#x8FD4;&#x672A;&#x6765;&#xFF0C;&#x7528;git reflog&#x67E5;&#x770B;&#x547D;&#x4EE4;&#x5386;&#x53F2;&#xFF0C;&#x4EE5;&#x4FBF;&#x786E;&#x5B9A;&#x8981;&#x56DE;&#x5230;&#x672A;&#x6765;&#x7684;&#x54EA;&#x4E2A;&#x7248;&#x672C;&#x3002; &#x64A4;&#x9500;&#x4FEE;&#x6539; &#x672A;add&#xFF0C;git checkout -- file add&#x540E;, git reset HEAD file &#x5206;&#x652F;&#x64CD;&#x4F5C; &#x67E5;&#x770B;&#x5206;&#x652F;&#xFF1A;git branch &#x521B;&#x5EFA;&#x5206;&#x652F;&#xFF1A;git branch &lt;name&gt; &#x5207;&#x6362;&#x5206;&#x652F;&#xFF1A;git checkout &lt;name&gt; &#x521B;&#x5EFA;+&#x5207;&#x6362;&#x5206;&#x652F;&#xFF1A;git checkout -b &lt;name&gt; &#x5408;&#x5E76;&#x67D0;&#x5206;&#x652F;&#x5230;&#x5F53;&#x524D;&#x5206;&#x652F;&#xFF1A;git merge &lt;name&gt; &#x5220;&#x9664;&#x5206;&#x652F;&#xFF1A;git branch -d &lt;name&gt; &#x5F3A;&#x884C;&#x5220;&#x9664;&#x5206;&#x652F;&#xFF0C;git branch -D &lt;name&gt; &#x5408;&#x5E76;&#x5206;&#x652F;&#x65F6;&#xFF0C;&#x52A0;&#x4E0A;--no-ff&#x53C2;&#x6570;&#x5C31;&#x53EF;&#x4EE5;&#x7528;&#x666E;&#x901A;&#x6A21;&#x5F0F;&#x5408;&#x5E76;&#xFF0C;&#x5408;&#x5E76;&#x540E;&#x7684;&#x5386;&#x53F2;&#x6709;&#x5206;&#x652F;&#xFF0C;&#x80FD;&#x770B;&#x51FA;&#x6765;&#x66FE;&#x7ECF;&#x505A;&#x8FC7;&#x5408;&#x5E76;&#xFF0C;&#x800C;fast forward&#x5408;&#x5E76;&#x5C31;&#x770B;&#x4E0D;&#x51FA;&#x6765;&#x66FE;&#x7ECF;&#x505A;&#x8FC7;&#x5408;&#x5E76;&#x3002; &#x5148;&#x628A;&#x5DE5;&#x4F5C;&#x73B0;&#x573A;git stash&#x4E00;&#x4E0B;&#xFF0C;&#x7136;&#x540E;&#x53BB;&#x4FEE;&#x590D;bug&#xFF0C;&#x4FEE;&#x590D;&#x540E;&#xFF0C;&#x518D;git stash pop&#xFF0C;&#x56DE;&#x5230;&#x5DE5;&#x4F5C;&#x73B0;&#x573A;&#x3002; &#x4ECE;&#x8FDC;&#x7A0B;&#x62C9;&#x53D6;&#x5206;&#x652F;: git fetch&#x62C9;&#x53D6;&#x8FDC;&#x7A0B;&#x4FE1;&#x606F;&#x540E;&#xFF0C;git checkout -b &lt;name&gt; origin/&lt;name&gt; &#x5F3A;&#x5236;push&#x5230;&#x8FDC;&#x7A0B;: git push --force origin dev:dev merge&#x6307;&#x5B9A;commnit1git cherry-pick &lt;commit&gt; &#x53C2;&#x8003;http://stackoverflow.com/questions/881092/how-to-merge-a-specific-commit-in-git/881112#881112 &#x5FFD;&#x7565;&#x7279;&#x6B8A;&#x6587;&#x4EF6; .gitignore https://github.com/github/gitignore &#x6211;&#x7684;idea java&#x7684;gitignore 12345678910111213141516171819202122.ideatarget*.imloutgenrebel.xml### Java template*.class# Mobile Tools for Java (J2ME).mtj.tmp/# Package Files #*.jar*.war*.ear# virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xmlhs_err_pid* &#x5176;&#x4ED6; &#x547D;&#x4EE4;git rm&#x7528;&#x4E8E;&#x5220;&#x9664;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x3002; &#x8981;&#x5173;&#x8054;&#x4E00;&#x4E2A;&#x8FDC;&#x7A0B;&#x5E93;&#xFF0C;&#x4F7F;&#x7528;&#x547D;&#x4EE4;git remote add origin git@server-name:path/repo-name.git &#x5173;&#x8054;&#x540E;&#xFF0C;&#x4F7F;&#x7528;&#x547D;&#x4EE4;git push -u origin master&#x7B2C;&#x4E00;&#x6B21;&#x63A8;&#x9001;master&#x5206;&#x652F;&#x7684;&#x6240;&#x6709;&#x5185;&#x5BB9;&#x3002;&#x6B64;&#x540E;&#xFF0C;&#x6BCF;&#x6B21;&#x672C;&#x5730;&#x63D0;&#x4EA4;&#x540E;&#xFF0C;&#x53EA;&#x8981;&#x6709;&#x5FC5;&#x8981;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x547D;&#x4EE4;git push origin master&#x63A8;&#x9001;&#x6700;&#x65B0;&#x4FEE;&#x6539; &#x5207;&#x6362;&#x8FDC;&#x7A0B;&#x4ED3;&#x5E93;&#x5730;&#x5740;&#xFF0C;git remote set-url origin &lt;remote repo url&gt; alias&#x7F16;&#x8F91;~/.gitconfig123456789101112[alias] cm = commit co = checkout lg = log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit -- remotes = remote -v cleanup = git remotes branch --merged | grep -v &apos;*&apos; | xargs git branch -d branches = branch -a brs = branch -a tags = tag -l st = status -sb ac = !git add -A &amp;&amp; git commit po = push origin &#x9047;&#x5230;&#x7684;&#x95EE;&#x9898;add ssh key1ssh-keygen -t rsa -b 4096 -C &quot;wzktravel@gmail.com&quot; &#x6D4B;&#x8BD5;&#x8FDE;&#x63A5;1ssh -T git@github.com Common reasons that contributions are not countedCommon reasons that contributions are not counted&#x5F88;&#x53EF;&#x80FD;&#x662F;&#x56E0;&#x4E3A;&#x6CA1;&#x6709;&#x5173;&#x8054;&#x81EA;&#x5DF1;&#x7684;&#x90AE;&#x7BB1;&#x3002; 12git config user.name &quot;wzktravel&quot;git config user.email &quot;wzktravel@gmail.com&quot; 403 Forbidden while accessing github&#x4FEE;&#x6539; .git/config 123[remote &quot;origin&quot;] fetch = +refs/heads/*:refs/remotes/origin/* url = https://github.com/wzktravel/hexo.git &#x4E3A; 123[remote &quot;origin&quot;] fetch = +refs/heads/*:refs/remotes/origin/* url = https://wzktravel@github.com/wzktravel/hexo.git &#x7136;&#x540E;&#x8F93;&#x5165;&#x5BC6;&#x7801;&#x5373;&#x53EF;&#x3002; &#x4F7F;&#x7528;vim&#x4F5C;&#x4E3A;&#x9ED8;&#x8BA4;&#x7F16;&#x8F91;&#x5668;1git config --global core.editor vim &#x53C2;&#x8003; &#x5ED6;&#x96EA;&#x5CF0;&#x7684;git&#x6559;&#x7A0B;","categories":[],"tags":[{"name":"github","slug":"github","permalink":"http://wzktravel.github.io/tags/github/"},{"name":"git","slug":"git","permalink":"http://wzktravel.github.io/tags/git/"}]},{"title":"scala学习笔记","slug":"learning-scala","date":"2015-08-08T10:08:34.000Z","updated":"2016-07-14T03:16:31.000Z","comments":true,"path":"2015/08/08/learning-scala/","link":"","permalink":"http://wzktravel.github.io/2015/08/08/learning-scala/","excerpt":"scala学习笔记。","text":"scala&#x5B66;&#x4E60;&#x7B14;&#x8BB0;&#x3002; &#x770B;twitter scala&#x6559;&#x7A0B;&#x5C31;&#x53EF;&#x4EE5;&#x4E86;&#x3002; http://twitter.github.io/scala_school/zh_cn/index.html &#x53C2;&#x8003; twitter Scala&#x6559;&#x7A0B; &#x5F15;&#x8DEF;&#x8702;Scala&#x5F00;&#x53D1;&#x6559;&#x7A0B; http://alvinalexander.com/scala","categories":[],"tags":[{"name":"scala","slug":"scala","permalink":"http://wzktravel.github.io/tags/scala/"}]},{"title":"java监控工具(jps,jstat,jstack,jmap,jvisualvm等)","slug":"java-monitor","date":"2015-08-06T14:53:11.000Z","updated":"2016-09-19T08:50:55.000Z","comments":true,"path":"2015/08/06/java-monitor/","link":"","permalink":"http://wzktravel.github.io/2015/08/06/java-monitor/","excerpt":"对于线上线下服务，针对服务状态，qps，cost等一般都会有一定的监控措施。如果遇到问题，比如cpu占用率高或者程序特别吃内存，对于java程序来说，会用到一些java监控命令和错误定位命令，能够更好的监控服务运行状态，也能够快速定位问题。整理一下我一般使用的命令，下面的命令都是基于oracle hotspot jvm。","text":"&#x5BF9;&#x4E8E;&#x7EBF;&#x4E0A;&#x7EBF;&#x4E0B;&#x670D;&#x52A1;&#xFF0C;&#x9488;&#x5BF9;&#x670D;&#x52A1;&#x72B6;&#x6001;&#xFF0C;qps&#xFF0C;cost&#x7B49;&#x4E00;&#x822C;&#x90FD;&#x4F1A;&#x6709;&#x4E00;&#x5B9A;&#x7684;&#x76D1;&#x63A7;&#x63AA;&#x65BD;&#x3002;&#x5982;&#x679C;&#x9047;&#x5230;&#x95EE;&#x9898;&#xFF0C;&#x6BD4;&#x5982;cpu&#x5360;&#x7528;&#x7387;&#x9AD8;&#x6216;&#x8005;&#x7A0B;&#x5E8F;&#x7279;&#x522B;&#x5403;&#x5185;&#x5B58;&#xFF0C;&#x5BF9;&#x4E8E;java&#x7A0B;&#x5E8F;&#x6765;&#x8BF4;&#xFF0C;&#x4F1A;&#x7528;&#x5230;&#x4E00;&#x4E9B;java&#x76D1;&#x63A7;&#x547D;&#x4EE4;&#x548C;&#x9519;&#x8BEF;&#x5B9A;&#x4F4D;&#x547D;&#x4EE4;&#xFF0C;&#x80FD;&#x591F;&#x66F4;&#x597D;&#x7684;&#x76D1;&#x63A7;&#x670D;&#x52A1;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#xFF0C;&#x4E5F;&#x80FD;&#x591F;&#x5FEB;&#x901F;&#x5B9A;&#x4F4D;&#x95EE;&#x9898;&#x3002;&#x6574;&#x7406;&#x4E00;&#x4E0B;&#x6211;&#x4E00;&#x822C;&#x4F7F;&#x7528;&#x7684;&#x547D;&#x4EE4;&#xFF0C;&#x4E0B;&#x9762;&#x7684;&#x547D;&#x4EE4;&#x90FD;&#x662F;&#x57FA;&#x4E8E;oracle hotspot jvm&#x3002; &#x6982;&#x8FF0;Monitoring Tools jps: JVM Process Status Tool, &#x5217;&#x51FA;&#x6307;&#x5B9A;&#x673A;&#x5668;&#x7684;jvm pid&#x3002; jstat: JVM Statistics Monitoring Tool, jvm&#x7684;&#x7EDF;&#x8BA1;&#x76D1;&#x63A7;&#x5DE5;&#x5177;&#x3002; jstatd: JVM jstat Daemon, &#x6CA1;&#x7528;&#x8FC7;&#x3002; Troubleshooting Tools jinfo: Configuration Info for Java, &#x6253;&#x5370;java&#x914D;&#x7F6E;&#x4FE1;&#x606F;&#x3002; jhat: Heap Dump Browser, &#x6839;&#x636E;dump&#x6587;&#x4EF6;&#x8FDB;&#x884C;&#x5206;&#x6790;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x67E5;&#x770B;&#x3002; jmap: Memory Map for Java, &#x5185;&#x5B58;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x3002; jsadebugd: Serviceability Agent Debug Daemon for Java, &#x6CA1;&#x7528;&#x8FC7;&#x3002; jstack: Stack Trace for Java, &#x6253;&#x5370;&#x6307;&#x5B9A;&#x7EBF;&#x7A0B;&#x7684;&#x6808;&#x4FE1;&#x606F;&#x3002; Java Troubleshooting, Profiling, Monitoring and Management Tools jcmd: JVM Diagnostic Commands Tool, &#x7ED9;jvm&#x53D1;&#x9001;&#x8BCA;&#x65AD;&#x8BF7;&#x6C42;&#x3002; jconsole: A JMX-compliant graphical tool for monitoring a Java virtual machine, jvm&#x6027;&#x80FD;&#x5206;&#x6790;&#xFF0C;&#x56FE;&#x5F62;&#x754C;&#x9762;&#x3002; jmc: Java Mission Control, &#x6CA1;&#x7528;&#x8FC7;&#x3002; jvisualvm: Java VisualVM, &#x67E5;&#x770B;&#x7A0B;&#x5E8F;&#x7684;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#xFF0C;&#x56FE;&#x5F62;&#x754C;&#x9762;&#x3002; &#x8FD8;&#x6709;&#x66F4;&#x591A;&#x7684;&#x4E00;&#x4E9B;&#x5DE5;&#x5177;&#xFF0C;&#x5177;&#x4F53;&#x53EF;&#x4EE5;&#x770B;http://docs.oracle.com/javase/7/docs/technotes/tools/index.html&#x4E0B;&#x9762;&#x53EA;&#x6574;&#x7406;&#x4E86;&#x81EA;&#x5DF1;&#x5E73;&#x65F6;&#x7528;&#x5230;&#x7684;&#xFF0C;&#x6CA1;&#x6709;&#x7528;&#x8FC7;&#x7684;&#x6682;&#x65F6;&#x4E0D;&#x63D0;&#xFF0C;&#x7B49;&#x7528;&#x8FC7;&#x4E4B;&#x540E;&#x518D;&#x8865;&#x5145;&#x3002; Monitoring Toolsjpsjps [ options ] [ hostid ]&#x4E00;&#x822C;&#x53EA;&#x662F;&#x4E3A;&#x4E86;&#x6253;&#x5370;&#x51FA;&#x7A0B;&#x5E8F;&#x7684;pid, &#x53EF;&#x80FD;&#x4F1A;&#x7528;&#x5230; -m, -l, -v&#x9009;&#x9879;, -m&#x5217;&#x51FA;main&#x65B9;&#x6CD5;&#x7684;&#x53C2;&#x6570;, -l&#x5217;&#x51FA;&#x5B8C;&#x6574;jar&#x5305;, -v&#x5217;&#x51FA;jvm&#x7684;&#x53C2;&#x6570;&#x3002; 123456789101112~ jps -m27364 Resin --root-directory /usr/local/resin -conf /usr/local/resin/conf/resin.xml -server web -socketwait 33740 -server web -root-directory /usr/local/resin -log-directory /usr/local/resin/log restart21126 Jps -m22478 WatchdogManager -Xloggc:log/gc.log.2015081910 -server web -root-directory /usr/local/resin -conf /usr/local/resin/conf/resin.xml -log-directory /usr/local/resin/log start --log-directory /usr/local/resin/log~ jps -l27364 com.caucho.server.resin.Resin21147 sun.tools.jps.Jps22478 com.caucho.boot.WatchdogManager~ jps -v # &#x6D89;&#x53CA;&#x5230;resin&#x5177;&#x4F53;&#x914D;&#x7F6E;&#xFF0C;&#x4E0D;&#x5217;&#x51FA;&#x5177;&#x4F53;&#x5185;&#x5BB9;&#x4E86;&#x3002; jstatjstat [ generalOption | outputOptions vmid [interval[s|ms] [count]] ]&#x5148;&#x770B;&#x4E00;&#x4E0B;&#x6709;&#x54EA;&#x4E9B;&#x7EDF;&#x8BA1;&#x9879;&#x53EF;&#x9009; Option Displays class Statistics on the behavior of the class loader. compiler Statistics of the behavior of the HotSpot Just-in-Time compiler. gc Statistics of the behavior of the garbage collected heap. gccapacity Statistics of the capacities of the generations and their corresponding spaces. gccause Summary of garbage collection statistics (same as -gcutil), with the cause of the last and current (if applicable) garbage collection events. gcnew Statistics of the behavior of the new generation. gcnewcapacity Statistics of the sizes of the new generations and its corresponding spaces. gcold Statistics of the behavior of the old and permanent generations. gcoldcapacity Statistics of the sizes of the old generation. gcpermcapacity Statistics of the sizes of the permanent generation. gcutil Summary of garbage collection statistics. printcompilation HotSpot compilation method statistics. &#x6700;&#x5E38;&#x7528;&#x5230;&#x662F;gcutil, jstat -gcutil ${pid} 1000 100, &#x6BCF;1000ms&#x6253;&#x5370;&#x4E00;&#x6B21;gc&#x7EDF;&#x8BA1;&#x60C5;&#x51B5;&#xFF0C;&#x4E00;&#x5171;&#x6253;&#x5370;100&#x6B21;&#x3002; 12345678910~ jstat -gcutil 29209 1000 100S0 S1 E O M CCS YGC YGCT FGC FGCT GCT17.56 0.00 88.08 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 88.08 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 88.53 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 88.53 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 88.54 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 88.55 36.98 97.54 96.04 12166 309.541 12 4.174 313.71517.56 0.00 89.35 36.98 97.54 96.04 12166 309.541 12 4.174 313.715...... &#x5148;&#x770B;&#x4E00;&#x4E0B;&#x6253;&#x5370;&#x51FA;&#x6765;&#x7684;&#x90FD;&#x662F;&#x4EC0;&#x4E48;&#xFF1A; Column Description S0 Survivor space 0 &#x7684;&#x5229;&#x7528;&#x7387; S1 Survivor space 1 &#x7684;&#x5229;&#x7528;&#x7387; E Eden space &#x7684;&#x5229;&#x7528;&#x7387; O Old space &#x7684;&#x5229;&#x7528;&#x7387; P Permanent space &#x7684;&#x5229;&#x7528;&#x7387; YGC young gc&#x6570;&#x91CF; YGCT young gc&#x65F6;&#x95F4; FGC Full gc&#x6570;&#x91CF; FGCT Full gc&#x65F6;&#x95F4; GCT &#x6240;&#x6709;&#x7684;gc&#x65F6;&#x95F4;, (YGCT + FGCT) &#x5BF9;java&#x5F00;&#x53D1;&#x5DE5;&#x7A0B;&#x5E08;&#x6765;&#x8BF4;&#xFF0C;&#x8FD9;&#x4E9B;&#x5E94;&#x8BE5;&#x90FD;&#x4E0D;&#x964C;&#x751F;&#x3002;&#x5982;&#x679C;&#x5728;&#x4E0A;&#x7EBF;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x6211;&#x4E00;&#x822C;&#x4F1A;&#x6BD4;&#x8F83;&#x5173;&#x6CE8;YGC&#x548C;FGC, &#x5982;&#x679C;&#x53D1;&#x73B0;gc&#x8FC7;&#x4E8E;&#x9891;&#x7E41;&#xFF0C;&#x4F1A;&#x53BB;&#x67E5;&#x770B;&#x5185;&#x5B58;&#x7684;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x3002;jvm&#x5185;&#x5B58;&#x7BA1;&#x7406;&#x53EF;&#x4EE5;&#x770B;&#x4E00;&#x4E0B;&#x63A2;&#x79D8;java&#x865A;&#x62DF;&#x673A;&#x2013;&#x5185;&#x5B58;&#x7BA1;&#x7406;&#x4E0E;&#x5783;&#x573E;&#x56DE;&#x6536;&#xFF0C;&#x4E0D;&#x8FC7;&#x662F;&#x57FA;&#x4E8E;jdk1.6&#x7684;&#xFF0C;&#x5BF9;&#x4E8E;java8&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x4E00;&#x4E0B;java8&#x7684;&#x5143;&#x7A7A;&#x95F4;&#x3002; Troubleshooting Toolsjinfojinfo [ option ] pid&#x9664;&#x4E86;&#x53EF;&#x4EE5;&#x6839;&#x636E;pid&#x4E4B;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x6839;&#x636E;core-file&#x6216;&#x8FDC;&#x7A0B;&#x5730;&#x5740;&#x3002;&#x53EF;&#x4EE5;&#x67E5;&#x770B;jvm&#x7684;&#x914D;&#x7F6E;&#x4FE1;&#x606F;&#xFF0C;&#x7C7B;&#x4F3C;&#x4E8E;java&#x7A0B;&#x5E8F;&#x4E2D;System.getProperties()&#xFF0C;&#x4E00;&#x822C;&#x4F1A;&#x5728;&#x67E5;&#x770B;encoding&#x7684;&#x65F6;&#x5019;&#x4F7F;&#x7528;&#x3002; 1234567891011121314~ jinfo 29209Attaching to process ID 29209, please wait...Debugger attached successfully.Server compiler detected.JVM version is 25.45-b02Java System Properties:java.runtime.name = Java(TM) SE Runtime Environmentjava.vm.version = 25.45-b02sun.boot.library.path = /usr/lib/jvm/java-1.8.0-oracle-1.8.0.45.x86_64/jre/lib/amd64javax.management.builder.initial = com.caucho.jmx.MBeanServerBuilderImpljava.vendor.url = http://java.oracle.com/java.vm.vendor = Oracle Corporation...... jmapjmap [ option ] pid&#x9664;&#x4E86;&#x53EF;&#x4EE5;&#x6839;&#x636E;pid&#x4E4B;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x6839;&#x636E;core-file&#x6216;&#x8FDC;&#x7A0B;&#x5730;&#x5740;&#x3002; jmap -heap ${pid}&#xFF0C;&#x53EF;&#x4EE5;&#x5217;&#x51FA;&#x5806;&#x7684;&#x914D;&#x7F6E;&#x548C;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#xFF0C;&#x5982;&#x679C;gc&#x9891;&#x7387;&#x8FC7;&#x9AD8;&#x6216;&#x5185;&#x5B58;&#x5360;&#x7528;&#x592A;&#x9AD8;&#xFF0C;&#x80FD;&#x591F;&#x4ECE;&#x8FD9;&#x4E9B;&#x4FE1;&#x606F;&#x4E2D;&#x627E;&#x5230;&#x662F;&#x54EA;&#x4E00;&#x5757;&#x51FA;&#x4E86;&#x95EE;&#x9898;&#x3002; jmap -histo[:live] ${pid}&#xFF0C;&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x5806;&#x5185;&#x5B58;&#x4E2D;&#x7684;&#x5BF9;&#x8C61;&#x6570;&#x76EE;&#x3001;&#x5927;&#x5C0F;&#x7EDF;&#x8BA1;&#x76F4;&#x65B9;&#x56FE;&#xFF0C;&#x5982;&#x679C;&#x5E26;&#x4E0A;live&#x5219;&#x53EA;&#x7EDF;&#x8BA1;&#x6D3B;&#x5BF9;&#x8C61;&#x3002; 1234567891011121314151617181920212223~ jmap -histo:live 29209 | more num #instances #bytes class name----------------------------------------------1: 3040709 585742624 [C2: 110636 379989312 [B3: 4797182 115132368 java.util.LinkedList$Node4: 121324 81142520 [Ljava.lang.Object;5: 19398 78996664 [I6: 2689135 64539240 java.lang.String7: 1443 47278640 [Lorg.apache.xpath.objects.XObject;8: 397818 38190528 org.apache.xpath.axes.AxesWalker9: 917760 29368320 com.caucho.env.actor.ValueActorQueue$ValueItem10: 708201 22662432 java.util.HashMap$Node11: 445 19404664 [J12: 363053 11617696 java.util.LinkedList15: 82855 9279760 org.apache.xpath.axes.WalkingIterator16: 60086 7210320 org.apache.xalan.templates.ElemLiteralResult17: 71974 6909504 org.apache.xalan.templates.ElemTextLiteral18: 65536 6291456 com.caucho.server.dispatch.Invocation19: 12072 5723592 [Ljava.util.HashMap$Node;20: 60593 5332184 org.apache.xalan.templates.ElemValueOf21: 190114 4562736 java.util.ArrayList...... jmap -dump:format=b,file=dumpFileName ${pid}&#xFF0C;jmap&#x8FD8;&#x53EF;&#x4EE5;&#x628A;&#x8FDB;&#x7A0B;&#x7684;&#x5185;&#x5B58;&#x4F7F;&#x7528;&#x60C5;&#x51B5;dump&#x5230;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x7136;&#x540E;&#x7528;jhat&#x6216;jvisualvm&#x5206;&#x6790;&#x3002;&#x5BF9;&#x4E8E;&#x7EBF;&#x4E0A;&#x73AF;&#x5883;&#x4E0D;&#x8981;&#x8F7B;&#x6613;&#x4F7F;&#x7528;&#xFF01;jmap -dump:live&#x6BCF;&#x6B21;&#x90FD;&#x4F1A;&#x89E6;&#x53D1;&#x4E00;&#x6B21;Full GC jhatjhat [ options ] &lt;heap-dump-file&gt;jmap dump&#x51FA;&#x6765;&#x7684;&#x6587;&#x4EF6;&#x4E00;&#x822C;&#x90FD;&#x4F1A;&#x5F88;&#x5927;&#xFF0C;jhat&#x5206;&#x6790;&#x65F6;&#x53EF;&#x80FD;&#x9700;&#x8981;&#x52A0;&#x4E0A;-J-Xmx512m&#x8FD9;&#x79CD;&#x53C2;&#x6570;&#x6765;&#x6307;&#x5B9A;&#x6700;&#x5927;&#x5806;&#x5185;&#x5B58;&#x3002; 1234~ jmap -dump:live,format=b,file=jmapdump 2106Dumping heap to /tmp/jmapdump ...Heap dump file created~ jhat -port 9998 jmapdump jhat&#x8FDB;&#x884C;&#x5206;&#x6790;&#xFF0C;&#x5E76;&#x542F;&#x52A8;&#x4E00;&#x4E2A;server&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x67E5;&#x770B;&#x3002;&#x56FE;&#x7247;&#x4E2D;&#x53EA;&#x622A;&#x53D6;&#x4E86;&#x5F88;&#x5C0F;&#x4E00;&#x90E8;&#x5206;&#x3002; jstackjstack [ option ] pid&#x9664;&#x4E86;&#x53EF;&#x4EE5;&#x6839;&#x636E;pid&#x4E4B;&#x5916;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x6839;&#x636E;core-file&#x6216;&#x8FDC;&#x7A0B;&#x5730;&#x5740;&#x3002;jstack&#x53EF;&#x4EE5;&#x5B9A;&#x4F4D;&#x5230;&#x7EBF;&#x7A0B;&#x5806;&#x6808;&#xFF0C;&#x6839;&#x636E;&#x5806;&#x6808;&#x4FE1;&#x606F;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5B9A;&#x4F4D;&#x5230;&#x5177;&#x4F53;&#x4EE3;&#x7801;&#x3002;&#x5982;&#x679C;java&#x7A0B;&#x5E8F;&#x5D29;&#x6E83;&#x751F;&#x6210;core&#x6587;&#x4EF6;&#xFF0C;jstack&#x5DE5;&#x5177;&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x83B7;&#x5F97;core&#x6587;&#x4EF6;&#x7684;java stack&#x548C;native stack&#x7684;&#x4FE1;&#x606F;&#xFF0C;&#x4ECE;&#x800C;&#x53EF;&#x4EE5;&#x8F7B;&#x677E;&#x5730;&#x77E5;&#x9053;java&#x7A0B;&#x5E8F;&#x662F;&#x5982;&#x4F55;&#x5D29;&#x6E83;&#x548C;&#x5728;&#x7A0B;&#x5E8F;&#x4F55;&#x5904;&#x53D1;&#x751F;&#x95EE;&#x9898;&#x3002;&#x53E6;&#x5916;&#xFF0C;jstack&#x5DE5;&#x5177;&#x8FD8;&#x53EF;&#x4EE5;&#x9644;&#x5C5E;&#x5230;&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x7684;java&#x7A0B;&#x5E8F;&#x4E2D;&#xFF0C;&#x770B;&#x5230;&#x5F53;&#x65F6;&#x8FD0;&#x884C;&#x7684;java&#x7A0B;&#x5E8F;&#x7684;java stack&#x548C;native stack&#x7684;&#x4FE1;&#x606F;, &#x5982;&#x679C;&#x73B0;&#x5728;&#x8FD0;&#x884C;&#x7684;java&#x7A0B;&#x5E8F;&#x5448;&#x73B0;hung&#x7684;&#x72B6;&#x6001;&#xFF0C;jstack&#x662F;&#x975E;&#x5E38;&#x6709;&#x7528;&#x7684;&#x3002; &#x5728;&#x5B9E;&#x9645;&#x5E94;&#x7528;&#x4E2D;&#xFF0C;&#x4E00;&#x822C;&#x4F1A;&#x901A;&#x8FC7;ps, printf, top, jstack&#x6765;&#x67E5;&#x627E;&#x51FA;&#x6700;&#x8017;cpu&#x7684;java&#x7EBF;&#x7A0B;&#x5E76;&#x5B9A;&#x4F4D;&#x5230;&#x67D0;&#x4E00;&#x884C;&#x4EE3;&#x7801;&#x3002;&#x4E0B;&#x9762;&#x4E3E;&#x4E2A;&#x5B9E;&#x4F8B;&#xFF1A; &#x627E;&#x5230;&#x5BF9;&#x5E94;&#x8FDB;&#x7A0B;id, &#x4F7F;&#x7528;ps -ef | fgrep resin | fgrep -v fgrep&#xFF0C;&#x627E;&#x5230;resin&#x7684;pid&#xFF0C;&#x6216;&#x8005;&#x76F4;&#x63A5;&#x4F7F;&#x7528;jps&#x3002; &#x627E;&#x51FA;resin&#x8FDB;&#x7A0B;&#x4E2D;&#x6700;&#x8017;cpu&#x7684;&#x7EBF;&#x7A0B;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;ps -Lfp ${pid}&#x6216;top -Hp ${pid}&#x6216;ps -mp ${pid} -o THREAD,tid,time&#xFF0C;&#x6211;&#x4E00;&#x822C;&#x4F7F;&#x7528;top -Hp ${pid}, top&#x547D;&#x4EE4;&#x4E2D;&#x6839;&#x636E;&#x67D0;&#x4E00;&#x884C;&#x6392;&#x5E8F;&#x4F7F;&#x7528;&#x201D;F&#x201D;&#xFF0C;&#x7136;&#x540E;&#x9009;&#x62E9;&#x5BF9;&#x5E94;&#x9879;&#x524D;&#x7684;a-z&#x5373;&#x53EF;&#x3002; &#x53EF;&#x4EE5;&#x770B;&#x5230;cpu&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x6700;&#x9AD8;&#x7684;&#x662F;31255, &#x6211;&#x4EEC;&#x8981;&#x6839;&#x636E;&#x8FD9;&#x4E2A;pid&#x5F97;&#x5230;&#x5176;16&#x8FDB;&#x5236;&#x6570;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;nid 12~ printf &quot;%x\\n&quot; 312557a17 &#x7136;&#x540E;&#x4F7F;&#x7528;jstack&#x6253;&#x5370;&#x8FDB;&#x7A0B;&#x7684;&#x5806;&#x6808;&#x4FE1;&#x606F;&#xFF0C;&#x518D;&#x6839;&#x636E;nid&#x8FDB;&#x884C;grep&#x3002; 123456789101112~ jstack 29209 | fgrep -A10 7a17&quot;vr_cache(Recver3)&quot; #119 prio=5 os_prio=0 tid=0x00007f6a3007b000 nid=0x7a17 runnable [0x00007f6abc5f6000]java.lang.Thread.State: RUNNABLE at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method) at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269) at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79) at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86) - locked &lt;0x00000006d70100c8&gt; (a sun.nio.ch.Util$2) - locked &lt;0x00000006d70100b0&gt; (a java.util.Collections$UnmodifiableSet) - locked &lt;0x00000006d7009958&gt; (a sun.nio.ch.EPollSelectorImpl) at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97) at common.connectionpool.async.Receiver.run(Receiver.java:379) &#x53EF;&#x4EE5;&#x770B;&#x5230;CPU&#x6D88;&#x8017;&#x90FD;&#x82B1;&#x5728;&#x4E86;epollWait&#x4E0A;&#xFF0C;&#x518D;&#x6DF1;&#x7A76;&#x4E0B;&#x53BB;&#xFF0C;&#x662F;&#x81EA;&#x5DF1;&#x5B9E;&#x73B0;&#x7684;&#x4EE3;&#x7801;&#x4E2D;Receiver&#x7C7B;&#x4E2D;&#x7B2C;379&#x884C;&#x5F15;&#x8D77;&#x7684;&#xFF0C;&#x6211;&#x4EEC;&#x770B;&#x4E00;&#x4E0B;&#x4EE3;&#x7801;&#xFF1A; 1int num = this.selector.select(pool.robinTime); &#x8FD9;&#x4E00;&#x884C;&#x6B63;&#x662F;selector&#x8FDB;&#x884C;&#x7B49;&#x5F85;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x5BF9;&#x5E94;&#x4E8E;epoll&#x6765;&#x8BF4;&#x5C31;&#x662F;epoll_wait&#x51FD;&#x6570;&#x3002;&#x5B9A;&#x4F4D;&#x5230;&#x95EE;&#x9898;&#xFF0C;&#x53EF;&#x4EE5;&#x53BB;&#x627E;&#x5BF9;&#x5E94;&#x65B9;&#x6848;&#x4E86;&#x3002;&#x5982;&#x679C;&#x5BF9;IO&#x591A;&#x8DEF;&#x590D;&#x7528;&#x673A;&#x5236;&#x7684;&#x53EF;&#x4EE5;&#x770B;&#x4E00;&#x4E0B;&#x76F8;&#x5173;&#x6587;&#x7AE0;&#xFF0C;&#x4E3B;&#x8981;&#x6709;select, poll, epoll&#x3002; java&#x56FE;&#x5F62;&#x5316;&#x754C;&#x9762;&#x76D1;&#x63A7;&#x5DE5;&#x5177;jconsole&#x548C;jvisualvm&#x90FD;&#x9700;&#x8981;&#x56FE;&#x5F62;&#x5316;&#x754C;&#x9762;&#xFF0C;&#x90FD;&#x53EF;&#x4EE5;&#x8FDE;&#x63A5;&#x8FDC;&#x7A0B;server&#x67E5;&#x770B;&#x3002;&#x56FE;&#x5F62;&#x5316;&#x754C;&#x9762;&#x770B;&#x8D77;&#x6765;&#x90FD;&#x6BD4;&#x8F83;&#x5BB9;&#x6613;&#xFF0C;&#x5728;&#x8FD9;&#x4E0D;&#x505A;&#x8D58;&#x8FF0;&#x4E86;&#x3002; jconsole jvisualvm &#x53C2;&#x8003; oracle&#x5B98;&#x65B9;&#x6587;&#x6863; jdk tools and utilities &#x63A2;&#x79D8;java&#x865A;&#x62DF;&#x673A;&#x2013;&#x5185;&#x5B58;&#x7BA1;&#x7406;&#x4E0E;&#x5783;&#x573E;&#x56DE;&#x6536; JVM&#x7684;&#x76F8;&#x5173;&#x77E5;&#x8BC6;&#x6574;&#x7406;&#x548C;&#x5B66;&#x4E60; java8&#x7684;&#x5143;&#x7A7A;&#x95F4; select&#x3001;poll&#x3001;epoll&#x4E4B;&#x95F4;&#x7684;&#x533A;&#x522B;&#x603B;&#x7ED3;(&#x6574;&#x7406;) jmap -dump:live&#x4E3A;&#x5565;&#x4F1A;&#x89E6;&#x53D1;Full GC","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"},{"name":"java","slug":"java","permalink":"http://wzktravel.github.io/tags/java/"}]},{"title":"vim快捷键","slug":"vim-shortcut","date":"2015-06-29T14:25:40.000Z","updated":"2016-11-23T08:29:27.000Z","comments":true,"path":"2015/06/29/vim-shortcut/","link":"","permalink":"http://wzktravel.github.io/2015/06/29/vim-shortcut/","excerpt":"整理一下用过的vim快捷键。有些平时不太用，但用到就比较捉急，也算温故知新吧。","text":"&#x6574;&#x7406;&#x4E00;&#x4E0B;&#x7528;&#x8FC7;&#x7684;vim&#x5FEB;&#x6377;&#x952E;&#x3002;&#x6709;&#x4E9B;&#x5E73;&#x65F6;&#x4E0D;&#x592A;&#x7528;&#xFF0C;&#x4F46;&#x7528;&#x5230;&#x5C31;&#x6BD4;&#x8F83;&#x6349;&#x6025;&#xFF0C;&#x4E5F;&#x7B97;&#x6E29;&#x6545;&#x77E5;&#x65B0;&#x5427;&#x3002; &#x5E38;&#x7528;&#x5FEB;&#x6377;&#x952E; &lt;c-o&gt; a &#x63D2;&#x5165;&#x6A21;&#x5F0F;&#x4E0B;&#x5230;&#x884C;&#x5C3E;&#x7EE7;&#x7EED;&#x8F93;&#x5165;(&#x76F8;&#x5F53;&#x4E8E;end&#x952E;)&lt;c-o&gt; i &#x63D2;&#x5165;&#x6A21;&#x5F0F;&#x4E0B;&#x5230;&#x884C;&#x9996;&#x7EE7;&#x7EED;&#x8F93;&#x5165;(&#x76F8;&#x5F53;&#x4E8E;home&#x952E;) h &#x8DF3;&#x8F6C;&#x5230;&#x5C4F;&#x5E55;&#x9876;&#x7AEF;&#xFF08;&#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E86;set so=n&#xFF0C;&#x5219;&#x8DF3;&#x8F6C;&#x5230;&#x7B2C;n&#x884C;&#xFF09;l &#x8DF3;&#x8F6C;&#x5230;&#x5C4F;&#x5E55;&#x5E95;&#x7AEF;&#xFF08;&#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E86;set so=n&#xFF0C;&#x5219;&#x8DF3;&#x8F6C;&#x5230;&#x5012;&#x6570;&#x7B2C;n&#x884C;&#xFF09;zz &#x5149;&#x6807;&#x4E0B;&#x5185;&#x5BB9;&#x5728;&#x5C4F;&#x5E55;&#x4E2D;&#x592E; gd &#x9009;&#x4E2D;&#x5355;&#x8BCD;&#x5E76;&#x9AD8;&#x4EAE; j &#x5C06;&#x4E0B;&#x4E00;&#x884C;&#x63D0;&#x5230;&#x8FD9;&#x884C;&#x6765; (join line) r &#x66FF;&#x6362;&#x5355;&#x4E2A;&#x5B57;&#x7B26; R &#x66FF;&#x6362;&#x591A;&#x4E2A;&#x5B57;&#x7B26; i &#x63D2;&#x5165;&#xFF0C;i &#x7B2C;&#x4E00;&#x4E2A;&#x975E;&#x7A7A;&#x767D;&#x5B57;&#x7B26;&#x524D;&#x63D2;&#x5165;o &#x5F53;&#x524D;&#x884C;&#x540E;&#x63D2;&#x5165;&#x4E00;&#x65B0;&#x884C; o &#x5F53;&#x524D;&#x884C;&#x524D;&#x63D2;&#x5165;&#x4E00;&#x65B0;&#x884C; dd&#x5220;&#x9664;&#x884C;&#xFF0C;dw&#x5220;&#x9664;&#x5355;&#x8BCD; ndd ndwc&#x4E0E;d&#x7C7B;&#x4F3C;&#xFF0C;&#x4F46;&#x5220;&#x9664;&#x540E;&#x8FDB;&#x5165;&#x63D2;&#x5165;&#x6A21;&#x5F0F; S&#x5220;&#x9664;&#x4E00;&#x884C;&#xFF0C;&#x5E76;&#x8FDB;&#x5165;&#x63D2;&#x5165;&#x6A21;&#x5F0F; x&#x5220;&#x9664;&#x5B57;&#x7B26; s&#x5220;&#x9664;&#x5B57;&#x7B26;&#x540E;&#x8FDB;&#x5165;&#x63D2;&#x5165;&#x6A21;&#x5F0F; w: go to the start of the following [w]ordb: go to the [b]eginning of this worde: go to the [e]nd of this wordt+&#x5B57;&#x7B26; &#x8DF3;&#x5230;&#x6B64;&#x884C;&#x7B2C;&#x4E00;&#x4E2A;&#x51FA;&#x73B0;&#x6B64;&#x5B57;&#x7B26;&#x7684;&#x5730;&#x65B9; ~&#x6309;&#x5B57;&#x7B26;&#x5927;&#x5C0F;&#x5199;&#x8F6C;&#x6362; gu&#x8F6C;&#x6362;&#x4E3A;&#x5C0F;&#x5199; gU&#x8F6C;&#x6362;&#x4E3A;&#x5927;&#x5199; gU3w&#x8F6C;&#x6362;3&#x4E2A;&#x5355;&#x8BCD; &#x67E5;&#x627E; /xxx(?xxx) &#x8868;&#x793A;&#x5728;&#x6574;&#x7BC7;&#x6587;&#x6863;&#x4E2D;&#x641C;&#x7D22;&#x5339;&#x914D;xxx&#x7684;&#x5B57;&#x7B26;&#x4E32;, / &#x8868;&#x793A;&#x5411;&#x4E0B;&#x67E5;&#x627E;, ? &#x8868;&#x793A; &#x5411;&#x4E0A;&#x67E5;&#x627E;.&#x5176;&#x4E2D;xxx&#x53EF;&#x4EE5;&#x662F;&#x6B63;&#x89C4;&#x8868;&#x8FBE;&#x5F0F;,&#x5173;&#x4E8E;&#x6B63;&#x89C4;&#x5F0F;&#x5C31;&#x4E0D;&#x591A;&#x8BF4;&#x4E86;. &#x4E00;&#x822C;&#x6765;&#x8BF4;&#x662F;&#x533A;&#x5206;&#x5927;&#x5C0F;&#x5199;&#x7684;, &#x8981;&#x60F3;&#x4E0D;&#x533A;&#x5206;&#x5927;&#x5C0F;&#x5199;, &#x90A3;&#x5F97;&#x5148;&#x8F93;&#x5165; :set ignorecase &#x67E5;&#x627E;&#x5230;&#x4EE5;&#x540E;, &#x518D;&#x8F93;&#x5165; n &#x67E5;&#x627E;&#x4E0B;&#x4E00;&#x4E2A;&#x5339;&#x914D;&#x5904;, &#x8F93;&#x5165; N &#x53CD;&#x65B9;&#x5411;&#x67E5;&#x627E;. *(#) &#x5F53;&#x5149;&#x6807;&#x505C;&#x7559;&#x5728;&#x67D0;&#x4E2A;&#x5355;&#x8BCD;&#x4E0A;&#x65F6;, &#x8F93;&#x5165;&#x8FD9;&#x6761;&#x547D;&#x4EE4;&#x8868;&#x793A;&#x67E5;&#x627E;&#x4E0E;&#x8BE5;&#x5355;&#x8BCD;&#x5339;&#x914D;&#x7684; &#x4E0B;(&#x4E0A;)&#x4E00;&#x4E2A;&#x5355;&#x8BCD;. &#x540C;&#x6837;, &#x518D;&#x8F93;&#x5165;n&#x67E5;&#x627E;&#x4E0B;&#x4E00;&#x4E2A;&#x5339;&#x914D;&#x5904;, &#x8F93;&#x5165; N &#x53CD;&#x65B9; &#x5411;&#x67E5;&#x627E;. g*(g#) &#x6B64;&#x547D;&#x4EE4;&#x4E0E;&#x4E0A;&#x6761;&#x547D;&#x4EE4;&#x76F8;&#x4F3C;, &#x53EA;&#x4E0D;&#x8FC7;&#x5B83;&#x4E0D;&#x5B8C;&#x5168;&#x5339;&#x914D;&#x5149;&#x6807;&#x6240;&#x5728;&#x5904;&#x7684;&#x5355;&#x8BCD;, &#x800C;&#x662F;&#x5339;&#x914D;&#x5305;&#x542B;&#x8BE5;&#x5355;&#x8BCD;&#x7684;&#x6240;&#x6709;&#x5B57;&#x7B26;&#x4E32;. gd &#x672C;&#x547D;&#x4EE4;&#x67E5;&#x627E;&#x4E0E;&#x5149;&#x6807;&#x6240;&#x5728;&#x5355;&#x8BCD;&#x76F8;&#x5339;&#x914D;&#x7684;&#x5355;&#x8BCD;, &#x5E76;&#x5C06;&#x5149;&#x6807;&#x505C;&#x7559;&#x5728;&#x6587;&#x6863;&#x7684;&#x975E; &#x6CE8;&#x91CA;&#x6BB5;&#x4E2D;&#x7B2C;&#x4E00;&#x6B21;&#x51FA;&#x73B0;&#x8FD9;&#x4E2A;&#x5355;&#x8BCD;&#x7684;&#x5730;&#x65B9;. % &#x672C;&#x547D;&#x4EE4;&#x67E5;&#x627E;&#x4E0E;&#x5149;&#x6807;&#x6240;&#x5728;&#x5904;&#x76F8;&#x5339;&#x914D;&#x7684;&#x53CD;&#x62EC;&#x53F7;, &#x5305;&#x62EC; () [] {} f(F)x &#x672C;&#x547D;&#x4EE4;&#x8868;&#x793A;&#x5728;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x8FDB;&#x884C;&#x67E5;&#x627E;, &#x67E5;&#x627E;&#x5149;&#x6807;&#x53F3;(&#x5DE6;)&#x65B9;&#x7B2C;&#x4E00;&#x4E2A;x&#x5B57;&#x7B26;. &#x627E;&#x5230;&#x540E;: &#x8F93;&#x5165; ; &#x8868;&#x793A;&#x7EE7;&#x7EED;&#x5F80;&#x4E0B;&#x627E; &#x8F93;&#x5165; , &#x8868;&#x793A;&#x53CD;&#x65B9;&#x5411;&#x67E5;&#x627E; &#x5FEB;&#x901F;&#x79FB;&#x52A8;&#x5149;&#x6807; w(e) &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0B;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;. b &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0A;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;. 0 &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x672C;&#x884C;&#x6700;&#x5F00;&#x5934;. ^ &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x672C;&#x884C;&#x6700;&#x5F00;&#x5934;&#x7684;&#x5B57;&#x7B26;&#x5904;. $ &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x672C;&#x884C;&#x7ED3;&#x5C3E;&#x5904;. H &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x5C4F;&#x5E55;&#x7684;&#x9996;&#x884C;. M &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x5C4F;&#x5E55;&#x7684;&#x4E2D;&#x95F4;&#x4E00;&#x884C;. L &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x5C4F;&#x5E55;&#x7684;&#x5C3E;&#x884C;. gg &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x6587;&#x6863;&#x9996;&#x884C;. G &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x6587;&#x6863;&#x5C3E;&#x884C;. c-f (&#x5373; ctrl &#x952E;&#x4E0E; f &#x952E;&#x4E00;&#x540C;&#x6309;&#x4E0B;) &#x672C;&#x547D;&#x4EE4;&#x5373; page down. c-b (&#x5373; ctrl &#x952E;&#x4E0E; b &#x952E;&#x4E00;&#x540C;&#x6309;&#x4E0B;, &#x540E;&#x540C;) &#x672C;&#x547D;&#x4EE4;&#x5373; page up. &apos;&apos; &#x6B64;&#x547D;&#x4EE4;&#x76F8;&#x5F53;&#x6709;&#x7528;, &#x5B83;&#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0A;&#x4E00;&#x4E2A;&#x6807;&#x8BB0;&#x5904;, &#x6BD4;&#x5982;&#x7528; gd, * &#x7B49;&#x67E5; &#x627E;&#x5230;&#x67D0;&#x4E2A;&#x5355;&#x8BCD;&#x540E;, &#x518D;&#x8F93;&#x5165;&#x6B64;. &apos;. &#x6B64;&#x547D;&#x4EE4;&#x76F8;&#x5F53;&#x597D;&#x4F7F;, &#x5B83;&#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0A;&#x4E00;&#x6B21;&#x7684;&#x4FEE;&#x6539;&#x884C; `. &#x6B64;&#x547D;&#x4EE4;&#x76F8;&#x5F53;&#x5F3A;&#x5927;, &#x5B83;&#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0A;&#x4E00;&#x6B21;&#x7684;&#x4FEE;&#x6539;&#x70B9;. &#x62F7;&#x8D1D;, &#x5220;&#x9664;&#x4E0E;&#x7C98;&#x8D34; yw &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x5355;&#x8BCD;&#x7ED3;&#x5C3E;&#x7684;&#x5185;&#x5BB9;. dw &#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x5355;&#x8BCD;&#x7ED3;&#x5C3E;&#x7684;&#x5185;&#x5BB9;. y0 &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x9996;&#x7684;&#x5185;&#x5BB9;. d0 &#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x9996;&#x7684;&#x5185;&#x5BB9;. y$ &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x5C3E;&#x7684;&#x5185;&#x5BB9;. d$ &#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x5C3E;&#x7684;&#x5185;&#x5BB9;. yfa &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x540E;&#x9762;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;a&#x5B57;&#x7B26;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. dfa &#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x540E;&#x9762;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;a&#x5B57;&#x7B26;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. yy &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;. dd &#x8868;&#x793A;&#x5220;&#x9664;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;. D &#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x5C3E;&#x7684;&#x5185;&#x5BB9;.&#x8868;&#x793A;&#x5220;&#x9664;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x5C3E;&#x7684;&#x5185;&#x5BB9; c c&#x4E0E;d&#x7C7B;&#x4F3C;&#xFF0C;&#x53EA;&#x662F;&#x5220;&#x9664;&#x540E;&#x8FDB;&#x5165;&#x7F16;&#x8F91;&#x6A21;&#x5F0F; x &#x5220;&#x9664;&#x5355;&#x4E2A;&#x5B57;&#x7B26; s &#x4E0E;x&#x7C7B;&#x4F3C;&#xFF0C;&#x5220;&#x9664;&#x540E;&#x8FDB;&#x5165;&#x7F16;&#x8F91;&#x6A21;&#x5F0F; &#x6570;&#x5B57;&#x4E0E;&#x547D;&#x4EE4;&#x5728; vi &#x4E2D;&#x6570;&#x5B57;&#x4E0E;&#x547D;&#x4EE4;&#x7ED3;&#x5408;&#x5F80;&#x5F80;&#x8868;&#x793A;&#x91CD;&#x590D;&#x8FDB;&#x884C;&#x6B64;&#x547D;&#x4EE4;, &#x82E5;&#x5728;&#x6269;&#x5C55;&#x6A21;&#x5F0F;&#x7684;&#x5F00;&#x5934;&#x51FA;&#x73B0;&#x5219;&#x8868;&#x793A;&#x884C;&#x53F7;&#x5B9A;&#x4F4D;. &#x5982;: 5fx &#x8868;&#x793A;&#x67E5;&#x627E;&#x5149;&#x6807;&#x540E;&#x7B2C;5&#x4E2A;x&#x5B57;&#x7B26;. 5w(e) &#x79FB;&#x52A8;&#x5149;&#x6807;&#x5230;&#x4E0B;&#x4E94;&#x4E2A;&#x5355;&#x8BCD;. 5yy &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x5149;&#x6807;&#x4EE5;&#x4E0B;5&#x884C;. 5dd &#x8868;&#x793A;&#x5220;&#x9664;&#x5149;&#x6807;&#x4EE5;&#x4E0B;5&#x884C;. y2fa &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x4ECE;&#x5F53;&#x524D;&#x5149;&#x6807;&#x5230;&#x5149;&#x6807;&#x540E;&#x9762;&#x7684;&#x7B2C;&#x4E8C;&#x4E2A;a&#x5B57;&#x7B26;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. :12,24y &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x7B2C;12&#x884C;&#x5230;&#x7B2C;24&#x884C;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. :12,y &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x7B2C;12&#x884C;&#x5230;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. :,24y &#x8868;&#x793A;&#x62F7;&#x8D1D;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x5230;&#x7B2C;24&#x884C;&#x4E4B;&#x95F4;&#x7684;&#x5185;&#x5BB9;. &#x5220;&#x9664;&#x7C7B;&#x4F3C;. &#x5FEB;&#x901F;&#x8F93;&#x5165;&#x5B57;&#x7B26; c-p(c-n) &#x5728;&#x7F16;&#x8F91;&#x6A21;&#x5F0F;&#x4E2D;, &#x8F93;&#x5165;&#x51E0;&#x4E2A;&#x5B57;&#x7B26;&#x540E;&#x518D;&#x8F93;&#x5165;&#x6B64;&#x547D;&#x4EE4;&#x5219; vi &#x5F00;&#x59CB;&#x5411;&#x4E0A;(&#x4E0B;)&#x641C;&#x7D22;&#x5F00;&#x5934;&#x4E0E;&#x5176;&#x5339;&#x914D;&#x7684;&#x5355;&#x8BCD;&#x5E76;&#x8865;&#x9F50;, &#x4E0D;&#x65AD;&#x8F93;&#x5165;&#x6B64;&#x547D;&#x4EE4;&#x5219;&#x5FAA;&#x73AF;&#x67E5;&#x627E;. &#x6B64;&#x547D;&#x4EE4;&#x4F1A;&#x5728;&#x6240;&#x6709;&#x5728;&#x8FD9;&#x4E2A; vim &#x7A0B;&#x5E8F;&#x4E2D;&#x6253;&#x5F00;&#x7684;&#x6587;&#x4EF6;&#x4E2D;&#x8FDB;&#x884C;&#x5339;&#x914D;. c-x-l &#x5728;&#x7F16;&#x8F91;&#x6A21;&#x5F0F;&#x4E2D;, &#x6B64;&#x547D;&#x4EE4;&#x5FEB;&#x901F;&#x8865;&#x9F50;&#x6574;&#x884C;&#x5185;&#x5BB9;, &#x4F46;&#x662F;&#x4EC5;&#x5728;&#x672C;&#x7A97;&#x53E3;&#x4E2D;&#x51FA;&#x73B0;&#x7684;&#x6587;&#x6863;&#x4E2D;&#x8FDB;&#x884C;&#x5339;&#x914D;. c-x-f &#x5728;&#x7F16;&#x8F91;&#x6A21;&#x5F0F;&#x4E2D;, &#x8FD9;&#x4E2A;&#x547D;&#x4EE4;&#x8868;&#x793A;&#x8865;&#x9F50;&#x6587;&#x4EF6;&#x540D;. &#x5982;&#x8F93;&#x5165;:/usr/local/tom &#x540E;&#x518D;&#x8F93;&#x5165;&#x6B64;&#x547D;&#x4EE4;&#x5219;&#x5B83;&#x4F1A;&#x81EA;&#x52A8;&#x5339;&#x914D;&#x51FA;:/usr/local/tomcat/ abbr &#x5373;&#x7F29;&#x5199;. &#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x5B8F;&#x64CD;&#x4F5C;, &#x53EF;&#x4EE5;&#x5728;&#x7F16;&#x8F91;&#x6A21;&#x5F0F;&#x4E2D;&#x7528;&#x4E00;&#x4E2A;&#x7F29;&#x5199;&#x4EE3;&#x66FF;&#x53E6;&#x4E00;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;. &#x6BD4;&#x5982;&#x7F16;&#x5199;java&#x6587;&#x4EF6;&#x7684;&#x5E38;&#x5E38;&#x8F93;&#x5165; System.out.println, &#x8FD9;&#x5F88; &#x662F;&#x9EBB;&#x70E6;, &#x6240;&#x4EE5;&#x5E94;&#x8BE5;&#x7528;&#x7F29;&#x5199;&#x6765;&#x51CF;&#x5C11;&#x6572;&#x5B57;. &#x53EF;&#x4EE5;&#x8FD9;&#x4E48;&#x505A;:abbr sprt System.out.println,&#x4EE5;&#x540E;&#x5728;&#x8F93;&#x5165;sprt&#x540E;&#x518D;&#x8F93;&#x5165;&#x5176;&#x4ED6;&#x975E;&#x5B57;&#x6BCD;&#x7B26;&#x53F7;, &#x5B83;&#x5C31;&#x4F1A;&#x81EA;&#x52A8;&#x6269;&#x5C55;&#x4E3A;System.out.println &#x66FF;&#x6362;&#x66FF;&#x6362;&#x662F; vi &#x7684;&#x5F3A;&#x9879;, &#x56E0;&#x4E3A;&#x53EF;&#x4EE5;&#x7528;&#x6B63;&#x89C4;&#x8868;&#x8FBE;&#x5F0F;&#x6765;&#x5339;&#x914D;&#x5B57;&#x7B26;&#x4E32;.&#x4EE5;&#x4E0B;&#x63D0;&#x4F9B;&#x51E0;&#x4E2A;&#x4F8B;&#x5B50;. :s/aa/bb/g &#x5C06;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x51FA;&#x73B0;&#x7684;&#x6240;&#x6709;&#x5305;&#x542B; aa &#x7684;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x7684; aa &#x66FF;&#x6362;&#x4E3A; bb :s/\\/bb/g &#x5C06;&#x5149;&#x6807;&#x6240;&#x5728;&#x884C;&#x51FA;&#x73B0;&#x7684;&#x6240;&#x6709; aa &#x66FF;&#x6362;&#x4E3A; bb, &#x4EC5;&#x66FF;&#x6362; aa &#x8FD9;&#x4E2A;&#x5355;&#x8BCD; :%s/aa/bb/g &#x5C06;&#x6587;&#x6863;&#x4E2D;&#x51FA;&#x73B0;&#x7684;&#x6240;&#x6709;&#x5305;&#x542B; aa &#x7684;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x7684; aa &#x66FF;&#x6362;&#x4E3A; bb :12,23s/aa/bb/g &#x5C06;&#x4ECE;12&#x884C;&#x5230;23&#x884C;&#x4E2D;&#x51FA;&#x73B0;&#x7684;&#x6240;&#x6709;&#x5305;&#x542B; aa &#x7684;&#x5B57;&#x7B26;&#x4E32;&#x4E2D;&#x7684; aa &#x66FF;&#x6362;&#x4E3A; bb :12,23s/^/#/ &#x5C06;&#x4ECE;12&#x884C;&#x5230;23&#x884C;&#x7684;&#x884C;&#x9996;&#x52A0;&#x5165; # &#x5B57;&#x7B26; :%s= *$== &#x5C06;&#x6240;&#x6709;&#x884C;&#x5C3E;&#x591A;&#x4F59;&#x7684;&#x7A7A;&#x683C;&#x5220;&#x9664; :g/^\\s*$/d &#x5C06;&#x6240;&#x6709;&#x4E0D;&#x5305;&#x542B;&#x5B57;&#x7B26;(&#x7A7A;&#x683C;&#x4E5F;&#x4E0D;&#x5305;&#x542B;)&#x7684;&#x7A7A;&#x884C;&#x5220;&#x9664;. &#x6298;&#x53E0; zf F-old creation &#x521B;&#x5EFA;&#x6298;&#x53E0; zfgg &#x4ECE;&#x5F53;&#x524D;&#x884C;&#x6298;&#x53E0;&#x5230;&#x6587;&#x4EF6;&#x5934; zf20G &#x4ECE;&#x5F53;&#x524D;&#x884C;&#x6298;&#x53E0;&#x5230;&#x7B2C;20&#x884C; 10zf+ &#x4ECE;&#x5F53;&#x524D;&#x884C;&#x5411;&#x4E0B;&#x6298;&#x53E0;10&#x884C; 10zf- &#x4ECE;&#x5F53;&#x524D;&#x884C;&#x5411;&#x4E0A;&#x6298;&#x53E0;10&#x884C; zo O-pen a fold &#x6253;&#x5F00;&#x6298;&#x53E0; zc C-lose a fold &#x5173;&#x95ED;&#x6298;&#x53E0; zr &#x5173;&#x95ED;&#x6240;&#x6709;&#x6298;&#x53E0; zm &#x6253;&#x5F00;&#x6240;&#x6709;&#x6298;&#x53E0; set foldmethod=() &#x8BBE;&#x7F6E;&#x6298;&#x53E0;&#x65B9;&#x5F0F; manual &#x624B;&#x5DE5;&#x5B9A;&#x4E49; indent &#x6839;&#x636E;&#x7F29;&#x8FDB; expr &#x6839;&#x636E;&#x8868;&#x8FBE;&#x5F0F; syntax &#x6839;&#x636E;&#x8BED;&#x6CD5;&#x9AD8;&#x4EAE; diff &#x5BF9;&#x6CA1;&#x6709;&#x66F4;&#x6539;&#x7684;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x6298;&#x53E0; marker &#x6839;&#x636E;&#x6587;&#x4E2D;&#x6807;&#x5FD7;&#x6298;&#x53E0; &#x5BC4;&#x5B58;&#x5668;&#xFF1A; &quot;{a-zA-Z}yy &#x4FDD;&#x5B58;&#x5230;&#x5BF9;&#x5E94;&#x5BC4;&#x5B58;&#x5668;&#x4E2D; &quot;{a-zA-Z}p &#x7C98;&#x8D34;&#x5BF9;&#x5E94;&#x5BC4;&#x5B58;&#x5668;&#x4E2D;&#x5185;&#x5BB9; :reg&#x6216;:dis &#x67E5;&#x770B;&#x5BC4;&#x5B58;&#x5668;&#x5185;&#x5BB9; &#x63D2;&#x5165;&#x6A21;&#x5F0F;&#x4E0B;&#x4F7F;&#x7528;&#x5BC4;&#x5B58;&#x5668;: &lt;C-r&gt;+&#x5BC4;&#x5B58;&#x5668; &#x5176;&#x4ED6; vim -o filename1 filename2 &#x6C34;&#x5E73;&#x5206;&#x5272;&#x7A97;&#x53E3; vim -O filename1 filename2 &#x5782;&#x76F4;&#x5206;&#x5272;&#x7A97;&#x53E3; &#x53C2;&#x8003; &#x6298;&#x53E0;","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"http://wzktravel.github.io/tags/vim/"}]},{"title":"打造属于自己的vim","slug":"create-my-own-vim","date":"2015-06-27T04:56:58.000Z","updated":"2016-07-14T03:16:31.000Z","comments":true,"path":"2015/06/27/create-my-own-vim/","link":"","permalink":"http://wzktravel.github.io/2015/06/27/create-my-own-vim/","excerpt":"打造自己的vim，包括基本配置，快捷键，映射，插件等，最后贴出来我自己的vim配置。","text":"&#x6253;&#x9020;&#x81EA;&#x5DF1;&#x7684;vim&#xFF0C;&#x5305;&#x62EC;&#x57FA;&#x672C;&#x914D;&#x7F6E;&#xFF0C;&#x5FEB;&#x6377;&#x952E;&#xFF0C;&#x6620;&#x5C04;&#xFF0C;&#x63D2;&#x4EF6;&#x7B49;&#xFF0C;&#x6700;&#x540E;&#x8D34;&#x51FA;&#x6765;&#x6211;&#x81EA;&#x5DF1;&#x7684;vim&#x914D;&#x7F6E;&#x3002; &#x5FEB;&#x6377;&#x952E;&#x76F8;&#x5173;&#x4F20;&#x9001;&#x95E8;vim&#x5FEB;&#x6377;&#x952E; &#x53C2;&#x8003; amix vimrc statusline","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"http://wzktravel.github.io/tags/vim/"}]},{"title":"使用hexo搭建github pages","slug":"hexo","date":"2015-06-25T04:12:12.000Z","updated":"2016-08-24T07:25:20.000Z","comments":true,"path":"2015/06/25/hexo/","link":"","permalink":"http://wzktravel.github.io/2015/06/25/hexo/","excerpt":"使用hexo搭建github pages。","text":"&#x4F7F;&#x7528;hexo&#x642D;&#x5EFA;github pages&#x3002; &#x51C6;&#x5907;&#x5DE5;&#x4F5C; git&#x4E00;&#x4E9B;&#x57FA;&#x672C;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x770B; &#x5ED6;&#x96EA;&#x5CF0;&#x7684;Git&#x6559;&#x7A0B; &#x4E00;&#x4E2A;github&#x8D26;&#x53F7; github pages&#x53EA;&#x9700;&#x8981;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;repository&#xFF0C;&#x540D;&#x4E3A; {username}.github.io&#xFF0C;username&#x4E3A;&#x4F60;&#x6CE8;&#x518C;&#x7684;github&#x8D26;&#x53F7;&#xFF0C;&#x7136;&#x540E;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x9875;&#x9762;index.html&#xFF0C;&#x5199;&#x5165;hello&#xFF0C;&#x63D0;&#x4EA4;&#x5230;github&#x4E2D;&#xFF0C;&#x5728;&#x9875;&#x9762;{username}.github.io&#x4E2D;&#x5373;&#x53EF;&#x663E;&#x793A;&#x9875;&#x9762;&#x5185;&#x5BB9;&#x3002; &#x5B89;&#x88C5;hexoRequirements Git Node.js &#x5B89;&#x88C5;hexo1$ npm install -g hexo-cli &#x521D;&#x59CB;&#x5316;1234$ npm install hexo --save$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install Hexo&#x547D;&#x4EE4;&#x65B0;&#x5EFA;&#x4E00;&#x7BC7;&#x6587;&#x7AE0;1$ hexo new &quot;My New Post&quot; More info: Writing &#x8FD0;&#x884C;server1$ hexo server ## &#x53EF;&#x4EE5;&#x7B80;&#x5199;&#x4E3A; hexo s &#x53EF;&#x4EE5;&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x67E5;&#x770B;(http://localhost:4000) More info: Server &#x751F;&#x6210;&#x9759;&#x6001;&#x9875;&#x9762;1$ hexo generate ## &#x4E00;&#x822C;hexo&#x4F1A;&#x81EA;&#x52A8;&#x751F;&#x6210; More info: Generating &#x81EA;&#x52A8;&#x90E8;&#x7F72;&#x5230;github&#x4E0A;1$ hexo deploy ## &#x4F7F;&#x7528;hexo d -g &#x8981;&#x4F7F;&#x7528;&#x6B64;&#x547D;&#x4EE4;&#xFF0C;&#x9996;&#x5148;&#x5F97;&#x5B89;&#x88C5;git&#x90E8;&#x7F72;&#x63D2;&#x4EF6; 1$ npm install hexo-deployer-git --save &#x7136;&#x540E;&#x5728;_config.yml&#x4E2D;&#x6DFB;&#x52A0;&#x5982;&#x4E0B;&#x8BBE;&#x7F6E;: 12345deploy: type: git repo: &lt;repository url&gt; branch: [branch] ##&#x53EF;&#x7701;&#x7565; message: [message] ##&#x53EF;&#x7701;&#x7565; More info: Deployment &#x5982;&#x4F55;&#x5904;&#x5904;&#x5199;&#x6587;&#x7AE0; &#x5B89;&#x88C5;git, node.js &#x5B89;&#x88C5;hexo, npm install -g hexo-cli &#x4ECE;github&#x4E0A;&#x62C9;&#x4EE3;&#x7801;, git clone https://github.com/wzktravel/hexo.git &#x521D;&#x59CB;&#x5316;hexo 1234$ npm install hexo --save$ hexo init &lt;folder&gt; ##&#x53D6;&#x6D88;&#x6B64;&#x53E5;&#xFF01;&#xFF01;&#x5DF2;&#x7ECF;&#x6709;hexo&#x7ED3;&#x6784;&#xFF0C;&#x65E0;&#x9700;init$ cd &lt;folder&gt;$ npm install &#x6587;&#x7AE0;md&#x6E90;&#x7801;&#x5728;source/_posts/&#x4E0B;&#xFF0C;&#x4F7F;&#x7528;hexo new ${post}&#x65B0;&#x5EFA;&#x6587;&#x7AE0;&#xFF0C;&#x4F7F;&#x7528;hexo s&#x542F;&#x52A8;&#x670D;&#x52A1;&#xFF0C;hexo d -g&#x63D0;&#x4EA4;&#x5230;github&#x4E0A; &#x6CE8;&#x610F;&#x6700;&#x540E;&#x5C06;&#x6587;&#x7AE0;&#x6E90;&#x7801;&#x4E5F;&#x63D0;&#x4EA4;&#x5230;&#x7EBF;&#x4E0A;,git add *, git commit -m &quot;${comment}&quot;, git push origin master&#x3002; &#x53C2;&#x8003; Hexo Hexo Docs Hexo Troubleshooting Hexo Github","categories":[],"tags":[]},{"title":"多线程curl","slug":"curl-in-multi-thread","date":"2015-06-17T11:56:58.000Z","updated":"2016-08-24T07:25:21.000Z","comments":true,"path":"2015/06/17/curl-in-multi-thread/","link":"","permalink":"http://wzktravel.github.io/2015/06/17/curl-in-multi-thread/","excerpt":"今天做了一个功能，后端提供一个接口，根据站点返回认证信息，很快ok。测试时要过一遍所有站点，总不能人工一个个查看吧，于是寻求解决方案。接口是post接口，所以自己写了一个jsp页面，用HttpURLConnection来访问接口，并把接口返回的数据吐到页面中。接下来用curl来访问这个jsp页面，获得数据放到文件中，再用awk进行解析。","text":"&#x4ECA;&#x5929;&#x505A;&#x4E86;&#x4E00;&#x4E2A;&#x529F;&#x80FD;&#xFF0C;&#x540E;&#x7AEF;&#x63D0;&#x4F9B;&#x4E00;&#x4E2A;&#x63A5;&#x53E3;&#xFF0C;&#x6839;&#x636E;&#x7AD9;&#x70B9;&#x8FD4;&#x56DE;&#x8BA4;&#x8BC1;&#x4FE1;&#x606F;&#xFF0C;&#x5F88;&#x5FEB;ok&#x3002;&#x6D4B;&#x8BD5;&#x65F6;&#x8981;&#x8FC7;&#x4E00;&#x904D;&#x6240;&#x6709;&#x7AD9;&#x70B9;&#xFF0C;&#x603B;&#x4E0D;&#x80FD;&#x4EBA;&#x5DE5;&#x4E00;&#x4E2A;&#x4E2A;&#x67E5;&#x770B;&#x5427;&#xFF0C;&#x4E8E;&#x662F;&#x5BFB;&#x6C42;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002;&#x63A5;&#x53E3;&#x662F;post&#x63A5;&#x53E3;&#xFF0C;&#x6240;&#x4EE5;&#x81EA;&#x5DF1;&#x5199;&#x4E86;&#x4E00;&#x4E2A;jsp&#x9875;&#x9762;&#xFF0C;&#x7528;HttpURLConnection&#x6765;&#x8BBF;&#x95EE;&#x63A5;&#x53E3;&#xFF0C;&#x5E76;&#x628A;&#x63A5;&#x53E3;&#x8FD4;&#x56DE;&#x7684;&#x6570;&#x636E;&#x5410;&#x5230;&#x9875;&#x9762;&#x4E2D;&#x3002;&#x63A5;&#x4E0B;&#x6765;&#x7528;curl&#x6765;&#x8BBF;&#x95EE;&#x8FD9;&#x4E2A;jsp&#x9875;&#x9762;&#xFF0C;&#x83B7;&#x5F97;&#x6570;&#x636E;&#x653E;&#x5230;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x518D;&#x7528;awk&#x8FDB;&#x884C;&#x89E3;&#x6790;&#x3002; &#x5728;curl&#x8FD9;&#x4E2A;&#x9636;&#x6BB5;&#x53D1;&#x751F;&#x95EE;&#x9898;&#x3002;url&#x8BCD;&#x8868;&#x4E3A;url.txt&#xFF0C;&#x6BCF;&#x884C;&#x4E00;&#x4E2A;&#x7AD9;&#x70B9;&#xFF0C;&#x76F4;&#x63A5; for line in `cat url.txt`; do curl -m 3 &quot;http://xxxx.jsp?url=$line&amp;type=1&quot; &gt;&gt; result.txt; done &#x55EF;&#xFF0C;&#x4E0D;&#x9519;&#xFF0C;&#x5F88;&#x4E0D;&#x9519;&#xFF0C;&#x5F88;&#x7A33;&#x5B9A;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x592A;&#x6162;&#xFF01;&#x7B2C;&#x4E00;&#x6279;&#x6D4B;&#x8BD5;&#x8BCD;&#x8868;&#x6709;6000&#x6761;&#x6570;&#x636E;&#xFF0C;&#x6BCF;&#x6B21;curl&#x8017;&#x65F6;&#x5927;&#x7EA6;300ms&#xFF0C;&#x8DD1;&#x5B8C;&#x9700;&#x8981;&#x5927;&#x7EA6;30&#x5206;&#x949F;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x5FCD;&#x53D7;&#x3002;&#x4F46;&#x662F;&#x540E;&#x7EED;&#x8BCD;&#x8868;&#x8D8A;&#x6765;&#x8D8A;&#x5927;&#xFF0C;&#x52A8;&#x4E0D;&#x52A8;&#x5C31;&#x51E0;&#x4E07;&#xFF0C;&#x51E0;&#x5341;&#x4E07;&#xFF0C;&#x8FD9;&#x65B9;&#x6CD5;&#x9700;&#x8981;&#x6539;&#x8FDB;&#x3002;&#x9700;&#x8981;&#x591A;&#x7EBF;&#x7A0B;&#x6216;&#x8005;&#x8BF4;&#x591A;&#x8FDB;&#x7A0B;&#x64CD;&#x4F5C;&#xFF0C;&#x4F46;&#x662F;&#x5728;&#x8FD9;&#x79CD;&#x5FAA;&#x73AF;&#x4E2D;&#x65E2;&#x7528;&amp;&#x6765;&#x540E;&#x53F0;&#x6267;&#x884C;&#x53C8;&#x6267;&#x884C;curl&#x65B9;&#x6CD5;&#xFF0C;&#x5C1D;&#x8BD5;&#x591A;&#x79CD;&#x65B9;&#x6CD5;&#x90FD;&#x4E0D;&#x53EF;&#x884C;&#x3002;&#x4F46;&#x4E0B;&#x9762;&#x7684;echo&#x662F;&#x53EF;&#x884C;&#x7684;&#x3002;12345for line in `cat url.txt`; do { sleep 3;echo &quot;http://xxx.jsp?url=&quot;$line&quot;&amp;type=1&quot; } &amp;done &#x7136;&#x540E;&#x5404;&#x79CD;google&#xFF0C;&#x6709;&#x4EBA;&#x5EFA;&#x8BAE;&#x7528;python&#xFF0C;&#x6709;&#x4EBA;&#x5EFA;&#x8BAE;&#x4F7F;&#x7528;ab&#xFF0C;&#x6700;&#x540E;&#x627E;&#x5230;&#x4E00;&#x4E2A;&#x547D;&#x4EE4;&#xFF0C;xargs&#xFF0C;&#x53EF;&#x4EE5;&#x540C;&#x65F6;&#x5F00;&#x542F;&#x591A;&#x4E2A;&#x8FDB;&#x7A0B;&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x3002; &#x4E8E;&#x662F;&#x8FDB;&#x884C;&#x6539;&#x9020;&#xFF0C;&#x9996;&#x5148;&#x8981;&#x5C06;&#x8BCD;&#x8868;&#x8FDB;&#x884C;&#x6574;&#x7406;&#xFF0C;&#x6574;&#x7406;&#x4E3A;http://xxx.jsp?url={host}&#x7684;&#x6837;&#x5B50;&#xFF0C;&#x4F7F;&#x7528;&#x5230;sed&#x547D;&#x4EE4;&#xFF0C;&#x522B;&#x5FD8;&#x4E86;&#x91CD;&#x5B9A;&#x5411;&#x5230;&#x65B0;&#x6587;&#x4EF6; 123456# &#x5728;&#x6BCF;&#x884C;&#x884C;&#x9996;&#x6DFB;&#x52A0;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x9700;&#x8981;&#x8F6C;&#x4E49;sed &apos;s/^/http:\\/\\/xxx.jsp?url=&amp;/g&apos; url.txt# &#x5728;&#x6BCF;&#x884C;&#x884C;&#x5C3E;&#x6DFB;&#x52A0;&#x5B57;&#x7B26;&#x4E32;sed &apos;s/$/&amp;\\&amp;type=1/g/&apos; url.txt # &#x4E5F;&#x53EF;&#x4EE5;&#x5728;&#x4E00;&#x6761;&#x547D;&#x4EE4;&#x4E2D;&#x5B8C;&#x6210;&#x4E0A;&#x9762;&#x4E24;&#x4E2A;&#x64CD;&#x4F5C;sed &apos;/./{s/^/http:\\/\\/xxx.jsp?url=&amp;/; s/$/&amp;\\&amp;type=1/}&apos; url.txt &#x5BF9;&#x4E8E;xargs&#x6211;&#x8FD9;&#x8FB9;&#x4F7F;&#x7528;&#x7684;&#x65B9;&#x6CD5;&#x5982;&#x4E0B;&#xFF1A; &lt; url.txt xargs -r -L 1 -P 50 curl &gt; result_xargs.txt &#x6CE8;&#x610F;&#xFF1A;&#x5982;&#x679C;&#x670D;&#x52A1;&#x5668;&#x662F;&#x6D4B;&#x8BD5;&#x673A;&#x5668;&#xFF0C;&#x5F00;&#x7684;&#x8FDB;&#x7A0B;&#x6570;&#x4E0D;&#x80FD;&#x592A;&#x591A;&#xFF0C;&#x8BF7;&#x6C42;&#x6570;&#x592A;&#x591A;&#x4F1A;&#x5C06;&#x670D;&#x52A1;&#x5668;&#x6253;&#x6302;&#x3002; &#x5907;&#x5FD8;&#x4ECA;&#x5929;&#x7528;&#x5230;&#x8BB8;&#x591A;&#x4E4B;&#x524D;&#x6CA1;&#x6709;&#x63A5;&#x89E6;&#x7684;&#x4E1C;&#x897F;&#xFF0C;&#x5907;&#x5FD8;&#x4E00;&#x4E0B; awk&#x4E2D;&#x8C03;&#x7528;shell&#x547D;&#x4EE4;: awk &apos;{cmd=&quot;echo &quot;$0; system(cmd);}&apos; shell&#x6309;&#x884C;&#x8BFB;&#x53D6;&#x4E09;&#x79CD;&#x65B9;&#x5F0F;&#xFF0C;&#x5176;&#x5B9E;&#x7528;awk&#x662F;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#x7684;&#xFF0C;&#x4F46;&#x662F;&#x5982;&#x679C;&#x9047;&#x5230;&#x66F4;&#x590D;&#x6742;&#x7684;&#x64CD;&#x4F5C;&#x9700;&#x8981;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F; while&#x7684;&#x7B2C;&#x4E00;&#x79CD;&#x65B9;&#x5F0F; 12345#!/bin/bashwhile read linedo echo $linedone &lt; filename while&#x7684;&#x7B2C;&#x4E8C;&#x79CD;&#x65B9;&#x5F0F; 12345#!/bin/bashcat filename | while read linedo echo $linedone for 1234for line in `cat filename`do echo $linedone for&#x548C;while&#x65B9;&#x5F0F;&#x8FD8;&#x6709;&#x6240;&#x4E0D;&#x540C; 12345678910$ cat file1111 3333 4444 $ cat file | while read line; do echo $line; done1111 3333 4444 $ for line in $(&lt;file); do echo $line; done1111 33334444 ab&#x547D;&#x4EE4;&#xFF0C;apache&#x51FA;&#x54C1;&#xFF0C;&#x6253;&#x538B;&#x529B;&#x4E13;&#x7528;&#x3002;&#x5907;&#x5FD8;&#xFF0C;&#x4EE5;&#x540E;&#x53EF;&#x80FD;&#x7528;&#x5230; &#x53C2;&#x8003; xargs&#x8BF4;&#x660E; xargs&#x5B9E;&#x4F8B; ab&#x547D;&#x4EE4;","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://wzktravel.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"}]},{"title":"在github搭建自己的blog","slug":"how-to-build-your-own-blog-on-github","date":"2015-06-15T11:56:58.000Z","updated":"2016-08-24T07:25:22.000Z","comments":true,"path":"2015/06/15/how-to-build-your-own-blog-on-github/","link":"","permalink":"http://wzktravel.github.io/2015/06/15/how-to-build-your-own-blog-on-github/","excerpt":"一个周末，终于搞定，写个大概流程，具体的可以参考下方列出的页面。开始用的是jekyll，后来转到了hexo。本篇介绍的是jekyll，hexo可以参考使用hexo搭建github pages，比jekyll配置简单许多。","text":"&#x4E00;&#x4E2A;&#x5468;&#x672B;&#xFF0C;&#x7EC8;&#x4E8E;&#x641E;&#x5B9A;&#xFF0C;&#x5199;&#x4E2A;&#x5927;&#x6982;&#x6D41;&#x7A0B;&#xFF0C;&#x5177;&#x4F53;&#x7684;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#x4E0B;&#x65B9;&#x5217;&#x51FA;&#x7684;&#x9875;&#x9762;&#x3002;&#x5F00;&#x59CB;&#x7528;&#x7684;&#x662F;jekyll&#xFF0C;&#x540E;&#x6765;&#x8F6C;&#x5230;&#x4E86;hexo&#x3002;&#x672C;&#x7BC7;&#x4ECB;&#x7ECD;&#x7684;&#x662F;jekyll&#xFF0C;hexo&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#x4F7F;&#x7528;hexo&#x642D;&#x5EFA;github pages&#xFF0C;&#x6BD4;jekyll&#x914D;&#x7F6E;&#x7B80;&#x5355;&#x8BB8;&#x591A;&#x3002; git&#x4E00;&#x4E9B;&#x57FA;&#x672C;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x770B; &#x5ED6;&#x96EA;&#x5CF0;&#x7684;Git&#x6559;&#x7A0B; &#x4E00;&#x4E2A;github&#x8D26;&#x53F7; &#x9700;&#x8981;&#x4E00;&#x70B9;&#x8010;&#x5FC3; &#x4F7F;&#x7528;github pages&#x53EA;&#x9700;&#x8981;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;repository&#xFF0C;&#x540D;&#x4E3A; {username}.github.io&#xFF0C;username&#x4E3A;&#x4F60;&#x6CE8;&#x518C;&#x7684;github&#x8D26;&#x53F7;&#xFF0C;&#x7136;&#x540E;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x9875;&#x9762;index.html&#xFF0C;&#x5199;&#x5165;hello&#xFF0C;&#x63D0;&#x4EA4;&#x5230;github&#x4E2D;&#xFF0C;&#x5728;&#x9875;&#x9762;{username}.github.io&#x4E2D;&#x5373;&#x53EF;&#x663E;&#x793A;&#x9875;&#x9762;&#x5185;&#x5BB9;&#x3002;&#x4F8B;&#x5982;&#xFF1A;&#x6211;&#x7684;&#x8D26;&#x53F7;&#x540D;&#x4E3A;wzktravel&#xFF0C;&#x6211;&#x7684;github blog&#x5730;&#x5740;&#x5C31;&#x4E3A; wzktravel.github.io &#x5728;&#x672C;&#x5730;&#x642D;&#x5EFA;jekyll&#x73AF;&#x5883;&#x5177;&#x4F53;&#x64CD;&#x4F5C;&#x7565;&#x8FC7;&#xFF0C;&#x8BE6;&#x7EC6;&#x7684;&#x53EF;&#x4EE5;&#x770B;github&#x5B98;&#x65B9;&#x6B65;&#x9AA4;&#xFF0C;&#x8FD9;&#x91CC;&#x4E3B;&#x8981;&#x8BF4;&#x4E00;&#x4E0B;&#x5927;&#x4F53;&#x6B65;&#x9AA4;&#x548C;&#x9047;&#x5230;&#x7684;&#x4E00;&#x4E9B;&#x5751;&#x3002; &#x673A;&#x5668;&#x73AF;&#x5883;&#xFF1A;redhat6&#xFF0C;mac 10.10.2 &#x5B89;&#x88C5;ruby&#xFF0C;&#x9700;&#x8981;&#x7248;&#x672C;2.0.0&#x4EE5;&#x4E0A; &#x4F7F;&#x7528;gem&#x5B89;&#x88C5;bundler&#xFF0C;&#x5728;&#x6B64;&#x6B65;&#x9AA4;&#x4E4B;&#x524D;&#xFF0C;&#x8BF7;&#x5148;&#x6362;gem&#x6E90;&#xFF01; gem sources --remove https://rubygems.org/ #&#x5220;&#x9664;ruby&#x5B98;&#x65B9;&#x6E90; gem sources -a http://ruby.taobao.org/ #&#x4F7F;&#x7528;taobao&#x6E90; gem sources -u #&#x66F4;&#x65B0;&#x6E90; gem sources -l #&#x5217;&#x51FA;&#x6240;&#x6709;&#x6E90;&#xFF0C;&#x4FDD;&#x8BC1;&#x53EA;&#x6709;taobao&#x7684;&#x90A3;&#x4E2A; &#x53EF;&#x4EE5;&#x5C06;&#x6211;&#x7684;repository copy&#x4E00;&#x4EFD;(&#x6700;&#x597D;&#x662F;&#x6211;&#x7684;&#xFF0C;&#x6709;&#x4E00;&#x4E9B;&#x5C0F;&#x5DE5;&#x5177;)&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x7528;&#x5176;&#x4ED6;&#x4EBA;&#x7684;&#xFF0C;&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;Gemfile&#xFF0C;&#x5185;&#x5BB9; 12source &apos;http://ruby.taobao.org/&apos; gem &apos;github-pages&apos; &#x7136;&#x540E;&#x8FD0;&#x884C;buddle install&#xFF0C;&#x795D;&#x4F60;&#x597D;&#x8FD0;&#x3002; &#x5982;&#x679C;&#x662F;&#x5728;mac&#x4E0A;&#xFF0C;&#x5728;buddle install&#x4E4B;&#x524D;&#xFF0C;&#x9700;&#x8981;&#x81EA;&#x884C;&#x5B89;&#x88C5;libxml2&#xFF0C;xcode&#x662F;&#x5FC5;&#x9700;&#x7684;&#xFF0C;&#x5176;&#x4ED6;&#x7684;&#x5404;&#x79CD;&#x7248;&#x672C;libxml2&#x90FD;&#x4E0D;&#x597D;&#x4F7F;&#xFF0C;&#x76F8;&#x4FE1;&#x6211; sudo gem install nokogiri -- --with-xml2-include=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.10.sdk/usr/include/libxml2 --use-system-libraries &#x53C2;&#x8003; http://www.virtlab.cx/ruby-fix-error-install-nokogiri-yosemite/ &#x5168;&#x90FD;&#x6210;&#x529F;&#x4E4B;&#x540E;&#xFF0C;&#x53EF;&#x4EE5;bundle exec jekyll serve&#xFF0C;&#x5F00;&#x542F;&#x672C;&#x5730;jekyll&#x670D;&#x52A1;&#xFF0C;&#x8F93;&#x5165;ip:4000&#x67E5;&#x770B;&#x4F60;&#x7684;&#x672C;&#x5730;blog&#x3002;&#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6211;&#x7684;&#x811A;&#x672C; 1./server (start|stop|restart) &#x6211;&#x7684;&#x662F;&#x57FA;&#x4E8E;jekyllbootstrap&#x7684;&#xFF0C;&#x6837;&#x5F0F;&#x53EF;&#x4EE5;&#x81EA;&#x5DF1;&#x5B9A;&#x4E49;&#xFF0C;&#x5728;assets/themes/bootstrap-3/css/style.css &#x5C0F;&#x5DE5;&#x5177;&#x548C;&#x5907;&#x5FD8;&#x65B0;&#x5EFA;&#x76F8;&#x5173;: rake &#x65B0;&#x5EFA;&#x4E00;&#x7BC7;&#x6587;&#x7AE0;: rake post title=&quot;hello world&quot; &#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x9875;&#x9762;: rake page name=&quot;about.md&quot; &#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x5185;&#x90E8;&#x9875;&#x9762;: rank page name=&quot;pages/about.md&quot; &#x672C;&#x5730;server ./server (start|stop|restart) &#x65E5;&#x5FD7;&#x5728;_log&#x76EE;&#x5F55;&#x4E0B; &#x53C2;&#x8003; https://help.github.com/articles/using-jekyll-with-pages/ http://jekyllbootstrap.com/usage/jekyll-quick-start.html http://cnfeat.com/2014/05/10/2014-05-11-how-to-build-a-blog/ markdown&#x8BED;&#x6CD5;","categories":[],"tags":[{"name":"shell","slug":"shell","permalink":"http://wzktravel.github.io/tags/shell/"},{"name":"github","slug":"github","permalink":"http://wzktravel.github.io/tags/github/"}]}]}